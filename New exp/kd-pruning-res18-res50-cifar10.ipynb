{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m981.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop the image\n",
    "    transforms.Resize(224),  # Resize to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# No augmentation for validation and test\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_val_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_test_transform)\n",
    "\n",
    "# Split train_val_dataset into train and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# Apply val_test_transform to the validation set\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "24.0%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "93.0%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-50 (Teacher Model)\n",
    "teacher = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for 10 classes (CIFAR-10)\n",
    "teacher.fc = nn.Linear(teacher.fc.in_features, 10)\n",
    "# Move models to device\n",
    "teacher = teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'Best_Teacher.pth'\n",
    "# Load the model weights\n",
    "teacher.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "52.5%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-18 (Student Model)\n",
    "student = models.resnet18(pretrained=True)\n",
    "# Modify the final fully connected layer for 10 classes (CIFAR-10)\n",
    "student.fc = nn.Linear(student.fc.in_features, 10)\n",
    "student = student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA-KLD Loss for Classification\n",
    "def cakld_loss(student_logits, teacher_logits, beta_prob):\n",
    "    # Forward KL (student || teacher)\n",
    "    student_log_prob = F.log_softmax(student_logits, dim=1)\n",
    "    teacher_prob = F.softmax(teacher_logits, dim=1)\n",
    "    forward_kl = F.kl_div(student_log_prob, teacher_prob, reduction='batchmean')\n",
    "\n",
    "    # Reverse KL (teacher || student)\n",
    "    teacher_log_prob = F.log_softmax(teacher_logits, dim=1)\n",
    "    student_prob = F.softmax(student_logits, dim=1)\n",
    "    reverse_kl = F.kl_div(teacher_log_prob, student_prob, reduction='batchmean')\n",
    "\n",
    "    # Combined KL loss\n",
    "    kl_loss = beta_prob * reverse_kl + (1 - beta_prob) * forward_kl\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model = model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparsity(model):\n",
    "    total_zeros = 0\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_zeros += torch.sum(param == 0).item()\n",
    "            total_params += param.numel()\n",
    "    return total_zeros / total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "def measure_inference_time(model, test_loader, num_runs=5):\n",
    "    device = torch.device('cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Warm-up (one batch to avoid startup cost)\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            _ = model(inputs)\n",
    "            break\n",
    "\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            for inputs, _ in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                start_time = time.time()\n",
    "                _ = model(inputs)\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += (end_time - start_time)\n",
    "                total_images += batch_size\n",
    "\n",
    "    avg_time_per_image = total_time / total_images\n",
    "    return avg_time_per_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def calculate_model_size(model, filename=\"temp.pth\"):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    size = os.path.getsize(filename) / (1024 * 1024)  # Size in MB\n",
    "    os.remove(filename)\n",
    "    return size\n",
    "\n",
    "def compare_model_sizes(teacher, student, pruned_student):\n",
    "    # Count parameters\n",
    "    teacher_params = count_parameters(teacher)\n",
    "    student_params = count_parameters(student)\n",
    "    pruned_params = count_parameters(pruned_student)\n",
    "    \n",
    "    # Calculate disk size\n",
    "    teacher_size = calculate_model_size(teacher, \"teacher.pth\")\n",
    "    student_size = calculate_model_size(student, \"student.pth\")\n",
    "    pruned_size = calculate_model_size(pruned_student, \"pruned_student.pth\")\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"\\n--- Model Size Comparison ---\")\n",
    "    print(f\"Teacher Model: {teacher_params} parameters, {teacher_size:.2f} MB\")\n",
    "    print(f\"Student Model (Before Pruning): {student_params} parameters, {student_size:.2f} MB\")\n",
    "    print(f\"Student Model (After Pruning): {pruned_params} parameters, {pruned_size:.2f} MB\")\n",
    "    \n",
    "    # Calculate compression ratio\n",
    "    compression_ratio = student_size / pruned_size\n",
    "    print(f\"\\nCompression Ratio: {compression_ratio:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, patience=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        val_accuracy = evaluate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            torch.save(model.state_dict(), 'best_teacher_model.pth')  # Save the best model\n",
    "            print(f\" New best model saved with validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" No improvement in validation accuracy ({patience_counter}/{patience})\")\n",
    "            \n",
    "            # Stop training if no improvement for 'patience' epochs\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered! No improvement for {patience} epochs.\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(torch.load('best_teacher_model.pth'))\n",
    "    print(\"\\nLoading the best model for final evaluation.\")\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    print(f\"Test Accuracy with Best Model: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_importance(\n",
    "    teacher, student, data_loader, device, temperature=4.0, alpha=0.5, beta_prob=0.5, accumulation_epochs=3\n",
    "):\n",
    "    importance_scores = {}\n",
    "\n",
    "    # Initialize importance score storage for conv layer weights only\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and isinstance(param, nn.Parameter) and len(param.shape) == 4:\n",
    "            importance_scores[name] = torch.zeros_like(param.data, device=device)\n",
    "\n",
    "    teacher.to(device).eval()\n",
    "    student.to(device).train()\n",
    "\n",
    "    for epoch in range(accumulation_epochs):\n",
    "        print(f\"Accumulation Epoch {epoch+1}/{accumulation_epochs}\")\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # Apply temperature scaling\n",
    "            student_logits_temp = student_logits / temperature\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "\n",
    "            # Compute CA-KLD loss with temperature\n",
    "            distillation_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "\n",
    "            # Cross-entropy loss\n",
    "            ce_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            # Total loss\n",
    "            loss = alpha * distillation_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Accumulate squared gradients (L2 norm)\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in importance_scores and param.grad is not None:\n",
    "                    importance_scores[name] += (param.grad.detach() ** 2)\n",
    "\n",
    "    # Normalize importance scores by total batches processed\n",
    "    total_batches = accumulation_epochs * len(data_loader)\n",
    "    for name in importance_scores:\n",
    "        importance_scores[name] /= total_batches\n",
    "\n",
    "    return importance_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_based_global_prune(model, importance_scores, prune_ratio=0.95):\n",
    "    all_scores = torch.cat([score.flatten() for score in importance_scores.values()])\n",
    "    threshold = torch.topk(all_scores, k=int(prune_ratio * all_scores.numel()), largest=False)[0][-1]\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in importance_scores:\n",
    "            mask = (importance_scores[name] > threshold).float()\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def retrain_with_sparsity(student, train_loader, val_loader, epochs=5, save_path=\"retrained_student_model.pt\", patience=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # 1. Store masks AND zero momentum buffers for pruned weights\n",
    "    masks = {}\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and param.dim() == 4:  # Consider only conv layers\n",
    "            mask = (param != 0).float().to(device)\n",
    "            masks[name] = mask\n",
    "            # Zero momentum buffers for pruned weights\n",
    "            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                optimizer.state[param]['momentum_buffer'] *= mask\n",
    "\n",
    "    student = student.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    best_model = None\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "\n",
    "    # 2. Add gradient clipping to prevent NaN\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = student(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Apply masks to gradients\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.grad.data *= masks[name]\n",
    "\n",
    "            # Gradient clipping before optimizer step\n",
    "            torch.nn.utils.clip_grad_norm_(student.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reapply masks and update momentum buffers\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.data *= masks[name]\n",
    "                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        student.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "        # Track best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = student.state_dict()\n",
    "            torch.save(best_model, save_path)\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            print(f\"New best model saved with Val Accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break  # Stop training\n",
    "\n",
    "        # Print results\n",
    "        sparsity = calculate_sparsity(student)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.2f}% | Sparsity: {sparsity*100:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}% | Best Model Saved at: {save_path}\")\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# KD training with CA-KLD loss and mask-based momentum handling\n",
    "def retrain_with_KD(teacher, student, train_loader, val_loader, epochs=50,\n",
    "                    temperature=5.0, alpha=0.5, beta_prob=0.5, patience=5,\n",
    "                    save_path=\"student_before_pruning.pth\"):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # 1. Store masks and zero momentum buffers\n",
    "    masks = {}\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and param.dim() == 4:\n",
    "            mask = (param != 0).float().to(device)\n",
    "            masks[name] = mask\n",
    "            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                optimizer.state[param]['momentum_buffer'] *= mask\n",
    "\n",
    "    teacher = teacher.to(device).eval()\n",
    "    student = student.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # Apply temperature\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "            student_logits_temp = student_logits / temperature\n",
    "\n",
    "            # CA-KLD loss\n",
    "            kd_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "            ce_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reapply masks and update momentum\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.data *= masks[name]\n",
    "                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = student_logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        student.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        sparsity = calculate_sparsity(student) * 100.0  # Assuming this function is defined elsewhere\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = student.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    # Restore and save best model\n",
    "    student.load_state_dict(best_model_state)\n",
    "    torch.save(student.state_dict(), save_path)\n",
    "    print(f\"Student model saved before pruning at: {save_path}\")\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Training function with KD + CA-KLD\n",
    "def train_kd_pruning(teacher, student, train_loader, val_loader, epochs=50,\n",
    "                     pruning_type='unstructured', temperature=5.0, alpha=0.5,\n",
    "                     beta_prob=0.5, patience=5, save_path=\"student_before_pruning.pth\"):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    teacher.eval()  # Freeze teacher\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # CA-KLD loss (temperature-scaled)\n",
    "            student_logits_temp = student_logits / temperature\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "            distillation_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "\n",
    "            # Cross-entropy loss\n",
    "            ground_truth_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            # Combined loss\n",
    "            loss = alpha * distillation_loss + (1 - alpha) * ground_truth_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = student_logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation accuracy\n",
    "        val_acc = evaluate(student, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = student.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    # Load best model state and save\n",
    "    student.load_state_dict(best_model_state)\n",
    "    torch.save(student.state_dict(), save_path)\n",
    "    print(f\"Student model saved before pruning at: {save_path}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Before Pruning: 0.00%\n",
      "Teacher Model Test Accuracy: 95.40%\n",
      "Student Model Test Accuracy Before Pruning: 95.29%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sparsity\n",
    "sparsity = calculate_sparsity(student)\n",
    "print(f\"Sparsity Before Pruning: {sparsity * 100:.2f}%\")\n",
    "\n",
    "teacher_accuracy = evaluate(teacher, test_loader, device)\n",
    "student_accuracy = evaluate(student, test_loader, device)\n",
    "print(f\"Teacher Model Test Accuracy: {teacher_accuracy:.2f}%\")\n",
    "print(f\"Student Model Test Accuracy Before Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 93% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 33s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 10.00%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 35.66%\n",
      "Epoch 1/200 | Train Loss: 2.0993 | Train Acc: 19.77%\n",
      "Validation Loss: 1.6356 | Validation Acc: 35.66% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 55.56%\n",
      "Epoch 2/200 | Train Loss: 1.3603 | Train Acc: 48.59%\n",
      "Validation Loss: 1.1900 | Validation Acc: 55.56% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 73.77%\n",
      "Epoch 3/200 | Train Loss: 0.8713 | Train Acc: 68.97%\n",
      "Validation Loss: 0.7565 | Validation Acc: 73.77% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 78.06%\n",
      "Epoch 4/200 | Train Loss: 0.6204 | Train Acc: 78.50%\n",
      "Validation Loss: 0.6466 | Validation Acc: 78.06% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 81.19%\n",
      "Epoch 5/200 | Train Loss: 0.4840 | Train Acc: 83.36%\n",
      "Validation Loss: 0.5528 | Validation Acc: 81.19% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 83.83%\n",
      "Epoch 6/200 | Train Loss: 0.3920 | Train Acc: 86.78%\n",
      "Validation Loss: 0.4883 | Validation Acc: 83.83% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 84.63%\n",
      "Epoch 7/200 | Train Loss: 0.3162 | Train Acc: 89.34%\n",
      "Validation Loss: 0.4692 | Validation Acc: 84.63% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 84.70%\n",
      "Epoch 8/200 | Train Loss: 0.2558 | Train Acc: 91.41%\n",
      "Validation Loss: 0.4865 | Validation Acc: 84.70% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 85.78%\n",
      "Epoch 9/200 | Train Loss: 0.2058 | Train Acc: 93.00%\n",
      "Validation Loss: 0.4561 | Validation Acc: 85.78% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 10/200 | Train Loss: 0.1643 | Train Acc: 94.50%\n",
      "Validation Loss: 0.5008 | Validation Acc: 84.82% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 11/200 | Train Loss: 0.1326 | Train Acc: 95.61%\n",
      "Validation Loss: 0.4784 | Validation Acc: 85.73% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 12/200 | Train Loss: 0.1096 | Train Acc: 96.42%\n",
      "Validation Loss: 0.5740 | Validation Acc: 85.34% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 85.93%\n",
      "Epoch 13/200 | Train Loss: 0.0886 | Train Acc: 97.15%\n",
      "Validation Loss: 0.5197 | Validation Acc: 85.93% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 14/200 | Train Loss: 0.0756 | Train Acc: 97.52%\n",
      "Validation Loss: 0.5521 | Validation Acc: 85.67% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 15/200 | Train Loss: 0.0634 | Train Acc: 98.01%\n",
      "Validation Loss: 0.5703 | Validation Acc: 85.66% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 16/200 | Train Loss: 0.0558 | Train Acc: 98.22%\n",
      "Validation Loss: 0.6270 | Validation Acc: 84.30% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 86.47%\n",
      "Epoch 17/200 | Train Loss: 0.0483 | Train Acc: 98.50%\n",
      "Validation Loss: 0.5457 | Validation Acc: 86.47% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 87.01%\n",
      "Epoch 18/200 | Train Loss: 0.0442 | Train Acc: 98.59%\n",
      "Validation Loss: 0.5340 | Validation Acc: 87.01% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 19/200 | Train Loss: 0.0391 | Train Acc: 98.79%\n",
      "Validation Loss: 0.5611 | Validation Acc: 86.92% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 20/200 | Train Loss: 0.0375 | Train Acc: 98.74%\n",
      "Validation Loss: 0.6448 | Validation Acc: 85.40% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 21/200 | Train Loss: 0.0333 | Train Acc: 98.93%\n",
      "Validation Loss: 0.6511 | Validation Acc: 85.67% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 22/200 | Train Loss: 0.0305 | Train Acc: 99.02%\n",
      "Validation Loss: 0.5786 | Validation Acc: 86.89% | Sparsity: 93.92%\n",
      "\n",
      "New best model saved with Val Accuracy: 87.25%\n",
      "Epoch 23/200 | Train Loss: 0.0298 | Train Acc: 99.08%\n",
      "Validation Loss: 0.5838 | Validation Acc: 87.25% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 24/200 | Train Loss: 0.0268 | Train Acc: 99.11%\n",
      "Validation Loss: 0.6339 | Validation Acc: 86.04% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 25/200 | Train Loss: 0.0247 | Train Acc: 99.18%\n",
      "Validation Loss: 0.6418 | Validation Acc: 86.09% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 26/200 | Train Loss: 0.0260 | Train Acc: 99.19%\n",
      "Validation Loss: 0.5912 | Validation Acc: 87.25% | Sparsity: 93.92%\n",
      "\n",
      "Epoch 27/200 | Train Loss: 0.0232 | Train Acc: 99.24%\n",
      "Validation Loss: 0.6513 | Validation Acc: 86.77% | Sparsity: 93.92%\n",
      "\n",
      "Early stopping triggered at epoch 28. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 87.25% | Best Model Saved at: retrained_student_model.pt\n",
      "Retraining completed in 16.18 minutes (970.75 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 84.44%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 6.3164 | Train Acc: 41.28% | Val Loss: 1.5014 | Val Acc: 58.30% | Sparsity: 93.92%\n",
      "Epoch 2/50 | Train Loss: 3.0966 | Train Acc: 74.76% | Val Loss: 0.9108 | Val Acc: 76.63% | Sparsity: 93.92%\n",
      "Epoch 3/50 | Train Loss: 2.0570 | Train Acc: 83.55% | Val Loss: 0.6739 | Val Acc: 81.50% | Sparsity: 93.92%\n",
      "Epoch 4/50 | Train Loss: 1.6038 | Train Acc: 87.52% | Val Loss: 0.6448 | Val Acc: 83.85% | Sparsity: 93.92%\n",
      "Epoch 5/50 | Train Loss: 1.3316 | Train Acc: 89.84% | Val Loss: 0.5693 | Val Acc: 85.33% | Sparsity: 93.92%\n",
      "Epoch 6/50 | Train Loss: 1.1241 | Train Acc: 91.87% | Val Loss: 0.4796 | Val Acc: 86.54% | Sparsity: 93.92%\n",
      "Epoch 7/50 | Train Loss: 0.9732 | Train Acc: 93.22% | Val Loss: 0.4670 | Val Acc: 87.70% | Sparsity: 93.92%\n",
      "Epoch 8/50 | Train Loss: 0.8462 | Train Acc: 94.60% | Val Loss: 0.5204 | Val Acc: 86.63% | Sparsity: 93.92%\n",
      "Epoch 9/50 | Train Loss: 0.7445 | Train Acc: 95.50% | Val Loss: 0.4442 | Val Acc: 88.27% | Sparsity: 93.92%\n",
      "Epoch 10/50 | Train Loss: 0.6392 | Train Acc: 96.54% | Val Loss: 0.4057 | Val Acc: 89.46% | Sparsity: 93.92%\n",
      "Epoch 11/50 | Train Loss: 0.5780 | Train Acc: 97.17% | Val Loss: 0.3800 | Val Acc: 89.56% | Sparsity: 93.92%\n",
      "Epoch 12/50 | Train Loss: 0.5156 | Train Acc: 97.72% | Val Loss: 0.3966 | Val Acc: 89.53% | Sparsity: 93.92%\n",
      "Epoch 13/50 | Train Loss: 0.4802 | Train Acc: 98.00% | Val Loss: 0.3577 | Val Acc: 90.37% | Sparsity: 93.92%\n",
      "Epoch 14/50 | Train Loss: 0.4426 | Train Acc: 98.30% | Val Loss: 0.3835 | Val Acc: 89.59% | Sparsity: 93.92%\n",
      "Epoch 15/50 | Train Loss: 0.4079 | Train Acc: 98.55% | Val Loss: 0.3764 | Val Acc: 89.86% | Sparsity: 93.92%\n",
      "Epoch 16/50 | Train Loss: 0.3864 | Train Acc: 98.65% | Val Loss: 0.3198 | Val Acc: 91.18% | Sparsity: 93.92%\n",
      "Epoch 17/50 | Train Loss: 0.3662 | Train Acc: 98.85% | Val Loss: 0.3396 | Val Acc: 90.82% | Sparsity: 93.92%\n",
      "Epoch 18/50 | Train Loss: 0.3459 | Train Acc: 98.92% | Val Loss: 0.3386 | Val Acc: 90.66% | Sparsity: 93.92%\n",
      "Epoch 19/50 | Train Loss: 0.3334 | Train Acc: 98.91% | Val Loss: 0.3602 | Val Acc: 90.13% | Sparsity: 93.92%\n",
      "Epoch 20/50 | Train Loss: 0.3209 | Train Acc: 99.00% | Val Loss: 0.3582 | Val Acc: 90.45% | Sparsity: 93.92%\n",
      "Epoch 21/50 | Train Loss: 0.3146 | Train Acc: 98.94% | Val Loss: 0.3129 | Val Acc: 91.21% | Sparsity: 93.92%\n",
      "Epoch 22/50 | Train Loss: 0.2996 | Train Acc: 99.13% | Val Loss: 0.3170 | Val Acc: 91.03% | Sparsity: 93.92%\n",
      "Epoch 23/50 | Train Loss: 0.2926 | Train Acc: 99.02% | Val Loss: 0.3102 | Val Acc: 91.28% | Sparsity: 93.92%\n",
      "Epoch 24/50 | Train Loss: 0.2816 | Train Acc: 99.08% | Val Loss: 0.3477 | Val Acc: 90.51% | Sparsity: 93.92%\n",
      "Epoch 25/50 | Train Loss: 0.2784 | Train Acc: 99.11% | Val Loss: 0.3210 | Val Acc: 91.19% | Sparsity: 93.92%\n",
      "Epoch 26/50 | Train Loss: 0.2664 | Train Acc: 99.10% | Val Loss: 0.3369 | Val Acc: 90.83% | Sparsity: 93.92%\n",
      "Epoch 27/50 | Train Loss: 0.2584 | Train Acc: 99.15% | Val Loss: 0.3186 | Val Acc: 91.09% | Sparsity: 93.92%\n",
      "Epoch 28/50 | Train Loss: 0.2509 | Train Acc: 99.13% | Val Loss: 0.3111 | Val Acc: 90.95% | Sparsity: 93.92%\n",
      "Early stopping triggered at epoch 28. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 26m 13s\n",
      "Retraining completed in 26.22 minutes (1573.04 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 90.55%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 6.5293 | Train Acc: 32.02% | Val Loss: 1.6913 | Val Acc: 54.95% | Sparsity: 93.92%\n",
      "Epoch 2/50 | Train Loss: 2.6744 | Train Acc: 76.64% | Val Loss: 1.1272 | Val Acc: 73.60% | Sparsity: 93.92%\n",
      "Epoch 3/50 | Train Loss: 1.6963 | Train Acc: 85.89% | Val Loss: 0.5245 | Val Acc: 85.56% | Sparsity: 93.92%\n",
      "Epoch 4/50 | Train Loss: 1.3119 | Train Acc: 89.51% | Val Loss: 0.4228 | Val Acc: 87.49% | Sparsity: 93.92%\n",
      "Epoch 5/50 | Train Loss: 1.0943 | Train Acc: 91.70% | Val Loss: 0.5385 | Val Acc: 85.99% | Sparsity: 93.92%\n",
      "Epoch 6/50 | Train Loss: 0.9378 | Train Acc: 93.20% | Val Loss: 0.5076 | Val Acc: 87.40% | Sparsity: 93.92%\n",
      "Epoch 7/50 | Train Loss: 0.8127 | Train Acc: 94.62% | Val Loss: 0.3619 | Val Acc: 89.87% | Sparsity: 93.92%\n",
      "Epoch 8/50 | Train Loss: 0.7068 | Train Acc: 95.63% | Val Loss: 0.3803 | Val Acc: 90.02% | Sparsity: 93.92%\n",
      "Epoch 9/50 | Train Loss: 0.6250 | Train Acc: 96.69% | Val Loss: 0.3600 | Val Acc: 90.05% | Sparsity: 93.92%\n",
      "Epoch 10/50 | Train Loss: 0.5771 | Train Acc: 97.15% | Val Loss: 0.3456 | Val Acc: 90.72% | Sparsity: 93.92%\n",
      "Epoch 11/50 | Train Loss: 0.5063 | Train Acc: 97.77% | Val Loss: 0.3332 | Val Acc: 91.15% | Sparsity: 93.92%\n",
      "Epoch 12/50 | Train Loss: 0.4642 | Train Acc: 98.22% | Val Loss: 0.3285 | Val Acc: 90.87% | Sparsity: 93.92%\n",
      "Epoch 13/50 | Train Loss: 0.4300 | Train Acc: 98.38% | Val Loss: 0.3185 | Val Acc: 90.98% | Sparsity: 93.92%\n",
      "Epoch 14/50 | Train Loss: 0.4065 | Train Acc: 98.61% | Val Loss: 0.3226 | Val Acc: 91.20% | Sparsity: 93.92%\n",
      "Epoch 15/50 | Train Loss: 0.3865 | Train Acc: 98.71% | Val Loss: 0.3068 | Val Acc: 91.29% | Sparsity: 93.92%\n",
      "Epoch 16/50 | Train Loss: 0.3638 | Train Acc: 98.87% | Val Loss: 0.3095 | Val Acc: 91.33% | Sparsity: 93.92%\n",
      "Epoch 17/50 | Train Loss: 0.3455 | Train Acc: 98.86% | Val Loss: 0.3317 | Val Acc: 90.91% | Sparsity: 93.92%\n",
      "Epoch 18/50 | Train Loss: 0.3337 | Train Acc: 99.04% | Val Loss: 0.3085 | Val Acc: 91.64% | Sparsity: 93.92%\n",
      "Epoch 19/50 | Train Loss: 0.3211 | Train Acc: 99.09% | Val Loss: 0.2971 | Val Acc: 91.52% | Sparsity: 93.92%\n",
      "Epoch 20/50 | Train Loss: 0.3102 | Train Acc: 99.09% | Val Loss: 0.3182 | Val Acc: 91.35% | Sparsity: 93.92%\n",
      "Epoch 21/50 | Train Loss: 0.3008 | Train Acc: 99.07% | Val Loss: 0.2982 | Val Acc: 91.46% | Sparsity: 93.92%\n",
      "Epoch 22/50 | Train Loss: 0.2941 | Train Acc: 99.19% | Val Loss: 0.3024 | Val Acc: 91.63% | Sparsity: 93.92%\n",
      "Epoch 23/50 | Train Loss: 0.2859 | Train Acc: 99.16% | Val Loss: 0.3005 | Val Acc: 91.58% | Sparsity: 93.92%\n",
      "Early stopping triggered at epoch 23. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 21m 33s\n",
      "Retraining completed in 21.56 minutes (1293.47 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=7.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 91.37%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90% of Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 64.24%\n",
      "Epoch 1/200 | Train Loss: 1.6893 | Train Acc: 36.20%\n",
      "Validation Loss: 1.0352 | Validation Acc: 64.24% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 85.56%\n",
      "Epoch 2/200 | Train Loss: 0.6579 | Train Acc: 77.54%\n",
      "Validation Loss: 0.4411 | Validation Acc: 85.56% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 89.20%\n",
      "Epoch 3/200 | Train Loss: 0.3260 | Train Acc: 89.28%\n",
      "Validation Loss: 0.3294 | Validation Acc: 89.20% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 90.34%\n",
      "Epoch 4/200 | Train Loss: 0.2119 | Train Acc: 92.95%\n",
      "Validation Loss: 0.2968 | Validation Acc: 90.34% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 90.81%\n",
      "Epoch 5/200 | Train Loss: 0.1453 | Train Acc: 95.12%\n",
      "Validation Loss: 0.2869 | Validation Acc: 90.81% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.20%\n",
      "Epoch 6/200 | Train Loss: 0.0993 | Train Acc: 96.77%\n",
      "Validation Loss: 0.2829 | Validation Acc: 91.20% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.32%\n",
      "Epoch 7/200 | Train Loss: 0.0681 | Train Acc: 97.78%\n",
      "Validation Loss: 0.3104 | Validation Acc: 91.32% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 8/200 | Train Loss: 0.0500 | Train Acc: 98.48%\n",
      "Validation Loss: 0.3371 | Validation Acc: 90.72% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 9/200 | Train Loss: 0.0388 | Train Acc: 98.72%\n",
      "Validation Loss: 0.3440 | Validation Acc: 90.89% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 10/200 | Train Loss: 0.0349 | Train Acc: 98.85%\n",
      "Validation Loss: 0.3333 | Validation Acc: 91.26% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 11/200 | Train Loss: 0.0270 | Train Acc: 99.16%\n",
      "Validation Loss: 0.3669 | Validation Acc: 91.19% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.37%\n",
      "Epoch 12/200 | Train Loss: 0.0264 | Train Acc: 99.14%\n",
      "Validation Loss: 0.3434 | Validation Acc: 91.37% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 13/200 | Train Loss: 0.0217 | Train Acc: 99.31%\n",
      "Validation Loss: 0.3679 | Validation Acc: 90.92% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 14/200 | Train Loss: 0.0170 | Train Acc: 99.47%\n",
      "Validation Loss: 0.4312 | Validation Acc: 90.65% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.71%\n",
      "Epoch 15/200 | Train Loss: 0.0174 | Train Acc: 99.42%\n",
      "Validation Loss: 0.3819 | Validation Acc: 91.71% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.89%\n",
      "Epoch 16/200 | Train Loss: 0.0144 | Train Acc: 99.54%\n",
      "Validation Loss: 0.3564 | Validation Acc: 91.89% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 17/200 | Train Loss: 0.0141 | Train Acc: 99.57%\n",
      "Validation Loss: 0.3706 | Validation Acc: 91.72% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 18/200 | Train Loss: 0.0128 | Train Acc: 99.56%\n",
      "Validation Loss: 0.3659 | Validation Acc: 91.56% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 19/200 | Train Loss: 0.0123 | Train Acc: 99.62%\n",
      "Validation Loss: 0.3885 | Validation Acc: 91.47% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 20/200 | Train Loss: 0.0117 | Train Acc: 99.63%\n",
      "Validation Loss: 0.3884 | Validation Acc: 91.54% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.90%\n",
      "Epoch 21/200 | Train Loss: 0.0109 | Train Acc: 99.67%\n",
      "Validation Loss: 0.3710 | Validation Acc: 91.90% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 22/200 | Train Loss: 0.0090 | Train Acc: 99.69%\n",
      "Validation Loss: 0.4053 | Validation Acc: 91.34% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 23/200 | Train Loss: 0.0093 | Train Acc: 99.72%\n",
      "Validation Loss: 0.4382 | Validation Acc: 91.40% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 24/200 | Train Loss: 0.0073 | Train Acc: 99.78%\n",
      "Validation Loss: 0.4034 | Validation Acc: 91.83% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 91.98%\n",
      "Epoch 25/200 | Train Loss: 0.0072 | Train Acc: 99.75%\n",
      "Validation Loss: 0.3744 | Validation Acc: 91.98% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 26/200 | Train Loss: 0.0062 | Train Acc: 99.79%\n",
      "Validation Loss: 0.3917 | Validation Acc: 91.81% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 92.36%\n",
      "Epoch 27/200 | Train Loss: 0.0058 | Train Acc: 99.85%\n",
      "Validation Loss: 0.3734 | Validation Acc: 92.36% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 28/200 | Train Loss: 0.0048 | Train Acc: 99.87%\n",
      "Validation Loss: 0.3856 | Validation Acc: 92.23% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 29/200 | Train Loss: 0.0049 | Train Acc: 99.86%\n",
      "Validation Loss: 0.3993 | Validation Acc: 91.85% | Sparsity: 90.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 92.64%\n",
      "Epoch 30/200 | Train Loss: 0.0042 | Train Acc: 99.87%\n",
      "Validation Loss: 0.3721 | Validation Acc: 92.64% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 31/200 | Train Loss: 0.0041 | Train Acc: 99.86%\n",
      "Validation Loss: 0.3858 | Validation Acc: 92.25% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 32/200 | Train Loss: 0.0038 | Train Acc: 99.89%\n",
      "Validation Loss: 0.3993 | Validation Acc: 92.23% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 33/200 | Train Loss: 0.0043 | Train Acc: 99.87%\n",
      "Validation Loss: 0.4037 | Validation Acc: 92.37% | Sparsity: 90.00%\n",
      "\n",
      "Epoch 34/200 | Train Loss: 0.0047 | Train Acc: 99.83%\n",
      "Validation Loss: 0.4086 | Validation Acc: 92.13% | Sparsity: 90.00%\n",
      "\n",
      "Early stopping triggered at epoch 35. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 92.64% | Best Model Saved at: retrained_student_model.pt\n",
      "Retraining completed in 20.19 minutes (1211.46 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 91.22%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Inference Time: 1.65 ms per batch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pruned_student_inference_time = measure_inference_time(retrained_student, test_loader,)\n",
    "print(f\"Pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrained with KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy: 95.29%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 4.7247 | Train Acc: 58.00% | Val Loss: 0.6383 | Val Acc: 82.47% | Sparsity: 90.00%\n",
      "Epoch 2/50 | Train Loss: 1.5648 | Train Acc: 88.30% | Val Loss: 0.3718 | Val Acc: 89.63% | Sparsity: 90.00%\n",
      "Epoch 3/50 | Train Loss: 1.0694 | Train Acc: 92.52% | Val Loss: 0.4017 | Val Acc: 89.29% | Sparsity: 90.00%\n",
      "Epoch 4/50 | Train Loss: 0.8279 | Train Acc: 94.85% | Val Loss: 0.3302 | Val Acc: 91.30% | Sparsity: 90.00%\n",
      "Epoch 5/50 | Train Loss: 0.6732 | Train Acc: 96.28% | Val Loss: 0.2834 | Val Acc: 91.88% | Sparsity: 90.00%\n",
      "Epoch 6/50 | Train Loss: 0.5648 | Train Acc: 97.31% | Val Loss: 0.2586 | Val Acc: 92.78% | Sparsity: 90.00%\n",
      "Epoch 7/50 | Train Loss: 0.4823 | Train Acc: 98.03% | Val Loss: 0.2369 | Val Acc: 93.30% | Sparsity: 90.00%\n",
      "Epoch 8/50 | Train Loss: 0.4202 | Train Acc: 98.40% | Val Loss: 0.2305 | Val Acc: 93.51% | Sparsity: 90.00%\n",
      "Epoch 9/50 | Train Loss: 0.3819 | Train Acc: 98.75% | Val Loss: 0.2173 | Val Acc: 93.52% | Sparsity: 90.00%\n",
      "Epoch 10/50 | Train Loss: 0.3510 | Train Acc: 98.88% | Val Loss: 0.2261 | Val Acc: 93.54% | Sparsity: 90.00%\n",
      "Epoch 11/50 | Train Loss: 0.3219 | Train Acc: 98.96% | Val Loss: 0.2241 | Val Acc: 93.43% | Sparsity: 90.00%\n",
      "Epoch 12/50 | Train Loss: 0.3090 | Train Acc: 99.01% | Val Loss: 0.2192 | Val Acc: 93.85% | Sparsity: 90.00%\n",
      "Epoch 13/50 | Train Loss: 0.2808 | Train Acc: 99.13% | Val Loss: 0.2027 | Val Acc: 94.17% | Sparsity: 90.00%\n",
      "Epoch 14/50 | Train Loss: 0.2634 | Train Acc: 99.11% | Val Loss: 0.2156 | Val Acc: 93.51% | Sparsity: 90.00%\n",
      "Epoch 15/50 | Train Loss: 0.2511 | Train Acc: 99.22% | Val Loss: 0.2026 | Val Acc: 93.97% | Sparsity: 90.00%\n",
      "Epoch 16/50 | Train Loss: 0.2446 | Train Acc: 99.22% | Val Loss: 0.2096 | Val Acc: 93.90% | Sparsity: 90.00%\n",
      "Epoch 17/50 | Train Loss: 0.2375 | Train Acc: 99.28% | Val Loss: 0.2159 | Val Acc: 93.80% | Sparsity: 90.00%\n",
      "Epoch 18/50 | Train Loss: 0.2294 | Train Acc: 99.21% | Val Loss: 0.2222 | Val Acc: 93.62% | Sparsity: 90.00%\n",
      "Epoch 19/50 | Train Loss: 0.2190 | Train Acc: 99.24% | Val Loss: 0.2138 | Val Acc: 93.66% | Sparsity: 90.00%\n",
      "Epoch 20/50 | Train Loss: 0.2068 | Train Acc: 99.24% | Val Loss: 0.2152 | Val Acc: 93.66% | Sparsity: 90.00%\n",
      "Early stopping triggered at epoch 20. No improvement for 7 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 18m 37s\n",
      "Retraining completed in 18.62 minutes (1116.91 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 92.65%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 33s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 4.0696 | Train Acc: 61.09% | Val Loss: 0.4792 | Val Acc: 85.92% | Sparsity: 90.00%\n",
      "Epoch 2/50 | Train Loss: 1.3172 | Train Acc: 89.75% | Val Loss: 0.4438 | Val Acc: 87.99% | Sparsity: 90.00%\n",
      "Epoch 3/50 | Train Loss: 0.9349 | Train Acc: 93.31% | Val Loss: 0.3550 | Val Acc: 89.55% | Sparsity: 90.00%\n",
      "Epoch 4/50 | Train Loss: 0.7432 | Train Acc: 95.40% | Val Loss: 0.2599 | Val Acc: 92.43% | Sparsity: 90.00%\n",
      "Epoch 5/50 | Train Loss: 0.5919 | Train Acc: 96.84% | Val Loss: 0.2599 | Val Acc: 92.61% | Sparsity: 90.00%\n",
      "Epoch 6/50 | Train Loss: 0.5124 | Train Acc: 97.75% | Val Loss: 0.2281 | Val Acc: 93.56% | Sparsity: 90.00%\n",
      "Epoch 7/50 | Train Loss: 0.4535 | Train Acc: 98.16% | Val Loss: 0.2356 | Val Acc: 93.19% | Sparsity: 90.00%\n",
      "Epoch 8/50 | Train Loss: 0.4020 | Train Acc: 98.60% | Val Loss: 0.2371 | Val Acc: 92.98% | Sparsity: 90.00%\n",
      "Epoch 9/50 | Train Loss: 0.3615 | Train Acc: 98.87% | Val Loss: 0.2121 | Val Acc: 93.79% | Sparsity: 90.00%\n",
      "Epoch 10/50 | Train Loss: 0.3394 | Train Acc: 98.97% | Val Loss: 0.2100 | Val Acc: 93.68% | Sparsity: 90.00%\n",
      "Epoch 11/50 | Train Loss: 0.3062 | Train Acc: 99.06% | Val Loss: 0.2105 | Val Acc: 94.05% | Sparsity: 90.00%\n",
      "Epoch 12/50 | Train Loss: 0.3040 | Train Acc: 99.16% | Val Loss: 0.2149 | Val Acc: 93.67% | Sparsity: 90.00%\n",
      "Epoch 13/50 | Train Loss: 0.2807 | Train Acc: 99.19% | Val Loss: 0.2061 | Val Acc: 93.61% | Sparsity: 90.00%\n",
      "Epoch 14/50 | Train Loss: 0.2697 | Train Acc: 99.12% | Val Loss: 0.2005 | Val Acc: 94.03% | Sparsity: 90.00%\n",
      "Epoch 15/50 | Train Loss: 0.2636 | Train Acc: 99.21% | Val Loss: 0.1982 | Val Acc: 94.09% | Sparsity: 90.00%\n",
      "Epoch 16/50 | Train Loss: 0.2493 | Train Acc: 99.24% | Val Loss: 0.2015 | Val Acc: 93.71% | Sparsity: 90.00%\n",
      "Epoch 17/50 | Train Loss: 0.2349 | Train Acc: 99.26% | Val Loss: 0.1898 | Val Acc: 94.05% | Sparsity: 90.00%\n",
      "Epoch 18/50 | Train Loss: 0.2240 | Train Acc: 99.24% | Val Loss: 0.1991 | Val Acc: 93.96% | Sparsity: 90.00%\n",
      "Epoch 19/50 | Train Loss: 0.2214 | Train Acc: 99.30% | Val Loss: 0.2087 | Val Acc: 93.67% | Sparsity: 90.00%\n",
      "Epoch 20/50 | Train Loss: 0.2137 | Train Acc: 99.33% | Val Loss: 0.1896 | Val Acc: 94.24% | Sparsity: 90.00%\n",
      "Epoch 21/50 | Train Loss: 0.1976 | Train Acc: 99.36% | Val Loss: 0.1954 | Val Acc: 94.01% | Sparsity: 90.00%\n",
      "Epoch 22/50 | Train Loss: 0.2006 | Train Acc: 99.28% | Val Loss: 0.1957 | Val Acc: 93.95% | Sparsity: 90.00%\n",
      "Epoch 23/50 | Train Loss: 0.1931 | Train Acc: 99.36% | Val Loss: 0.1941 | Val Acc: 94.12% | Sparsity: 90.00%\n",
      "Epoch 24/50 | Train Loss: 0.1845 | Train Acc: 99.39% | Val Loss: 0.1879 | Val Acc: 94.14% | Sparsity: 90.00%\n",
      "Epoch 25/50 | Train Loss: 0.1758 | Train Acc: 99.39% | Val Loss: 0.1933 | Val Acc: 94.00% | Sparsity: 90.00%\n",
      "Epoch 26/50 | Train Loss: 0.1767 | Train Acc: 99.31% | Val Loss: 0.1958 | Val Acc: 94.06% | Sparsity: 90.00%\n",
      "Epoch 27/50 | Train Loss: 0.1808 | Train Acc: 99.31% | Val Loss: 0.2006 | Val Acc: 93.92% | Sparsity: 90.00%\n",
      "Early stopping triggered at epoch 27. No improvement for 7 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 25m 12s\n",
      "Retraining completed in 25.19 minutes (1511.63 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=7.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 93.05%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 10.00%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 93.86%\n",
      "Epoch 1/100 | Train Loss: 0.4171 | Train Acc: 86.99%\n",
      "Validation Loss: 0.1858 | Validation Acc: 93.86% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 94.57%\n",
      "Epoch 2/100 | Train Loss: 0.1117 | Train Acc: 96.42%\n",
      "Validation Loss: 0.1717 | Validation Acc: 94.57% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 95.18%\n",
      "Epoch 3/100 | Train Loss: 0.0552 | Train Acc: 98.25%\n",
      "Validation Loss: 0.1580 | Validation Acc: 95.18% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 95.54%\n",
      "Epoch 4/100 | Train Loss: 0.0304 | Train Acc: 99.11%\n",
      "Validation Loss: 0.1562 | Validation Acc: 95.54% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 5/100 | Train Loss: 0.0181 | Train Acc: 99.49%\n",
      "Validation Loss: 0.1795 | Validation Acc: 95.16% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 6/100 | Train Loss: 0.0134 | Train Acc: 99.59%\n",
      "Validation Loss: 0.1889 | Validation Acc: 94.91% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 7/100 | Train Loss: 0.0105 | Train Acc: 99.72%\n",
      "Validation Loss: 0.1887 | Validation Acc: 95.19% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.0083 | Train Acc: 99.75%\n",
      "Validation Loss: 0.1939 | Validation Acc: 95.46% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 95.55%\n",
      "Epoch 9/100 | Train Loss: 0.0082 | Train Acc: 99.78%\n",
      "Validation Loss: 0.1935 | Validation Acc: 95.55% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 10/100 | Train Loss: 0.0046 | Train Acc: 99.89%\n",
      "Validation Loss: 0.1854 | Validation Acc: 95.55% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 95.85%\n",
      "Epoch 11/100 | Train Loss: 0.0035 | Train Acc: 99.92%\n",
      "Validation Loss: 0.1905 | Validation Acc: 95.85% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 12/100 | Train Loss: 0.0033 | Train Acc: 99.91%\n",
      "Validation Loss: 0.1884 | Validation Acc: 95.62% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 95.87%\n",
      "Epoch 13/100 | Train Loss: 0.0033 | Train Acc: 99.91%\n",
      "Validation Loss: 0.1882 | Validation Acc: 95.87% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 14/100 | Train Loss: 0.0015 | Train Acc: 99.97%\n",
      "Validation Loss: 0.1903 | Validation Acc: 95.80% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.05%\n",
      "Epoch 15/100 | Train Loss: 0.0015 | Train Acc: 99.96%\n",
      "Validation Loss: 0.1807 | Validation Acc: 96.05% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 16/100 | Train Loss: 0.0016 | Train Acc: 99.95%\n",
      "Validation Loss: 0.1996 | Validation Acc: 95.62% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 17/100 | Train Loss: 0.0013 | Train Acc: 99.98%\n",
      "Validation Loss: 0.1948 | Validation Acc: 95.92% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 18/100 | Train Loss: 0.0009 | Train Acc: 99.97%\n",
      "Validation Loss: 0.1927 | Validation Acc: 95.82% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 19/100 | Train Loss: 0.0009 | Train Acc: 99.98%\n",
      "Validation Loss: 0.1906 | Validation Acc: 95.88% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.09%\n",
      "Epoch 20/100 | Train Loss: 0.0008 | Train Acc: 99.98%\n",
      "Validation Loss: 0.1832 | Validation Acc: 96.09% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 21/100 | Train Loss: 0.0010 | Train Acc: 99.97%\n",
      "Validation Loss: 0.1885 | Validation Acc: 95.93% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.10%\n",
      "Epoch 22/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1857 | Validation Acc: 96.10% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 23/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1829 | Validation Acc: 96.07% | Sparsity: 80.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.34%\n",
      "Epoch 24/100 | Train Loss: 0.0005 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1825 | Validation Acc: 96.34% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 25/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1847 | Validation Acc: 96.13% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 26/100 | Train Loss: 0.0004 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1993 | Validation Acc: 95.97% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 27/100 | Train Loss: 0.0004 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1983 | Validation Acc: 95.76% | Sparsity: 80.00%\n",
      "\n",
      "Epoch 28/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1925 | Validation Acc: 96.09% | Sparsity: 80.00%\n",
      "\n",
      "Early stopping triggered at epoch 29. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 96.34% | Best Model Saved at: retrained_student_model_80.pt\n",
      "Retraining completed in 16.64 minutes (998.40 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_80.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain without KD): 93.90%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain without KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure inference times\n",
    "pruned_student_inference_time = measure_inference_time(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Inference Time(After Pruning): {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.6337 | Train Acc: 88.75% | Val Loss: 0.2158 | Val Acc: 93.18% | Sparsity: 80.00%\n",
      "Epoch 2/50 | Train Loss: 0.7188 | Train Acc: 95.72% | Val Loss: 0.2001 | Val Acc: 93.75% | Sparsity: 80.00%\n",
      "Epoch 3/50 | Train Loss: 0.5160 | Train Acc: 97.69% | Val Loss: 0.2020 | Val Acc: 93.92% | Sparsity: 80.00%\n",
      "Epoch 4/50 | Train Loss: 0.4023 | Train Acc: 98.49% | Val Loss: 0.1446 | Val Acc: 95.57% | Sparsity: 80.00%\n",
      "Epoch 5/50 | Train Loss: 0.3328 | Train Acc: 98.89% | Val Loss: 0.1401 | Val Acc: 95.53% | Sparsity: 80.00%\n",
      "Epoch 6/50 | Train Loss: 0.2912 | Train Acc: 99.08% | Val Loss: 0.1239 | Val Acc: 96.09% | Sparsity: 80.00%\n",
      "Epoch 7/50 | Train Loss: 0.2643 | Train Acc: 99.16% | Val Loss: 0.1180 | Val Acc: 96.33% | Sparsity: 80.00%\n",
      "Epoch 8/50 | Train Loss: 0.2411 | Train Acc: 99.17% | Val Loss: 0.1250 | Val Acc: 95.94% | Sparsity: 80.00%\n",
      "Epoch 9/50 | Train Loss: 0.2202 | Train Acc: 99.27% | Val Loss: 0.1248 | Val Acc: 95.98% | Sparsity: 80.00%\n",
      "Epoch 10/50 | Train Loss: 0.2089 | Train Acc: 99.34% | Val Loss: 0.1199 | Val Acc: 96.22% | Sparsity: 80.00%\n",
      "Epoch 11/50 | Train Loss: 0.1884 | Train Acc: 99.27% | Val Loss: 0.1194 | Val Acc: 96.06% | Sparsity: 80.00%\n",
      "Epoch 12/50 | Train Loss: 0.1768 | Train Acc: 99.35% | Val Loss: 0.1172 | Val Acc: 96.17% | Sparsity: 80.00%\n",
      "Early stopping triggered at epoch 12. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 11m 13s\n",
      "Retraining completed in 11.22 minutes (673.16 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 94.32%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.4604 | Train Acc: 89.33% | Val Loss: 0.2326 | Val Acc: 92.67% | Sparsity: 80.00%\n",
      "Epoch 2/50 | Train Loss: 0.6872 | Train Acc: 95.98% | Val Loss: 0.1875 | Val Acc: 94.08% | Sparsity: 80.00%\n",
      "Epoch 3/50 | Train Loss: 0.5078 | Train Acc: 97.77% | Val Loss: 0.1284 | Val Acc: 95.96% | Sparsity: 80.00%\n",
      "Epoch 4/50 | Train Loss: 0.4008 | Train Acc: 98.52% | Val Loss: 0.1405 | Val Acc: 95.60% | Sparsity: 80.00%\n",
      "Epoch 5/50 | Train Loss: 0.3291 | Train Acc: 99.02% | Val Loss: 0.1340 | Val Acc: 95.76% | Sparsity: 80.00%\n",
      "Epoch 6/50 | Train Loss: 0.2938 | Train Acc: 99.08% | Val Loss: 0.1273 | Val Acc: 96.04% | Sparsity: 80.00%\n",
      "Epoch 7/50 | Train Loss: 0.2672 | Train Acc: 99.22% | Val Loss: 0.1228 | Val Acc: 96.14% | Sparsity: 80.00%\n",
      "Epoch 8/50 | Train Loss: 0.2415 | Train Acc: 99.28% | Val Loss: 0.1283 | Val Acc: 96.05% | Sparsity: 80.00%\n",
      "Epoch 9/50 | Train Loss: 0.2327 | Train Acc: 99.26% | Val Loss: 0.1121 | Val Acc: 96.57% | Sparsity: 80.00%\n",
      "Epoch 10/50 | Train Loss: 0.2104 | Train Acc: 99.31% | Val Loss: 0.1105 | Val Acc: 96.48% | Sparsity: 80.00%\n",
      "Epoch 11/50 | Train Loss: 0.2008 | Train Acc: 99.38% | Val Loss: 0.1159 | Val Acc: 96.35% | Sparsity: 80.00%\n",
      "Epoch 12/50 | Train Loss: 0.1913 | Train Acc: 99.33% | Val Loss: 0.1110 | Val Acc: 96.34% | Sparsity: 80.00%\n",
      "Epoch 13/50 | Train Loss: 0.1844 | Train Acc: 99.38% | Val Loss: 0.1175 | Val Acc: 96.35% | Sparsity: 80.00%\n",
      "Epoch 14/50 | Train Loss: 0.1775 | Train Acc: 99.40% | Val Loss: 0.1134 | Val Acc: 96.35% | Sparsity: 80.00%\n",
      "Early stopping triggered at epoch 14. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 12m 59s\n",
      "Retraining completed in 12.98 minutes (778.56 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=7.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 94.24%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75% of Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 10.00%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 95.98%\n",
      "Epoch 1/100 | Train Loss: 0.2448 | Train Acc: 92.87%\n",
      "Validation Loss: 0.1245 | Validation Acc: 95.98% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 2/100 | Train Loss: 0.0720 | Train Acc: 97.82%\n",
      "Validation Loss: 0.1296 | Validation Acc: 95.81% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.04%\n",
      "Epoch 3/100 | Train Loss: 0.0297 | Train Acc: 99.14%\n",
      "Validation Loss: 0.1348 | Validation Acc: 96.04% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.16%\n",
      "Epoch 4/100 | Train Loss: 0.0174 | Train Acc: 99.48%\n",
      "Validation Loss: 0.1330 | Validation Acc: 96.16% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.26%\n",
      "Epoch 5/100 | Train Loss: 0.0109 | Train Acc: 99.74%\n",
      "Validation Loss: 0.1487 | Validation Acc: 96.26% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.62%\n",
      "Epoch 6/100 | Train Loss: 0.0060 | Train Acc: 99.84%\n",
      "Validation Loss: 0.1332 | Validation Acc: 96.62% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 7/100 | Train Loss: 0.0043 | Train Acc: 99.91%\n",
      "Validation Loss: 0.1456 | Validation Acc: 96.28% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.0031 | Train Acc: 99.93%\n",
      "Validation Loss: 0.1347 | Validation Acc: 96.42% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 9/100 | Train Loss: 0.0033 | Train Acc: 99.92%\n",
      "Validation Loss: 0.1411 | Validation Acc: 96.50% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.80%\n",
      "Epoch 10/100 | Train Loss: 0.0024 | Train Acc: 99.94%\n",
      "Validation Loss: 0.1357 | Validation Acc: 96.80% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 11/100 | Train Loss: 0.0013 | Train Acc: 99.97%\n",
      "Validation Loss: 0.1471 | Validation Acc: 96.42% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 12/100 | Train Loss: 0.0010 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1371 | Validation Acc: 96.68% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 13/100 | Train Loss: 0.0008 | Train Acc: 99.98%\n",
      "Validation Loss: 0.1447 | Validation Acc: 96.64% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 14/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1372 | Validation Acc: 96.62% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.82%\n",
      "Epoch 15/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1341 | Validation Acc: 96.82% | Sparsity: 75.00%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.88%\n",
      "Epoch 16/100 | Train Loss: 0.0004 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1355 | Validation Acc: 96.88% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 17/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1353 | Validation Acc: 96.85% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 18/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1352 | Validation Acc: 96.87% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 19/100 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1366 | Validation Acc: 96.75% | Sparsity: 75.00%\n",
      "\n",
      "Epoch 20/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1351 | Validation Acc: 96.88% | Sparsity: 75.00%\n",
      "\n",
      "Early stopping triggered at epoch 21. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 96.88% | Best Model Saved at: retrained_student_model_75.pt\n",
      "Retraining completed in 12.20 minutes (731.89 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_75.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.34%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained pruned Student Model Inference Time: 1.70 ms per batch\n"
     ]
    }
   ],
   "source": [
    "# Measure inference times\n",
    "pruned_student_inference_time = measure_inference_time(retrained_student, test_loader,)\n",
    "print(f\" Retrained pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain with KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 33s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.2571 | Train Acc: 92.11% | Val Loss: 0.1841 | Val Acc: 94.36% | Sparsity: 75.00%\n",
      "Epoch 2/50 | Train Loss: 0.6186 | Train Acc: 96.75% | Val Loss: 0.1615 | Val Acc: 95.17% | Sparsity: 75.00%\n",
      "Epoch 3/50 | Train Loss: 0.4222 | Train Acc: 98.38% | Val Loss: 0.1287 | Val Acc: 96.00% | Sparsity: 75.00%\n",
      "Epoch 4/50 | Train Loss: 0.3290 | Train Acc: 98.94% | Val Loss: 0.1075 | Val Acc: 96.67% | Sparsity: 75.00%\n",
      "Epoch 5/50 | Train Loss: 0.2901 | Train Acc: 99.15% | Val Loss: 0.1116 | Val Acc: 96.43% | Sparsity: 75.00%\n",
      "Epoch 6/50 | Train Loss: 0.2570 | Train Acc: 99.19% | Val Loss: 0.1011 | Val Acc: 96.80% | Sparsity: 75.00%\n",
      "Epoch 7/50 | Train Loss: 0.2257 | Train Acc: 99.25% | Val Loss: 0.1003 | Val Acc: 96.63% | Sparsity: 75.00%\n",
      "Epoch 8/50 | Train Loss: 0.2045 | Train Acc: 99.31% | Val Loss: 0.0960 | Val Acc: 96.78% | Sparsity: 75.00%\n",
      "Epoch 9/50 | Train Loss: 0.1923 | Train Acc: 99.27% | Val Loss: 0.0947 | Val Acc: 96.90% | Sparsity: 75.00%\n",
      "Epoch 10/50 | Train Loss: 0.1788 | Train Acc: 99.30% | Val Loss: 0.0902 | Val Acc: 97.02% | Sparsity: 75.00%\n",
      "Epoch 11/50 | Train Loss: 0.1757 | Train Acc: 99.37% | Val Loss: 0.0970 | Val Acc: 96.81% | Sparsity: 75.00%\n",
      "Epoch 12/50 | Train Loss: 0.1597 | Train Acc: 99.32% | Val Loss: 0.0940 | Val Acc: 96.79% | Sparsity: 75.00%\n",
      "Epoch 13/50 | Train Loss: 0.1505 | Train Acc: 99.41% | Val Loss: 0.0924 | Val Acc: 96.96% | Sparsity: 75.00%\n",
      "Epoch 14/50 | Train Loss: 0.1498 | Train Acc: 99.36% | Val Loss: 0.0932 | Val Acc: 96.87% | Sparsity: 75.00%\n",
      "Epoch 15/50 | Train Loss: 0.1470 | Train Acc: 99.35% | Val Loss: 0.0983 | Val Acc: 96.67% | Sparsity: 75.00%\n",
      "Early stopping triggered at epoch 15. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 14m 8s\n",
      "Retraining completed in 14.13 minutes (847.80 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.88%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained pruned Student Model Inference Time: 2.00 ms per batch\n"
     ]
    }
   ],
   "source": [
    "# Measure inference times\n",
    "pruned_student_inference_time = measure_inference_time(pruned_student, test_loader, device)\n",
    "print(f\" Retrained pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.2503 | Train Acc: 92.19% | Val Loss: 0.1845 | Val Acc: 94.03% | Sparsity: 75.00%\n",
      "Epoch 2/50 | Train Loss: 0.6055 | Train Acc: 96.87% | Val Loss: 0.1313 | Val Acc: 95.95% | Sparsity: 75.00%\n",
      "Epoch 3/50 | Train Loss: 0.4348 | Train Acc: 98.31% | Val Loss: 0.1207 | Val Acc: 96.15% | Sparsity: 75.00%\n",
      "Epoch 4/50 | Train Loss: 0.3382 | Train Acc: 98.85% | Val Loss: 0.1063 | Val Acc: 96.59% | Sparsity: 75.00%\n",
      "Epoch 5/50 | Train Loss: 0.2738 | Train Acc: 99.18% | Val Loss: 0.1029 | Val Acc: 96.71% | Sparsity: 75.00%\n",
      "Epoch 6/50 | Train Loss: 0.2436 | Train Acc: 99.23% | Val Loss: 0.1030 | Val Acc: 96.72% | Sparsity: 75.00%\n",
      "Epoch 7/50 | Train Loss: 0.2246 | Train Acc: 99.23% | Val Loss: 0.0994 | Val Acc: 96.76% | Sparsity: 75.00%\n",
      "Epoch 8/50 | Train Loss: 0.2069 | Train Acc: 99.28% | Val Loss: 0.0974 | Val Acc: 96.78% | Sparsity: 75.00%\n",
      "Epoch 9/50 | Train Loss: 0.1932 | Train Acc: 99.31% | Val Loss: 0.0950 | Val Acc: 96.84% | Sparsity: 75.00%\n",
      "Epoch 10/50 | Train Loss: 0.1856 | Train Acc: 99.32% | Val Loss: 0.0945 | Val Acc: 96.91% | Sparsity: 75.00%\n",
      "Epoch 11/50 | Train Loss: 0.1709 | Train Acc: 99.35% | Val Loss: 0.0939 | Val Acc: 96.99% | Sparsity: 75.00%\n",
      "Epoch 12/50 | Train Loss: 0.1636 | Train Acc: 99.36% | Val Loss: 0.0905 | Val Acc: 96.89% | Sparsity: 75.00%\n",
      "Epoch 13/50 | Train Loss: 0.1507 | Train Acc: 99.33% | Val Loss: 0.0946 | Val Acc: 96.82% | Sparsity: 75.00%\n",
      "Epoch 14/50 | Train Loss: 0.1453 | Train Acc: 99.37% | Val Loss: 0.0898 | Val Acc: 97.18% | Sparsity: 75.00%\n",
      "Epoch 15/50 | Train Loss: 0.1400 | Train Acc: 99.35% | Val Loss: 0.0894 | Val Acc: 97.01% | Sparsity: 75.00%\n",
      "Epoch 16/50 | Train Loss: 0.1373 | Train Acc: 99.34% | Val Loss: 0.0917 | Val Acc: 96.94% | Sparsity: 75.00%\n",
      "Epoch 17/50 | Train Loss: 0.1277 | Train Acc: 99.41% | Val Loss: 0.0910 | Val Acc: 96.98% | Sparsity: 75.00%\n",
      "Epoch 18/50 | Train Loss: 0.1293 | Train Acc: 99.40% | Val Loss: 0.0994 | Val Acc: 96.70% | Sparsity: 75.00%\n",
      "Epoch 19/50 | Train Loss: 0.1210 | Train Acc: 99.40% | Val Loss: 0.0913 | Val Acc: 97.03% | Sparsity: 75.00%\n",
      "Early stopping triggered at epoch 19. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 17m 47s\n",
      "Retraining completed in 17.78 minutes (1066.68 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.87%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.707)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 97.11%\n",
      "Epoch 1/100 | Train Loss: 0.1764 | Train Acc: 95.05%\n",
      "Validation Loss: 0.0948 | Validation Acc: 97.11% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 2/100 | Train Loss: 0.0499 | Train Acc: 98.53%\n",
      "Validation Loss: 0.0942 | Validation Acc: 96.98% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 3/100 | Train Loss: 0.0213 | Train Acc: 99.38%\n",
      "Validation Loss: 0.0966 | Validation Acc: 97.10% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 4/100 | Train Loss: 0.0098 | Train Acc: 99.77%\n",
      "Validation Loss: 0.1005 | Validation Acc: 97.07% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.30%\n",
      "Epoch 5/100 | Train Loss: 0.0059 | Train Acc: 99.86%\n",
      "Validation Loss: 0.0997 | Validation Acc: 97.30% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 6/100 | Train Loss: 0.0040 | Train Acc: 99.93%\n",
      "Validation Loss: 0.1014 | Validation Acc: 97.24% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.52%\n",
      "Epoch 7/100 | Train Loss: 0.0022 | Train Acc: 99.95%\n",
      "Validation Loss: 0.0983 | Validation Acc: 97.52% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.0022 | Train Acc: 99.95%\n",
      "Validation Loss: 0.1028 | Validation Acc: 97.45% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 9/100 | Train Loss: 0.0011 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1036 | Validation Acc: 97.48% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.56%\n",
      "Epoch 10/100 | Train Loss: 0.0008 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1004 | Validation Acc: 97.56% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 11/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1040 | Validation Acc: 97.48% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.57%\n",
      "Epoch 12/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1005 | Validation Acc: 97.57% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.67%\n",
      "Epoch 13/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0986 | Validation Acc: 97.67% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 14/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0970 | Validation Acc: 97.67% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.70%\n",
      "Epoch 15/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1000 | Validation Acc: 97.70% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 16/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1034 | Validation Acc: 97.53% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 17/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0975 | Validation Acc: 97.65% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.75%\n",
      "Epoch 18/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0996 | Validation Acc: 97.75% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 19/100 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0989 | Validation Acc: 97.66% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 20/100 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1004 | Validation Acc: 97.56% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 21/100 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0976 | Validation Acc: 97.64% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 22/100 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0964 | Validation Acc: 97.72% | Sparsity: 70.64%\n",
      "\n",
      "Early stopping triggered at epoch 23. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 97.75% | Best Model Saved at: retrained_student_model_70.pt\n",
      "Retraining completed in 13.00 minutes (780.00 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_70.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.50%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.707)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.0910 | Train Acc: 93.56% | Val Loss: 0.1450 | Val Acc: 95.20% | Sparsity: 70.64%\n",
      "Epoch 2/50 | Train Loss: 0.5123 | Train Acc: 97.60% | Val Loss: 0.1085 | Val Acc: 96.44% | Sparsity: 70.64%\n",
      "Epoch 3/50 | Train Loss: 0.3669 | Train Acc: 98.78% | Val Loss: 0.0849 | Val Acc: 97.13% | Sparsity: 70.64%\n",
      "Epoch 4/50 | Train Loss: 0.3024 | Train Acc: 99.02% | Val Loss: 0.0796 | Val Acc: 97.33% | Sparsity: 70.64%\n",
      "Epoch 5/50 | Train Loss: 0.2597 | Train Acc: 99.14% | Val Loss: 0.0833 | Val Acc: 97.18% | Sparsity: 70.64%\n",
      "Epoch 6/50 | Train Loss: 0.2337 | Train Acc: 99.21% | Val Loss: 0.0789 | Val Acc: 97.41% | Sparsity: 70.64%\n",
      "Epoch 7/50 | Train Loss: 0.2085 | Train Acc: 99.25% | Val Loss: 0.0813 | Val Acc: 97.32% | Sparsity: 70.64%\n",
      "Epoch 8/50 | Train Loss: 0.1980 | Train Acc: 99.32% | Val Loss: 0.0790 | Val Acc: 97.42% | Sparsity: 70.64%\n",
      "Epoch 9/50 | Train Loss: 0.1770 | Train Acc: 99.35% | Val Loss: 0.0784 | Val Acc: 97.42% | Sparsity: 70.64%\n",
      "Epoch 10/50 | Train Loss: 0.1726 | Train Acc: 99.34% | Val Loss: 0.0763 | Val Acc: 97.52% | Sparsity: 70.64%\n",
      "Epoch 11/50 | Train Loss: 0.1640 | Train Acc: 99.38% | Val Loss: 0.0763 | Val Acc: 97.47% | Sparsity: 70.64%\n",
      "Epoch 12/50 | Train Loss: 0.1493 | Train Acc: 99.36% | Val Loss: 0.0780 | Val Acc: 97.33% | Sparsity: 70.64%\n",
      "Epoch 13/50 | Train Loss: 0.1444 | Train Acc: 99.34% | Val Loss: 0.0748 | Val Acc: 97.55% | Sparsity: 70.64%\n",
      "Epoch 14/50 | Train Loss: 0.1393 | Train Acc: 99.45% | Val Loss: 0.0751 | Val Acc: 97.42% | Sparsity: 70.64%\n",
      "Epoch 15/50 | Train Loss: 0.1342 | Train Acc: 99.33% | Val Loss: 0.0783 | Val Acc: 97.38% | Sparsity: 70.64%\n",
      "Epoch 16/50 | Train Loss: 0.1293 | Train Acc: 99.41% | Val Loss: 0.0737 | Val Acc: 97.49% | Sparsity: 70.64%\n",
      "Epoch 17/50 | Train Loss: 0.1231 | Train Acc: 99.37% | Val Loss: 0.0776 | Val Acc: 97.22% | Sparsity: 70.64%\n",
      "Epoch 18/50 | Train Loss: 0.1219 | Train Acc: 99.41% | Val Loss: 0.0788 | Val Acc: 97.41% | Sparsity: 70.64%\n",
      "Early stopping triggered at epoch 18. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 16m 53s\n",
      "Retraining completed in 16.89 minutes (1013.43 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.97%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained pruned Student Model Inference Time: 1.76 ms per batch\n"
     ]
    }
   ],
   "source": [
    "# Measure inference times\n",
    "pruned_student_inference_time = measure_inference_time(pruned_student, test_loader, device)\n",
    "print(f\" Retrained pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 34s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.707)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.0044 | Train Acc: 94.14% | Val Loss: 0.1237 | Val Acc: 95.91% | Sparsity: 70.64%\n",
      "Epoch 2/50 | Train Loss: 0.4977 | Train Acc: 97.69% | Val Loss: 0.1097 | Val Acc: 96.42% | Sparsity: 70.64%\n",
      "Epoch 3/50 | Train Loss: 0.3688 | Train Acc: 98.74% | Val Loss: 0.1008 | Val Acc: 96.78% | Sparsity: 70.64%\n",
      "Epoch 4/50 | Train Loss: 0.3090 | Train Acc: 99.07% | Val Loss: 0.1140 | Val Acc: 96.32% | Sparsity: 70.64%\n",
      "Epoch 5/50 | Train Loss: 0.2698 | Train Acc: 99.28% | Val Loss: 0.1038 | Val Acc: 96.51% | Sparsity: 70.64%\n",
      "Epoch 6/50 | Train Loss: 0.2382 | Train Acc: 99.33% | Val Loss: 0.0738 | Val Acc: 97.60% | Sparsity: 70.64%\n",
      "Epoch 7/50 | Train Loss: 0.2095 | Train Acc: 99.30% | Val Loss: 0.0761 | Val Acc: 97.49% | Sparsity: 70.64%\n",
      "Epoch 8/50 | Train Loss: 0.2025 | Train Acc: 99.38% | Val Loss: 0.0715 | Val Acc: 97.57% | Sparsity: 70.64%\n",
      "Epoch 9/50 | Train Loss: 0.1876 | Train Acc: 99.31% | Val Loss: 0.0874 | Val Acc: 96.95% | Sparsity: 70.64%\n",
      "Epoch 10/50 | Train Loss: 0.1675 | Train Acc: 99.39% | Val Loss: 0.0736 | Val Acc: 97.59% | Sparsity: 70.64%\n",
      "Epoch 11/50 | Train Loss: 0.1672 | Train Acc: 99.39% | Val Loss: 0.0771 | Val Acc: 97.37% | Sparsity: 70.64%\n",
      "Early stopping triggered at epoch 11. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 10m 12s\n",
      "Retraining completed in 10.20 minutes (612.21 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=7.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.88%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.707)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 10.00%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 96.62%\n",
      "Epoch 1/200 | Train Loss: 0.1792 | Train Acc: 94.97%\n",
      "Validation Loss: 0.1015 | Validation Acc: 96.62% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 96.72%\n",
      "Epoch 2/200 | Train Loss: 0.0501 | Train Acc: 98.45%\n",
      "Validation Loss: 0.0983 | Validation Acc: 96.72% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 3/200 | Train Loss: 0.0211 | Train Acc: 99.43%\n",
      "Validation Loss: 0.1106 | Validation Acc: 96.65% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.11%\n",
      "Epoch 4/200 | Train Loss: 0.0102 | Train Acc: 99.75%\n",
      "Validation Loss: 0.1053 | Validation Acc: 97.11% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 5/200 | Train Loss: 0.0064 | Train Acc: 99.84%\n",
      "Validation Loss: 0.1090 | Validation Acc: 96.89% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.25%\n",
      "Epoch 6/200 | Train Loss: 0.0044 | Train Acc: 99.91%\n",
      "Validation Loss: 0.0977 | Validation Acc: 97.25% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 7/200 | Train Loss: 0.0030 | Train Acc: 99.94%\n",
      "Validation Loss: 0.0964 | Validation Acc: 97.22% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.41%\n",
      "Epoch 8/200 | Train Loss: 0.0019 | Train Acc: 99.97%\n",
      "Validation Loss: 0.0999 | Validation Acc: 97.41% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 9/200 | Train Loss: 0.0013 | Train Acc: 99.98%\n",
      "Validation Loss: 0.0990 | Validation Acc: 97.34% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 10/200 | Train Loss: 0.0014 | Train Acc: 99.97%\n",
      "Validation Loss: 0.1056 | Validation Acc: 97.29% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 11/200 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1010 | Validation Acc: 97.38% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.51%\n",
      "Epoch 12/200 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Validation Loss: 0.1000 | Validation Acc: 97.51% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 13/200 | Train Loss: 0.0006 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1015 | Validation Acc: 97.33% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 14/200 | Train Loss: 0.0005 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1040 | Validation Acc: 97.28% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 15/200 | Train Loss: 0.0006 | Train Acc: 99.99%\n",
      "Validation Loss: 0.1015 | Validation Acc: 97.40% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 16/200 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0981 | Validation Acc: 97.47% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.53%\n",
      "Epoch 17/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0958 | Validation Acc: 97.53% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 18/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0972 | Validation Acc: 97.44% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 19/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0991 | Validation Acc: 97.46% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.59%\n",
      "Epoch 20/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0981 | Validation Acc: 97.59% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 21/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0974 | Validation Acc: 97.54% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 22/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0983 | Validation Acc: 97.58% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 23/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0997 | Validation Acc: 97.51% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.60%\n",
      "Epoch 24/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0950 | Validation Acc: 97.60% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 25/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0945 | Validation Acc: 97.59% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 26/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0957 | Validation Acc: 97.58% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.68%\n",
      "Epoch 27/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0951 | Validation Acc: 97.68% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 28/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0974 | Validation Acc: 97.50% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 29/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0951 | Validation Acc: 97.63% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 30/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0956 | Validation Acc: 97.68% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 31/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0955 | Validation Acc: 97.63% | Sparsity: 70.64%\n",
      "\n",
      "New best model saved with Val Accuracy: 97.71%\n",
      "Epoch 32/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0957 | Validation Acc: 97.71% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 33/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0966 | Validation Acc: 97.68% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 34/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0990 | Validation Acc: 97.62% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 35/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0978 | Validation Acc: 97.62% | Sparsity: 70.64%\n",
      "\n",
      "Epoch 36/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0955 | Validation Acc: 97.62% | Sparsity: 70.64%\n",
      "\n",
      "Early stopping triggered at epoch 37. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 97.71% | Best Model Saved at: retrained_student_model_50%.pt\n",
      "Retraining completed in 21.32 minutes (1279.27 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model_50%.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 94.60%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 32s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 10.07%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 98.50%\n",
      "Epoch 1/200 | Train Loss: 0.0709 | Train Acc: 98.11%\n",
      "Validation Loss: 0.0517 | Validation Acc: 98.50% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.68%\n",
      "Epoch 2/200 | Train Loss: 0.0182 | Train Acc: 99.54%\n",
      "Validation Loss: 0.0486 | Validation Acc: 98.68% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 3/200 | Train Loss: 0.0049 | Train Acc: 99.94%\n",
      "Validation Loss: 0.0478 | Validation Acc: 98.63% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.76%\n",
      "Epoch 4/200 | Train Loss: 0.0019 | Train Acc: 99.98%\n",
      "Validation Loss: 0.0473 | Validation Acc: 98.76% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.81%\n",
      "Epoch 5/200 | Train Loss: 0.0012 | Train Acc: 99.99%\n",
      "Validation Loss: 0.0452 | Validation Acc: 98.81% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.82%\n",
      "Epoch 6/200 | Train Loss: 0.0008 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0462 | Validation Acc: 98.82% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 7/200 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0464 | Validation Acc: 98.82% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 8/200 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0468 | Validation Acc: 98.78% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 9/200 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0483 | Validation Acc: 98.76% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.84%\n",
      "Epoch 10/200 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0469 | Validation Acc: 98.84% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.86%\n",
      "Epoch 11/200 | Train Loss: 0.0003 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0466 | Validation Acc: 98.86% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 12/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0469 | Validation Acc: 98.82% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 13/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0474 | Validation Acc: 98.83% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 14/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0475 | Validation Acc: 98.86% | Sparsity: 50.46%\n",
      "\n",
      "New best model saved with Val Accuracy: 98.93%\n",
      "Epoch 15/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0473 | Validation Acc: 98.93% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 16/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0478 | Validation Acc: 98.88% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 17/200 | Train Loss: 0.0002 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0477 | Validation Acc: 98.84% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 18/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0485 | Validation Acc: 98.85% | Sparsity: 50.46%\n",
      "\n",
      "Epoch 19/200 | Train Loss: 0.0001 | Train Acc: 100.00%\n",
      "Validation Loss: 0.0484 | Validation Acc: 98.83% | Sparsity: 50.46%\n",
      "\n",
      "Early stopping triggered at epoch 20. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 98.93% | Best Model Saved at: retrained_student_model_50%.pt\n",
      "Retraining completed in 11.39 minutes (683.55 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model_50%.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 95.49%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 33s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=7.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.5677 | Train Acc: 97.63% | Val Loss: 0.0573 | Val Acc: 98.25% | Sparsity: 50.46%\n",
      "Epoch 2/50 | Train Loss: 0.3234 | Train Acc: 98.89% | Val Loss: 0.0483 | Val Acc: 98.47% | Sparsity: 50.46%\n",
      "Epoch 3/50 | Train Loss: 0.2600 | Train Acc: 99.20% | Val Loss: 0.0537 | Val Acc: 98.26% | Sparsity: 50.46%\n",
      "Epoch 4/50 | Train Loss: 0.2225 | Train Acc: 99.33% | Val Loss: 0.0456 | Val Acc: 98.73% | Sparsity: 50.46%\n",
      "Epoch 5/50 | Train Loss: 0.1924 | Train Acc: 99.41% | Val Loss: 0.0468 | Val Acc: 98.54% | Sparsity: 50.46%\n",
      "Epoch 6/50 | Train Loss: 0.1782 | Train Acc: 99.42% | Val Loss: 0.0491 | Val Acc: 98.51% | Sparsity: 50.46%\n",
      "Epoch 7/50 | Train Loss: 0.1706 | Train Acc: 99.41% | Val Loss: 0.0450 | Val Acc: 98.58% | Sparsity: 50.46%\n",
      "Epoch 8/50 | Train Loss: 0.1556 | Train Acc: 99.42% | Val Loss: 0.0443 | Val Acc: 98.69% | Sparsity: 50.46%\n",
      "Epoch 9/50 | Train Loss: 0.1545 | Train Acc: 99.45% | Val Loss: 0.0470 | Val Acc: 98.56% | Sparsity: 50.46%\n",
      "Early stopping triggered at epoch 9. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 8m 22s\n",
      "Retraining completed in 8.37 minutes (501.93 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=7.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 95.41%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 2m 31s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.5663 | Train Acc: 97.52% | Val Loss: 0.0652 | Val Acc: 98.01% | Sparsity: 50.46%\n",
      "Epoch 2/50 | Train Loss: 0.3217 | Train Acc: 98.78% | Val Loss: 0.0512 | Val Acc: 98.43% | Sparsity: 50.46%\n",
      "Epoch 3/50 | Train Loss: 0.2568 | Train Acc: 99.17% | Val Loss: 0.0521 | Val Acc: 98.30% | Sparsity: 50.46%\n",
      "Epoch 4/50 | Train Loss: 0.2144 | Train Acc: 99.30% | Val Loss: 0.0494 | Val Acc: 98.60% | Sparsity: 50.46%\n",
      "Epoch 5/50 | Train Loss: 0.1934 | Train Acc: 99.31% | Val Loss: 0.0479 | Val Acc: 98.58% | Sparsity: 50.46%\n",
      "Epoch 6/50 | Train Loss: 0.1742 | Train Acc: 99.40% | Val Loss: 0.0498 | Val Acc: 98.47% | Sparsity: 50.46%\n",
      "Epoch 7/50 | Train Loss: 0.1613 | Train Acc: 99.37% | Val Loss: 0.0477 | Val Acc: 98.57% | Sparsity: 50.46%\n",
      "Epoch 8/50 | Train Loss: 0.1531 | Train Acc: 99.41% | Val Loss: 0.0473 | Val Acc: 98.62% | Sparsity: 50.46%\n",
      "Epoch 9/50 | Train Loss: 0.1425 | Train Acc: 99.38% | Val Loss: 0.0519 | Val Acc: 98.38% | Sparsity: 50.46%\n",
      "Epoch 10/50 | Train Loss: 0.1360 | Train Acc: 99.36% | Val Loss: 0.0455 | Val Acc: 98.76% | Sparsity: 50.46%\n",
      "Epoch 11/50 | Train Loss: 0.1256 | Train Acc: 99.42% | Val Loss: 0.0458 | Val Acc: 98.58% | Sparsity: 50.46%\n",
      "Epoch 12/50 | Train Loss: 0.1199 | Train Acc: 99.41% | Val Loss: 0.0497 | Val Acc: 98.45% | Sparsity: 50.46%\n",
      "Epoch 13/50 | Train Loss: 0.1193 | Train Acc: 99.39% | Val Loss: 0.0472 | Val Acc: 98.64% | Sparsity: 50.46%\n",
      "Epoch 14/50 | Train Loss: 0.1168 | Train Acc: 99.44% | Val Loss: 0.0483 | Val Acc: 98.64% | Sparsity: 50.46%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": false,
     "modelId": 268576,
     "modelInstanceId": 247034,
     "sourceId": 288333,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
