{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x72208cb8b610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "import time\n",
    "torch.manual_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(dataset, [80000, 10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet-50 (Teacher Model)\n",
    "teacher = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for 10 classes (CIFAR-10)\n",
    "teacher.fc = nn.Linear(teacher.fc.in_features, 200)\n",
    "# Move models to device\n",
    "teacher = teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model_path = 'best_teacher_model.pth'\n",
    "# # Load the model weights\n",
    "# teacher.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-18 (Student Model)\n",
    "student = models.resnet18(pretrained=True)\n",
    "# Modify the final fully connected layer for 10 classes (CIFAR-10)\n",
    "student.fc = nn.Linear(student.fc.in_features, 200)\n",
    "student = student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model_path = 'student_before_pruning.pth'\n",
    "# # Load the model weights\n",
    "# student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits normalization function\n",
    "def normalize(logit):\n",
    "    mean = logit.mean(dim=-1, keepdim=True)\n",
    "    stdv = logit.std(dim=-1, keepdim=True)\n",
    "    return (logit - mean) / (1e-7 + stdv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA-KLD Loss for Classification\n",
    "def cakld_loss(student_logits, teacher_logits, beta_prob):\n",
    "    # Forward KL (student || teacher)\n",
    "    student_log_prob = F.log_softmax(student_logits, dim=1)\n",
    "    teacher_prob = F.softmax(teacher_logits, dim=1)\n",
    "    forward_kl = F.kl_div(student_log_prob, teacher_prob, reduction='batchmean')\n",
    "\n",
    "    # Reverse KL (teacher || student)\n",
    "    teacher_log_prob = F.log_softmax(teacher_logits, dim=1)\n",
    "    student_prob = F.softmax(student_logits, dim=1)\n",
    "    reverse_kl = F.kl_div(teacher_log_prob, student_prob, reduction='batchmean')\n",
    "\n",
    "    # Combined KL loss\n",
    "    kl_loss = beta_prob * reverse_kl + (1 - beta_prob) * forward_kl\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model = model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparsity(model):\n",
    "    total_zeros = 0\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            total_zeros += torch.sum(param == 0).item()\n",
    "            total_params += param.numel()\n",
    "    return total_zeros / total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "def measure_inference_time(model, test_loader, num_runs=5):\n",
    "    device = torch.device('cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Warm-up (one batch to avoid startup cost)\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            _ = model(inputs)\n",
    "            break\n",
    "\n",
    "    total_time = 0\n",
    "    total_images = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            for inputs, _ in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                start_time = time.time()\n",
    "                _ = model(inputs)\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += (end_time - start_time)\n",
    "                total_images += batch_size\n",
    "\n",
    "    avg_time_per_image = total_time / total_images\n",
    "    return avg_time_per_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def calculate_model_size(model, filename=\"temp.pth\"):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    size = os.path.getsize(filename) / (1024 * 1024)  # Size in MB\n",
    "    os.remove(filename)\n",
    "    return size\n",
    "\n",
    "def compare_model_sizes(teacher, student, pruned_student):\n",
    "    # Count parameters\n",
    "    teacher_params = count_parameters(teacher)\n",
    "    student_params = count_parameters(student)\n",
    "    pruned_params = count_parameters(pruned_student)\n",
    "    \n",
    "    # Calculate disk size\n",
    "    teacher_size = calculate_model_size(teacher, \"teacher.pth\")\n",
    "    student_size = calculate_model_size(student, \"student.pth\")\n",
    "    pruned_size = calculate_model_size(pruned_student, \"pruned_student.pth\")\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"\\n--- Model Size Comparison ---\")\n",
    "    print(f\"Teacher Model: {teacher_params} parameters, {teacher_size:.2f} MB\")\n",
    "    print(f\"Student Model (Before Pruning): {student_params} parameters, {student_size:.2f} MB\")\n",
    "    print(f\"Student Model (After Pruning): {pruned_params} parameters, {pruned_size:.2f} MB\")\n",
    "    \n",
    "    # Calculate compression ratio\n",
    "    compression_ratio = student_size / pruned_size\n",
    "    print(f\"\\nCompression Ratio: {compression_ratio:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, patience=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        val_accuracy = evaluate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            torch.save(model.state_dict(), 'best_teacher_model.pth')  # Save the best model\n",
    "            print(f\" New best model saved with validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" No improvement in validation accuracy ({patience_counter}/{patience})\")\n",
    "            \n",
    "            # Stop training if no improvement for 'patience' epochs\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered! No improvement for {patience} epochs.\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(torch.load('best_teacher_model.pth'))\n",
    "    print(\"\\nLoading the best model for final evaluation.\")\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    print(f\"Test Accuracy with Best Model: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/200 | Loss: 2.0593 | Val Accuracy: 74.06%\n",
      " New best model saved with validation accuracy: 74.06%\n",
      "1\n",
      "Epoch 2/200 | Loss: 0.8640 | Val Accuracy: 76.41%\n",
      " New best model saved with validation accuracy: 76.41%\n",
      "2\n",
      "Epoch 3/200 | Loss: 0.5448 | Val Accuracy: 76.62%\n",
      " New best model saved with validation accuracy: 76.62%\n",
      "3\n",
      "Epoch 4/200 | Loss: 0.3316 | Val Accuracy: 76.56%\n",
      " No improvement in validation accuracy (1/5)\n",
      "4\n",
      "Epoch 5/200 | Loss: 0.1921 | Val Accuracy: 77.56%\n",
      " New best model saved with validation accuracy: 77.56%\n",
      "5\n",
      "Epoch 6/200 | Loss: 0.1019 | Val Accuracy: 77.74%\n",
      " New best model saved with validation accuracy: 77.74%\n",
      "6\n",
      "Epoch 7/200 | Loss: 0.0574 | Val Accuracy: 77.66%\n",
      " No improvement in validation accuracy (1/5)\n",
      "7\n",
      "Epoch 8/200 | Loss: 0.0329 | Val Accuracy: 77.80%\n",
      " New best model saved with validation accuracy: 77.80%\n",
      "8\n",
      "Epoch 9/200 | Loss: 0.0221 | Val Accuracy: 77.92%\n",
      " New best model saved with validation accuracy: 77.92%\n",
      "9\n",
      "Epoch 10/200 | Loss: 0.0160 | Val Accuracy: 78.00%\n",
      " New best model saved with validation accuracy: 78.00%\n",
      "10\n",
      "Epoch 11/200 | Loss: 0.0114 | Val Accuracy: 78.21%\n",
      " New best model saved with validation accuracy: 78.21%\n",
      "11\n",
      "Epoch 12/200 | Loss: 0.0095 | Val Accuracy: 78.05%\n",
      " No improvement in validation accuracy (1/5)\n",
      "12\n",
      "Epoch 13/200 | Loss: 0.0077 | Val Accuracy: 78.24%\n",
      " New best model saved with validation accuracy: 78.24%\n",
      "13\n",
      "Epoch 14/200 | Loss: 0.0065 | Val Accuracy: 78.21%\n",
      " No improvement in validation accuracy (1/5)\n",
      "14\n",
      "Epoch 15/200 | Loss: 0.0057 | Val Accuracy: 78.22%\n",
      " No improvement in validation accuracy (2/5)\n",
      "15\n",
      "Epoch 16/200 | Loss: 0.0050 | Val Accuracy: 78.25%\n",
      " New best model saved with validation accuracy: 78.25%\n",
      "16\n",
      "Epoch 17/200 | Loss: 0.0046 | Val Accuracy: 78.45%\n",
      " New best model saved with validation accuracy: 78.45%\n",
      "17\n",
      "Epoch 18/200 | Loss: 0.0043 | Val Accuracy: 78.47%\n",
      " New best model saved with validation accuracy: 78.47%\n",
      "18\n",
      "Epoch 19/200 | Loss: 0.0039 | Val Accuracy: 78.54%\n",
      " New best model saved with validation accuracy: 78.54%\n",
      "19\n",
      "Epoch 20/200 | Loss: 0.0038 | Val Accuracy: 78.56%\n",
      " New best model saved with validation accuracy: 78.56%\n",
      "20\n",
      "Epoch 21/200 | Loss: 0.0034 | Val Accuracy: 78.28%\n",
      " No improvement in validation accuracy (1/5)\n",
      "21\n",
      "Epoch 22/200 | Loss: 0.0032 | Val Accuracy: 78.21%\n",
      " No improvement in validation accuracy (2/5)\n",
      "22\n",
      "Epoch 23/200 | Loss: 0.0031 | Val Accuracy: 78.25%\n",
      " No improvement in validation accuracy (3/5)\n",
      "23\n",
      "Epoch 24/200 | Loss: 0.0029 | Val Accuracy: 78.23%\n",
      " No improvement in validation accuracy (4/5)\n",
      "24\n",
      "Epoch 25/200 | Loss: 0.0027 | Val Accuracy: 78.04%\n",
      " No improvement in validation accuracy (5/5)\n",
      "\n",
      "Early stopping triggered! No improvement for 5 epochs.\n",
      "\n",
      "Loading the best model for final evaluation.\n",
      "Test Accuracy with Best Model: 78.46%\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the teacher model\n",
    "teacher = train_model(teacher, train_loader, val_loader, epochs=200, lr=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_importance(\n",
    "    teacher, student, data_loader, device, temperature=4.0, alpha=0.5, beta_prob=0.5, accumulation_epochs=3\n",
    "):\n",
    "    importance_scores = {}\n",
    "\n",
    "    # Initialize importance score storage for conv layer weights only\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and len(param.shape) == 4:  # Conv weights only\n",
    "            importance_scores[name] = torch.zeros_like(param.data, device=device)\n",
    "\n",
    "    teacher.to(device).eval()\n",
    "    student.to(device).train()\n",
    "\n",
    "    # Add momentum for gradient accumulation smoothing\n",
    "    momentum = 0.9  # Controls exponential moving average\n",
    "    accumulated_batches = 0  # Track for bias correction\n",
    "\n",
    "    for epoch in range(accumulation_epochs):\n",
    "        print(f\"Accumulation Epoch {epoch+1}/{accumulation_epochs}\")\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # Temperature scaling\n",
    "            student_logits_temp = student_logits / temperature\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "\n",
    "            # Compute losses\n",
    "            distillation_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "            ce_loss = F.cross_entropy(student_logits, labels)\n",
    "            loss = alpha * distillation_loss + (1 - alpha) * ce_loss\n",
    "\n",
    "            # Modified backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Accumulate importance scores with parameter-gradient product\n",
    "            accumulated_batches += 1\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in importance_scores and param.grad is not None:\n",
    "                    # Key modification: Use parameter-gradient product magnitude\n",
    "                    grad_product = (param.data * param.grad).abs_()\n",
    "                    \n",
    "                    # Exponential moving average with bias correction\n",
    "                    if accumulated_batches == 1:\n",
    "                        importance_scores[name] = grad_product\n",
    "                    else:\n",
    "                        importance_scores[name] = momentum * importance_scores[name] + (1 - momentum) * grad_product\n",
    "\n",
    "    # Apply bias correction for EMA\n",
    "    for name in importance_scores:\n",
    "        importance_scores[name] /= (1 - momentum**accumulated_batches)\n",
    "\n",
    "    return importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_based_global_prune(model, importance_scores, prune_ratio=0.95):\n",
    "    all_scores = torch.cat([score.flatten() for score in importance_scores.values()])\n",
    "    threshold = torch.topk(all_scores, k=int(prune_ratio * all_scores.numel()), largest=False)[0][-1]\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in importance_scores:\n",
    "            mask = (importance_scores[name] > threshold).float()\n",
    "            param.data.mul_(mask)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def retrain_with_sparsity(student, train_loader, val_loader, epochs=5, save_path=\"retrained_student_model.pt\", patience=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # 1. Store masks AND zero momentum buffers for pruned weights\n",
    "    masks = {}\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and param.dim() == 4:  # Consider only conv layers\n",
    "            mask = (param != 0).float().to(device)\n",
    "            masks[name] = mask\n",
    "            # Zero momentum buffers for pruned weights\n",
    "            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                optimizer.state[param]['momentum_buffer'] *= mask\n",
    "\n",
    "    student = student.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    best_model = None\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "\n",
    "    # 2. Add gradient clipping to prevent NaN\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = student(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Apply masks to gradients\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.grad.data *= masks[name]\n",
    "\n",
    "            # Gradient clipping before optimizer step\n",
    "            torch.nn.utils.clip_grad_norm_(student.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reapply masks and update momentum buffers\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.data *= masks[name]\n",
    "                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        student.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "        # Track best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = student.state_dict()\n",
    "            torch.save(best_model, save_path)\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            print(f\"New best model saved with Val Accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break  # Stop training\n",
    "\n",
    "        # Print results\n",
    "        sparsity = calculate_sparsity(student)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.2f}% | Sparsity: {sparsity*100:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}% | Best Model Saved at: {save_path}\")\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# KD training with CA-KLD loss and mask-based momentum handling\n",
    "def retrain_with_KD(teacher, student, train_loader, val_loader, epochs=50,\n",
    "                    temperature=5.0, alpha=0.5, beta_prob=0.5, patience=5,\n",
    "                    save_path=\"student_before_pruning.pth\"):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # 1. Store masks and zero momentum buffers\n",
    "    masks = {}\n",
    "    for name, param in student.named_parameters():\n",
    "        if 'weight' in name and param.dim() == 4:\n",
    "            mask = (param != 0).float().to(device)\n",
    "            masks[name] = mask\n",
    "            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                optimizer.state[param]['momentum_buffer'] *= mask\n",
    "\n",
    "    teacher = teacher.to(device).eval()\n",
    "    student = student.to(device)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # Apply temperature\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "            student_logits_temp = student_logits / temperature\n",
    "\n",
    "            # Logits normalization\n",
    "            teacher_logits_temp = normalize(teacher_logits_temp)\n",
    "            student_logits_temp = normalize(student_logits_temp)\n",
    "\n",
    "\n",
    "            # CA-KLD loss\n",
    "            kd_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "            ce_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reapply masks and update momentum\n",
    "            for name, param in student.named_parameters():\n",
    "                if name in masks:\n",
    "                    param.data *= masks[name]\n",
    "                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n",
    "                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = student_logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        student.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        sparsity = calculate_sparsity(student) * 100.0  # Assuming this function is defined elsewhere\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = student.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    # Restore and save best model\n",
    "    student.load_state_dict(best_model_state)\n",
    "    torch.save(student.state_dict(), save_path)\n",
    "    print(f\"Student model saved before pruning at: {save_path}\")\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Training function with KD + CA-KLD and logits normalization\n",
    "def train_kd_pruning(teacher, student, train_loader, val_loader, epochs=50, temperature=5.0, alpha=0.5,\n",
    "                     beta_prob=0.5, patience=5, save_path=\"student_before_pruning.pth\"):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    teacher.eval()  # Freeze teacher\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            # Temperature scaling\n",
    "            teacher_logits_temp = teacher_logits / temperature\n",
    "            student_logits_temp = student_logits / temperature\n",
    "\n",
    "            # Logits normalization\n",
    "            teacher_logits_temp = normalize(teacher_logits_temp)\n",
    "            student_logits_temp = normalize(student_logits_temp)\n",
    "\n",
    "            # CA-KLD loss (normalized logits)\n",
    "            distillation_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n",
    "\n",
    "            # Cross-entropy loss\n",
    "            ground_truth_loss = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "            # Combined loss\n",
    "            loss = alpha * distillation_loss + (1 - alpha) * ground_truth_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = student_logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation accuracy\n",
    "        val_acc = evaluate(student, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = student.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    # Load best model state and save\n",
    "    student.load_state_dict(best_model_state)\n",
    "    torch.save(student.state_dict(), save_path)\n",
    "    print(f\"Student model saved before pruning at: {save_path}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 2.5908 | Train Acc: 95.53% | Val Acc: 56.69%\n",
      "Epoch 2/50 | Train Loss: 1.2254 | Train Acc: 99.10% | Val Acc: 58.77%\n",
      "Epoch 3/50 | Train Loss: 0.7198 | Train Acc: 99.83% | Val Acc: 60.37%\n",
      "Epoch 4/50 | Train Loss: 0.5329 | Train Acc: 99.95% | Val Acc: 61.01%\n",
      "Epoch 5/50 | Train Loss: 0.4462 | Train Acc: 99.98% | Val Acc: 61.32%\n",
      "Epoch 6/50 | Train Loss: 0.4034 | Train Acc: 99.98% | Val Acc: 61.37%\n",
      "Epoch 7/50 | Train Loss: 0.3741 | Train Acc: 99.98% | Val Acc: 61.65%\n",
      "Epoch 8/50 | Train Loss: 0.3559 | Train Acc: 99.98% | Val Acc: 61.67%\n",
      "Epoch 9/50 | Train Loss: 0.3395 | Train Acc: 99.98% | Val Acc: 61.68%\n",
      "Epoch 10/50 | Train Loss: 0.3279 | Train Acc: 99.98% | Val Acc: 61.55%\n",
      "Epoch 11/50 | Train Loss: 0.3166 | Train Acc: 99.98% | Val Acc: 61.65%\n",
      "Epoch 12/50 | Train Loss: 0.3063 | Train Acc: 99.98% | Val Acc: 61.89%\n",
      "Epoch 13/50 | Train Loss: 0.2991 | Train Acc: 99.98% | Val Acc: 61.59%\n",
      "Epoch 14/50 | Train Loss: 0.2922 | Train Acc: 99.98% | Val Acc: 61.72%\n",
      "Epoch 15/50 | Train Loss: 0.2847 | Train Acc: 99.98% | Val Acc: 61.47%\n",
      "Epoch 16/50 | Train Loss: 0.2791 | Train Acc: 99.98% | Val Acc: 61.76%\n",
      "Epoch 17/50 | Train Loss: 0.2741 | Train Acc: 99.98% | Val Acc: 61.50%\n",
      "Early stopping triggered at epoch 17. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: student_before_pruning.pth\n",
      "Total Training Time: 29m 13s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "student = train_kd_pruning(\n",
    "    teacher, student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.5,beta_prob=0.5, patience=5,save_path=\"student_before_pruning.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Before Pruning: 0.00%\n",
      "Teacher Model Test Accuracy: 78.46%\n",
      "Student Model Test Accuracy Before Pruning: 62.19%\n"
     ]
    }
   ],
   "source": [
    "# Calculate sparsity\n",
    "sparsity = calculate_sparsity(student)\n",
    "print(f\"Sparsity Before Pruning: {sparsity * 100:.2f}%\")\n",
    "\n",
    "teacher_accuracy = evaluate(teacher, test_loader, device)\n",
    "student_accuracy = evaluate(student, test_loader, device)\n",
    "print(f\"Teacher Model Test Accuracy: {teacher_accuracy:.2f}%\")\n",
    "print(f\"Student Model Test Accuracy Before Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 93% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 37s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 0.51%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 29.42%\n",
      "Epoch 1/200 | Train Loss: 4.3579 | Train Acc: 15.95%\n",
      "Validation Loss: 3.2594 | Validation Acc: 29.42% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 41.56%\n",
      "Epoch 2/200 | Train Loss: 2.5401 | Train Acc: 41.16%\n",
      "Validation Loss: 2.4974 | Validation Acc: 41.56% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 46.10%\n",
      "Epoch 3/200 | Train Loss: 1.9987 | Train Acc: 51.41%\n",
      "Validation Loss: 2.2510 | Validation Acc: 46.10% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 48.25%\n",
      "Epoch 4/200 | Train Loss: 1.7396 | Train Acc: 56.88%\n",
      "Validation Loss: 2.1539 | Validation Acc: 48.25% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 49.58%\n",
      "Epoch 5/200 | Train Loss: 1.5582 | Train Acc: 61.03%\n",
      "Validation Loss: 2.0967 | Validation Acc: 49.58% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 50.25%\n",
      "Epoch 6/200 | Train Loss: 1.4234 | Train Acc: 63.96%\n",
      "Validation Loss: 2.0655 | Validation Acc: 50.25% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 50.77%\n",
      "Epoch 7/200 | Train Loss: 1.3132 | Train Acc: 66.35%\n",
      "Validation Loss: 2.0508 | Validation Acc: 50.77% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 51.20%\n",
      "Epoch 8/200 | Train Loss: 1.2165 | Train Acc: 68.73%\n",
      "Validation Loss: 2.0486 | Validation Acc: 51.20% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 51.53%\n",
      "Epoch 9/200 | Train Loss: 1.1324 | Train Acc: 70.78%\n",
      "Validation Loss: 2.0564 | Validation Acc: 51.53% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 51.74%\n",
      "Epoch 10/200 | Train Loss: 1.0564 | Train Acc: 72.65%\n",
      "Validation Loss: 2.0503 | Validation Acc: 51.74% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.17%\n",
      "Epoch 11/200 | Train Loss: 0.9828 | Train Acc: 74.42%\n",
      "Validation Loss: 2.0671 | Validation Acc: 52.17% | Sparsity: 93.11%\n",
      "\n",
      "Epoch 12/200 | Train Loss: 0.9183 | Train Acc: 76.07%\n",
      "Validation Loss: 2.0790 | Validation Acc: 51.94% | Sparsity: 93.11%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.36%\n",
      "Epoch 13/200 | Train Loss: 0.8563 | Train Acc: 77.59%\n",
      "Validation Loss: 2.0977 | Validation Acc: 52.36% | Sparsity: 93.11%\n",
      "\n",
      "Epoch 14/200 | Train Loss: 0.7988 | Train Acc: 79.14%\n",
      "Validation Loss: 2.1539 | Validation Acc: 51.63% | Sparsity: 93.11%\n",
      "\n",
      "Epoch 15/200 | Train Loss: 0.7447 | Train Acc: 80.71%\n",
      "Validation Loss: 2.1813 | Validation Acc: 51.96% | Sparsity: 93.11%\n",
      "\n",
      "Epoch 16/200 | Train Loss: 0.6950 | Train Acc: 81.77%\n",
      "Validation Loss: 2.2258 | Validation Acc: 51.39% | Sparsity: 93.11%\n",
      "\n",
      "Epoch 17/200 | Train Loss: 0.6456 | Train Acc: 83.06%\n",
      "Validation Loss: 2.2542 | Validation Acc: 51.86% | Sparsity: 93.11%\n",
      "\n",
      "Early stopping triggered at epoch 18. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 52.36% | Best Model Saved at: retrained_student_model.pt\n",
      "Retraining completed in 20.60 minutes (1236.17 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 51.74%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 46s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=3.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 13.4261 | Train Acc: 45.14% | Val Loss: 2.4397 | Val Acc: 48.49% | Sparsity: 93.11%\n",
      "Epoch 2/50 | Train Loss: 9.2128 | Train Acc: 62.95% | Val Loss: 2.2383 | Val Acc: 52.33% | Sparsity: 93.11%\n",
      "Epoch 3/50 | Train Loss: 7.7465 | Train Acc: 69.39% | Val Loss: 2.2246 | Val Acc: 53.10% | Sparsity: 93.11%\n",
      "Epoch 4/50 | Train Loss: 6.7792 | Train Acc: 73.76% | Val Loss: 2.2012 | Val Acc: 54.59% | Sparsity: 93.11%\n",
      "Epoch 5/50 | Train Loss: 6.0349 | Train Acc: 77.25% | Val Loss: 2.2135 | Val Acc: 54.97% | Sparsity: 93.11%\n",
      "Epoch 6/50 | Train Loss: 5.4562 | Train Acc: 80.12% | Val Loss: 2.2291 | Val Acc: 54.40% | Sparsity: 93.11%\n",
      "Epoch 7/50 | Train Loss: 4.9603 | Train Acc: 82.44% | Val Loss: 2.2161 | Val Acc: 53.69% | Sparsity: 93.11%\n",
      "Epoch 8/50 | Train Loss: 4.5286 | Train Acc: 84.54% | Val Loss: 2.2590 | Val Acc: 53.57% | Sparsity: 93.11%\n",
      "Epoch 9/50 | Train Loss: 4.1383 | Train Acc: 86.40% | Val Loss: 2.2403 | Val Acc: 53.78% | Sparsity: 93.11%\n",
      "Epoch 10/50 | Train Loss: 3.8150 | Train Acc: 87.94% | Val Loss: 2.2409 | Val Acc: 53.00% | Sparsity: 93.11%\n",
      "Early stopping triggered at epoch 10. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 17m 25s\n",
      "Retraining completed in 17.41 minutes (1044.62 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 53.79%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 53s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.94)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 32.9822 | Train Acc: 47.87% | Val Loss: 2.3725 | Val Acc: 49.29% | Sparsity: 93.11%\n",
      "Epoch 2/50 | Train Loss: 24.0918 | Train Acc: 62.03% | Val Loss: 2.2526 | Val Acc: 52.02% | Sparsity: 93.11%\n",
      "Epoch 3/50 | Train Loss: 20.8340 | Train Acc: 67.53% | Val Loss: 2.1998 | Val Acc: 53.33% | Sparsity: 93.11%\n",
      "Epoch 4/50 | Train Loss: 18.5712 | Train Acc: 71.50% | Val Loss: 2.2473 | Val Acc: 53.02% | Sparsity: 93.11%\n",
      "Epoch 5/50 | Train Loss: 16.8159 | Train Acc: 74.71% | Val Loss: 2.2101 | Val Acc: 52.87% | Sparsity: 93.11%\n",
      "Epoch 6/50 | Train Loss: 15.3038 | Train Acc: 77.57% | Val Loss: 2.2537 | Val Acc: 52.42% | Sparsity: 93.11%\n",
      "Epoch 7/50 | Train Loss: 13.8867 | Train Acc: 80.14% | Val Loss: 2.2255 | Val Acc: 53.39% | Sparsity: 93.11%\n",
      "Epoch 8/50 | Train Loss: 12.7689 | Train Acc: 82.13% | Val Loss: 2.2549 | Val Acc: 52.50% | Sparsity: 93.11%\n",
      "Epoch 9/50 | Train Loss: 11.6378 | Train Acc: 84.35% | Val Loss: 2.2415 | Val Acc: 53.16% | Sparsity: 93.11%\n",
      "Epoch 10/50 | Train Loss: 10.6613 | Train Acc: 86.04% | Val Loss: 2.2583 | Val Acc: 52.57% | Sparsity: 93.11%\n",
      "Epoch 11/50 | Train Loss: 9.8661 | Train Acc: 87.75% | Val Loss: 2.2714 | Val Acc: 52.41% | Sparsity: 93.11%\n",
      "Epoch 12/50 | Train Loss: 9.0470 | Train Acc: 89.19% | Val Loss: 2.2976 | Val Acc: 52.36% | Sparsity: 93.11%\n",
      "Early stopping triggered at epoch 12. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 20m 41s\n",
      "Retraining completed in 20.68 minutes (1240.90 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 52.11%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98% of Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 28s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.985)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 4.74%\n",
      "Epoch 1/200 | Train Loss: 5.2237 | Train Acc: 2.33%\n",
      "Validation Loss: 4.9673 | Validation Acc: 4.74% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 15.13%\n",
      "Epoch 2/200 | Train Loss: 4.5510 | Train Acc: 9.47%\n",
      "Validation Loss: 4.1147 | Validation Acc: 15.13% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 24.89%\n",
      "Epoch 3/200 | Train Loss: 3.6774 | Train Acc: 20.93%\n",
      "Validation Loss: 3.3649 | Validation Acc: 24.89% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 30.82%\n",
      "Epoch 4/200 | Train Loss: 3.1443 | Train Acc: 28.74%\n",
      "Validation Loss: 3.0213 | Validation Acc: 30.82% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 34.57%\n",
      "Epoch 5/200 | Train Loss: 2.8503 | Train Acc: 34.04%\n",
      "Validation Loss: 2.8266 | Validation Acc: 34.57% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 37.12%\n",
      "Epoch 6/200 | Train Loss: 2.6522 | Train Acc: 37.63%\n",
      "Validation Loss: 2.7025 | Validation Acc: 37.12% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 39.19%\n",
      "Epoch 7/200 | Train Loss: 2.5115 | Train Acc: 40.39%\n",
      "Validation Loss: 2.5974 | Validation Acc: 39.19% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 40.90%\n",
      "Epoch 8/200 | Train Loss: 2.3944 | Train Acc: 42.68%\n",
      "Validation Loss: 2.5256 | Validation Acc: 40.90% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 41.88%\n",
      "Epoch 9/200 | Train Loss: 2.3021 | Train Acc: 44.55%\n",
      "Validation Loss: 2.4755 | Validation Acc: 41.88% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 43.12%\n",
      "Epoch 10/200 | Train Loss: 2.2211 | Train Acc: 46.33%\n",
      "Validation Loss: 2.4209 | Validation Acc: 43.12% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 43.20%\n",
      "Epoch 11/200 | Train Loss: 2.1475 | Train Acc: 47.86%\n",
      "Validation Loss: 2.4053 | Validation Acc: 43.20% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 44.23%\n",
      "Epoch 12/200 | Train Loss: 2.0873 | Train Acc: 49.24%\n",
      "Validation Loss: 2.3570 | Validation Acc: 44.23% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 44.55%\n",
      "Epoch 13/200 | Train Loss: 2.0232 | Train Acc: 50.38%\n",
      "Validation Loss: 2.3368 | Validation Acc: 44.55% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 45.61%\n",
      "Epoch 14/200 | Train Loss: 1.9715 | Train Acc: 51.67%\n",
      "Validation Loss: 2.3092 | Validation Acc: 45.61% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 15/200 | Train Loss: 1.9243 | Train Acc: 52.65%\n",
      "Validation Loss: 2.2943 | Validation Acc: 45.27% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 16/200 | Train Loss: 1.8770 | Train Acc: 53.73%\n",
      "Validation Loss: 2.2891 | Validation Acc: 45.59% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 46.28%\n",
      "Epoch 17/200 | Train Loss: 1.8381 | Train Acc: 54.42%\n",
      "Validation Loss: 2.2569 | Validation Acc: 46.28% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 46.73%\n",
      "Epoch 18/200 | Train Loss: 1.8020 | Train Acc: 55.26%\n",
      "Validation Loss: 2.2558 | Validation Acc: 46.73% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 19/200 | Train Loss: 1.7611 | Train Acc: 56.22%\n",
      "Validation Loss: 2.2612 | Validation Acc: 46.70% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 20/200 | Train Loss: 1.7257 | Train Acc: 57.06%\n",
      "Validation Loss: 2.2357 | Validation Acc: 46.73% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.23%\n",
      "Epoch 21/200 | Train Loss: 1.6892 | Train Acc: 57.90%\n",
      "Validation Loss: 2.2359 | Validation Acc: 47.23% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.36%\n",
      "Epoch 22/200 | Train Loss: 1.6594 | Train Acc: 58.46%\n",
      "Validation Loss: 2.2257 | Validation Acc: 47.36% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 23/200 | Train Loss: 1.6286 | Train Acc: 59.19%\n",
      "Validation Loss: 2.2288 | Validation Acc: 47.11% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.50%\n",
      "Epoch 24/200 | Train Loss: 1.5968 | Train Acc: 59.91%\n",
      "Validation Loss: 2.2210 | Validation Acc: 47.50% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 25/200 | Train Loss: 1.5690 | Train Acc: 60.49%\n",
      "Validation Loss: 2.2243 | Validation Acc: 47.49% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 26/200 | Train Loss: 1.5411 | Train Acc: 60.98%\n",
      "Validation Loss: 2.2328 | Validation Acc: 47.50% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 27/200 | Train Loss: 1.5149 | Train Acc: 61.72%\n",
      "Validation Loss: 2.2242 | Validation Acc: 47.49% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.90%\n",
      "Epoch 28/200 | Train Loss: 1.4880 | Train Acc: 62.16%\n",
      "Validation Loss: 2.2295 | Validation Acc: 47.90% | Sparsity: 97.56%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.92%\n",
      "Epoch 29/200 | Train Loss: 1.4637 | Train Acc: 63.01%\n",
      "Validation Loss: 2.2375 | Validation Acc: 47.92% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 30/200 | Train Loss: 1.4370 | Train Acc: 63.43%\n",
      "Validation Loss: 2.2383 | Validation Acc: 47.84% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 31/200 | Train Loss: 1.4128 | Train Acc: 64.00%\n",
      "Validation Loss: 2.2430 | Validation Acc: 47.76% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 32/200 | Train Loss: 1.3898 | Train Acc: 64.56%\n",
      "Validation Loss: 2.2549 | Validation Acc: 47.39% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 33/200 | Train Loss: 1.3686 | Train Acc: 65.14%\n",
      "Validation Loss: 2.2620 | Validation Acc: 47.52% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 34/200 | Train Loss: 1.3462 | Train Acc: 65.72%\n",
      "Validation Loss: 2.2596 | Validation Acc: 47.58% | Sparsity: 97.56%\n",
      "\n",
      "Epoch 35/200 | Train Loss: 1.3248 | Train Acc: 65.96%\n",
      "Validation Loss: 2.2724 | Validation Acc: 47.86% | Sparsity: 97.56%\n",
      "\n",
      "Early stopping triggered at epoch 36. No improvement for 7 epochs.\n",
      "Best Validation Accuracy: 47.92% | Best Model Saved at: retrained_student_model.pt\n",
      "Retraining completed in 40.72 minutes (2442.92 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model.pt',patience=7\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(After Retrain): 47.71%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pruned_student_inference_time = measure_inference_time(retrained_student, test_loader,)\n",
    "# print(f\"Pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrained with KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy: 62.19%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 30s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.985)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 46.5602 | Train Acc: 25.36% | Val Loss: 2.9118 | Val Acc: 36.93% | Sparsity: 97.56%\n",
      "Epoch 2/50 | Train Loss: 36.0633 | Train Acc: 42.82% | Val Loss: 2.5652 | Val Acc: 43.14% | Sparsity: 97.56%\n",
      "Epoch 3/50 | Train Loss: 32.7026 | Train Acc: 48.26% | Val Loss: 2.4702 | Val Acc: 45.11% | Sparsity: 97.56%\n",
      "Epoch 4/50 | Train Loss: 30.6133 | Train Acc: 51.74% | Val Loss: 2.4115 | Val Acc: 46.74% | Sparsity: 97.56%\n",
      "Epoch 5/50 | Train Loss: 29.1158 | Train Acc: 54.12% | Val Loss: 2.3706 | Val Acc: 47.74% | Sparsity: 97.56%\n",
      "Epoch 6/50 | Train Loss: 27.9455 | Train Acc: 56.08% | Val Loss: 2.2967 | Val Acc: 49.34% | Sparsity: 97.56%\n",
      "Epoch 7/50 | Train Loss: 26.9808 | Train Acc: 57.91% | Val Loss: 2.3064 | Val Acc: 49.82% | Sparsity: 97.56%\n",
      "Epoch 8/50 | Train Loss: 26.1604 | Train Acc: 59.42% | Val Loss: 2.2794 | Val Acc: 49.66% | Sparsity: 97.56%\n",
      "Epoch 9/50 | Train Loss: 25.4633 | Train Acc: 60.62% | Val Loss: 2.2977 | Val Acc: 49.05% | Sparsity: 97.56%\n",
      "Epoch 10/50 | Train Loss: 24.7114 | Train Acc: 62.03% | Val Loss: 2.2692 | Val Acc: 49.21% | Sparsity: 97.56%\n",
      "Epoch 11/50 | Train Loss: 24.2055 | Train Acc: 62.70% | Val Loss: 2.2890 | Val Acc: 48.60% | Sparsity: 97.56%\n",
      "Epoch 12/50 | Train Loss: 23.6325 | Train Acc: 63.94% | Val Loss: 2.2749 | Val Acc: 49.91% | Sparsity: 97.56%\n",
      "Epoch 13/50 | Train Loss: 23.1358 | Train Acc: 64.83% | Val Loss: 2.2689 | Val Acc: 49.64% | Sparsity: 97.56%\n",
      "Epoch 14/50 | Train Loss: 22.7000 | Train Acc: 65.76% | Val Loss: 2.2702 | Val Acc: 49.68% | Sparsity: 97.56%\n",
      "Epoch 15/50 | Train Loss: 22.2874 | Train Acc: 66.42% | Val Loss: 2.3259 | Val Acc: 49.00% | Sparsity: 97.56%\n",
      "Epoch 16/50 | Train Loss: 21.8944 | Train Acc: 67.29% | Val Loss: 2.2807 | Val Acc: 49.74% | Sparsity: 97.56%\n",
      "Epoch 17/50 | Train Loss: 21.4612 | Train Acc: 67.90% | Val Loss: 2.2780 | Val Acc: 49.88% | Sparsity: 97.56%\n",
      "Epoch 18/50 | Train Loss: 21.1573 | Train Acc: 68.55% | Val Loss: 2.2978 | Val Acc: 49.86% | Sparsity: 97.56%\n",
      "Epoch 19/50 | Train Loss: 20.8094 | Train Acc: 69.31% | Val Loss: 2.3216 | Val Acc: 49.58% | Sparsity: 97.56%\n",
      "Early stopping triggered at epoch 19. No improvement for 7 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 32m 14s\n",
      "Retraining completed in 32.23 minutes (1933.53 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=7,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 50.07%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 31s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.985)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 19.1698 | Train Acc: 18.37% | Val Loss: 3.3076 | Val Acc: 31.60% | Sparsity: 97.56%\n",
      "Epoch 2/50 | Train Loss: 14.9123 | Train Acc: 37.73% | Val Loss: 2.8577 | Val Acc: 39.68% | Sparsity: 97.56%\n",
      "Epoch 3/50 | Train Loss: 13.2350 | Train Acc: 45.12% | Val Loss: 2.6228 | Val Acc: 43.53% | Sparsity: 97.56%\n",
      "Epoch 4/50 | Train Loss: 12.2541 | Train Acc: 49.32% | Val Loss: 2.5229 | Val Acc: 45.37% | Sparsity: 97.56%\n",
      "Epoch 5/50 | Train Loss: 11.5527 | Train Acc: 52.38% | Val Loss: 2.4525 | Val Acc: 47.32% | Sparsity: 97.56%\n",
      "Epoch 6/50 | Train Loss: 11.0221 | Train Acc: 54.87% | Val Loss: 2.4072 | Val Acc: 48.01% | Sparsity: 97.56%\n",
      "Epoch 7/50 | Train Loss: 10.6098 | Train Acc: 56.55% | Val Loss: 2.4083 | Val Acc: 48.69% | Sparsity: 97.56%\n",
      "Epoch 8/50 | Train Loss: 10.2647 | Train Acc: 58.23% | Val Loss: 2.3425 | Val Acc: 49.61% | Sparsity: 97.56%\n",
      "Epoch 9/50 | Train Loss: 9.9430 | Train Acc: 59.73% | Val Loss: 2.3698 | Val Acc: 49.42% | Sparsity: 97.56%\n",
      "Epoch 10/50 | Train Loss: 9.6793 | Train Acc: 60.95% | Val Loss: 2.3392 | Val Acc: 49.47% | Sparsity: 97.56%\n",
      "Epoch 11/50 | Train Loss: 9.4558 | Train Acc: 61.94% | Val Loss: 2.3360 | Val Acc: 50.23% | Sparsity: 97.56%\n",
      "Epoch 12/50 | Train Loss: 9.2418 | Train Acc: 63.08% | Val Loss: 2.3331 | Val Acc: 49.80% | Sparsity: 97.56%\n",
      "Epoch 13/50 | Train Loss: 9.0537 | Train Acc: 63.97% | Val Loss: 2.3153 | Val Acc: 50.15% | Sparsity: 97.56%\n",
      "Epoch 14/50 | Train Loss: 8.8795 | Train Acc: 64.82% | Val Loss: 2.3228 | Val Acc: 49.93% | Sparsity: 97.56%\n",
      "Epoch 15/50 | Train Loss: 8.7193 | Train Acc: 65.54% | Val Loss: 2.2880 | Val Acc: 50.05% | Sparsity: 97.56%\n",
      "Epoch 16/50 | Train Loss: 8.5563 | Train Acc: 66.46% | Val Loss: 2.3200 | Val Acc: 49.54% | Sparsity: 97.56%\n",
      "Epoch 17/50 | Train Loss: 8.4287 | Train Acc: 66.98% | Val Loss: 2.2845 | Val Acc: 50.34% | Sparsity: 97.56%\n",
      "Epoch 18/50 | Train Loss: 8.2895 | Train Acc: 67.63% | Val Loss: 2.3253 | Val Acc: 49.78% | Sparsity: 97.56%\n",
      "Epoch 19/50 | Train Loss: 8.1666 | Train Acc: 68.37% | Val Loss: 2.3059 | Val Acc: 49.87% | Sparsity: 97.56%\n",
      "Epoch 20/50 | Train Loss: 8.0596 | Train Acc: 68.68% | Val Loss: 2.2910 | Val Acc: 49.81% | Sparsity: 97.56%\n",
      "Epoch 21/50 | Train Loss: 7.9360 | Train Acc: 69.64% | Val Loss: 2.2972 | Val Acc: 49.87% | Sparsity: 97.56%\n",
      "Epoch 22/50 | Train Loss: 7.8271 | Train Acc: 69.99% | Val Loss: 2.3249 | Val Acc: 50.43% | Sparsity: 97.56%\n",
      "Epoch 23/50 | Train Loss: 7.7289 | Train Acc: 70.46% | Val Loss: 2.2811 | Val Acc: 50.00% | Sparsity: 97.56%\n",
      "Epoch 24/50 | Train Loss: 7.6369 | Train Acc: 70.92% | Val Loss: 2.3241 | Val Acc: 49.51% | Sparsity: 97.56%\n",
      "Epoch 25/50 | Train Loss: 7.5358 | Train Acc: 71.39% | Val Loss: 2.3120 | Val Acc: 49.22% | Sparsity: 97.56%\n",
      "Epoch 26/50 | Train Loss: 7.4534 | Train Acc: 71.86% | Val Loss: 2.2866 | Val Acc: 49.80% | Sparsity: 97.56%\n",
      "Epoch 27/50 | Train Loss: 7.3813 | Train Acc: 72.26% | Val Loss: 2.3249 | Val Acc: 49.28% | Sparsity: 97.56%\n",
      "Epoch 28/50 | Train Loss: 7.2900 | Train Acc: 72.73% | Val Loss: 2.3212 | Val Acc: 49.34% | Sparsity: 97.56%\n",
      "Epoch 29/50 | Train Loss: 7.2103 | Train Acc: 73.01% | Val Loss: 2.3030 | Val Acc: 49.39% | Sparsity: 97.56%\n",
      "Early stopping triggered at epoch 29. No improvement for 7 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 49m 17s\n",
      "Retraining completed in 49.29 minutes (2957.34 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=7,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 50.64%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 40s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 41.80%\n",
      "Epoch 1/100 | Train Loss: 3.1422 | Train Acc: 35.62%\n",
      "Validation Loss: 2.6129 | Validation Acc: 41.80% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 47.98%\n",
      "Epoch 2/100 | Train Loss: 1.6920 | Train Acc: 59.09%\n",
      "Validation Loss: 2.2863 | Validation Acc: 47.98% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 50.02%\n",
      "Epoch 3/100 | Train Loss: 1.3231 | Train Acc: 66.88%\n",
      "Validation Loss: 2.1767 | Validation Acc: 50.02% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 51.11%\n",
      "Epoch 4/100 | Train Loss: 1.1100 | Train Acc: 71.51%\n",
      "Validation Loss: 2.1598 | Validation Acc: 51.11% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 51.90%\n",
      "Epoch 5/100 | Train Loss: 0.9548 | Train Acc: 75.21%\n",
      "Validation Loss: 2.1443 | Validation Acc: 51.90% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.27%\n",
      "Epoch 6/100 | Train Loss: 0.8275 | Train Acc: 78.41%\n",
      "Validation Loss: 2.1486 | Validation Acc: 52.27% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.39%\n",
      "Epoch 7/100 | Train Loss: 0.7239 | Train Acc: 81.04%\n",
      "Validation Loss: 2.2008 | Validation Acc: 52.39% | Sparsity: 89.22%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.6356 | Train Acc: 83.24%\n",
      "Validation Loss: 2.2336 | Validation Acc: 51.98% | Sparsity: 89.22%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.44%\n",
      "Epoch 9/100 | Train Loss: 0.5555 | Train Acc: 85.48%\n",
      "Validation Loss: 2.2802 | Validation Acc: 52.44% | Sparsity: 89.22%\n",
      "\n",
      "Epoch 10/100 | Train Loss: 0.4887 | Train Acc: 87.23%\n",
      "Validation Loss: 2.3436 | Validation Acc: 52.20% | Sparsity: 89.22%\n",
      "\n",
      "Epoch 11/100 | Train Loss: 0.4278 | Train Acc: 88.91%\n",
      "Validation Loss: 2.3781 | Validation Acc: 52.26% | Sparsity: 89.22%\n",
      "\n",
      "Epoch 12/100 | Train Loss: 0.3685 | Train Acc: 90.64%\n",
      "Validation Loss: 2.4658 | Validation Acc: 51.80% | Sparsity: 89.22%\n",
      "\n",
      "Epoch 13/100 | Train Loss: 0.3236 | Train Acc: 91.80%\n",
      "Validation Loss: 2.5253 | Validation Acc: 51.84% | Sparsity: 89.22%\n",
      "\n",
      "Early stopping triggered at epoch 14. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 52.44% | Best Model Saved at: retrained_student_model_80.pt\n",
      "Retraining completed in 16.48 minutes (988.88 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_80.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain without KD): 52.53%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain without KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 45s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 27.8730 | Train Acc: 56.07% | Val Loss: 2.2529 | Val Acc: 51.29% | Sparsity: 89.22%\n",
      "Epoch 2/50 | Train Loss: 19.7225 | Train Acc: 69.14% | Val Loss: 2.1973 | Val Acc: 53.17% | Sparsity: 89.22%\n",
      "Epoch 3/50 | Train Loss: 16.4280 | Train Acc: 74.95% | Val Loss: 2.1107 | Val Acc: 53.76% | Sparsity: 89.22%\n",
      "Epoch 4/50 | Train Loss: 14.0353 | Train Acc: 79.15% | Val Loss: 2.1627 | Val Acc: 54.23% | Sparsity: 89.22%\n",
      "Epoch 5/50 | Train Loss: 12.1198 | Train Acc: 82.50% | Val Loss: 2.1879 | Val Acc: 53.88% | Sparsity: 89.22%\n",
      "Epoch 6/50 | Train Loss: 10.4491 | Train Acc: 85.61% | Val Loss: 2.2494 | Val Acc: 52.57% | Sparsity: 89.22%\n",
      "Epoch 7/50 | Train Loss: 9.0884 | Train Acc: 88.21% | Val Loss: 2.2734 | Val Acc: 52.82% | Sparsity: 89.22%\n",
      "Epoch 8/50 | Train Loss: 7.8299 | Train Acc: 90.48% | Val Loss: 2.2770 | Val Acc: 52.48% | Sparsity: 89.22%\n",
      "Epoch 9/50 | Train Loss: 6.7699 | Train Acc: 92.34% | Val Loss: 2.3172 | Val Acc: 52.20% | Sparsity: 89.22%\n",
      "Early stopping triggered at epoch 9. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 15m 49s\n",
      "Retraining completed in 15.82 minutes (949.37 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 52.19%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 39s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=6.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy: 0.53%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 10.6875 | Train Acc: 56.91% | Val Loss: 2.2260 | Val Acc: 52.06% | Sparsity: 89.22%\n",
      "Epoch 2/50 | Train Loss: 6.7451 | Train Acc: 73.45% | Val Loss: 2.1636 | Val Acc: 53.09% | Sparsity: 89.22%\n",
      "Epoch 3/50 | Train Loss: 5.3013 | Train Acc: 79.98% | Val Loss: 2.1820 | Val Acc: 53.86% | Sparsity: 89.22%\n",
      "Epoch 4/50 | Train Loss: 4.3263 | Train Acc: 84.48% | Val Loss: 2.1997 | Val Acc: 53.38% | Sparsity: 89.22%\n",
      "Epoch 5/50 | Train Loss: 3.6481 | Train Acc: 87.76% | Val Loss: 2.2236 | Val Acc: 52.86% | Sparsity: 89.22%\n",
      "Epoch 6/50 | Train Loss: 3.0661 | Train Acc: 90.29% | Val Loss: 2.2727 | Val Acc: 52.94% | Sparsity: 89.22%\n",
      "Epoch 7/50 | Train Loss: 2.6082 | Train Acc: 92.57% | Val Loss: 2.2733 | Val Acc: 52.87% | Sparsity: 89.22%\n",
      "Epoch 8/50 | Train Loss: 2.2409 | Train Acc: 94.13% | Val Loss: 2.3140 | Val Acc: 52.44% | Sparsity: 89.22%\n",
      "Early stopping triggered at epoch 8. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 13m 57s\n",
      "Retraining completed in 13.95 minutes (837.02 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 52.26%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 39s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 1.08%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 50.89%\n",
      "Epoch 1/100 | Train Loss: 1.1842 | Train Acc: 73.18%\n",
      "Validation Loss: 2.4256 | Validation Acc: 50.89% | Sparsity: 79.31%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.31%\n",
      "Epoch 2/100 | Train Loss: 0.5174 | Train Acc: 87.06%\n",
      "Validation Loss: 2.3679 | Validation Acc: 52.31% | Sparsity: 79.31%\n",
      "\n",
      "New best model saved with Val Accuracy: 52.98%\n",
      "Epoch 3/100 | Train Loss: 0.3434 | Train Acc: 91.36%\n",
      "Validation Loss: 2.3985 | Validation Acc: 52.98% | Sparsity: 79.31%\n",
      "\n",
      "New best model saved with Val Accuracy: 53.05%\n",
      "Epoch 4/100 | Train Loss: 0.2385 | Train Acc: 94.02%\n",
      "Validation Loss: 2.4798 | Validation Acc: 53.05% | Sparsity: 79.31%\n",
      "\n",
      "New best model saved with Val Accuracy: 53.98%\n",
      "Epoch 5/100 | Train Loss: 0.1666 | Train Acc: 96.00%\n",
      "Validation Loss: 2.5519 | Validation Acc: 53.98% | Sparsity: 79.31%\n",
      "\n",
      "Epoch 6/100 | Train Loss: 0.1185 | Train Acc: 97.25%\n",
      "Validation Loss: 2.6098 | Validation Acc: 53.14% | Sparsity: 79.31%\n",
      "\n",
      "Epoch 7/100 | Train Loss: 0.0847 | Train Acc: 98.23%\n",
      "Validation Loss: 2.7309 | Validation Acc: 53.03% | Sparsity: 79.31%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.0610 | Train Acc: 98.90%\n",
      "Validation Loss: 2.8184 | Validation Acc: 53.16% | Sparsity: 79.31%\n",
      "\n",
      "Epoch 9/100 | Train Loss: 0.0458 | Train Acc: 99.16%\n",
      "Validation Loss: 2.8356 | Validation Acc: 53.14% | Sparsity: 79.31%\n",
      "\n",
      "Early stopping triggered at epoch 10. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 53.98% | Best Model Saved at: retrained_student_model_80.pt\n",
      "Retraining completed in 11.65 minutes (699.27 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_80.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain without KD): 53.41%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain without KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure inference times\n",
    "# pruned_student_inference_time = measure_inference_time(pruned_student, test_loader, device)\n",
    "# print(f\"Student Model Inference Time(After Pruning): {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 44s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 19.0211 | Train Acc: 71.34% | Val Loss: 2.6777 | Val Acc: 51.57% | Sparsity: 79.31%\n",
      "Epoch 2/50 | Train Loss: 12.8240 | Train Acc: 80.88% | Val Loss: 2.6079 | Val Acc: 51.81% | Sparsity: 79.31%\n",
      "Epoch 3/50 | Train Loss: 9.8287 | Train Acc: 86.15% | Val Loss: 2.3964 | Val Acc: 53.67% | Sparsity: 79.31%\n",
      "Epoch 4/50 | Train Loss: 7.6236 | Train Acc: 90.11% | Val Loss: 2.5063 | Val Acc: 52.46% | Sparsity: 79.31%\n",
      "Epoch 5/50 | Train Loss: 5.7970 | Train Acc: 93.44% | Val Loss: 2.3623 | Val Acc: 52.76% | Sparsity: 79.31%\n",
      "Epoch 6/50 | Train Loss: 4.3215 | Train Acc: 96.04% | Val Loss: 2.3580 | Val Acc: 53.19% | Sparsity: 79.31%\n",
      "Epoch 7/50 | Train Loss: 3.2049 | Train Acc: 97.87% | Val Loss: 2.3115 | Val Acc: 54.03% | Sparsity: 79.31%\n",
      "Epoch 8/50 | Train Loss: 2.4023 | Train Acc: 98.97% | Val Loss: 2.2415 | Val Acc: 54.21% | Sparsity: 79.31%\n",
      "Epoch 9/50 | Train Loss: 1.8065 | Train Acc: 99.58% | Val Loss: 2.1415 | Val Acc: 55.56% | Sparsity: 79.31%\n",
      "Epoch 10/50 | Train Loss: 1.4223 | Train Acc: 99.82% | Val Loss: 2.0951 | Val Acc: 56.11% | Sparsity: 79.31%\n",
      "Epoch 11/50 | Train Loss: 1.2026 | Train Acc: 99.92% | Val Loss: 2.0870 | Val Acc: 55.98% | Sparsity: 79.31%\n",
      "Epoch 12/50 | Train Loss: 1.0688 | Train Acc: 99.95% | Val Loss: 2.0634 | Val Acc: 56.57% | Sparsity: 79.31%\n",
      "Epoch 13/50 | Train Loss: 0.9789 | Train Acc: 99.97% | Val Loss: 2.0606 | Val Acc: 56.61% | Sparsity: 79.31%\n",
      "Epoch 14/50 | Train Loss: 0.9181 | Train Acc: 99.97% | Val Loss: 2.0498 | Val Acc: 56.83% | Sparsity: 79.31%\n",
      "Epoch 15/50 | Train Loss: 0.8670 | Train Acc: 99.97% | Val Loss: 2.0417 | Val Acc: 56.45% | Sparsity: 79.31%\n",
      "Epoch 16/50 | Train Loss: 0.8188 | Train Acc: 99.98% | Val Loss: 2.0429 | Val Acc: 57.04% | Sparsity: 79.31%\n",
      "Epoch 17/50 | Train Loss: 0.7914 | Train Acc: 99.98% | Val Loss: 2.0359 | Val Acc: 56.84% | Sparsity: 79.31%\n",
      "Epoch 18/50 | Train Loss: 0.7596 | Train Acc: 99.98% | Val Loss: 2.0356 | Val Acc: 56.60% | Sparsity: 79.31%\n",
      "Epoch 19/50 | Train Loss: 0.7340 | Train Acc: 99.98% | Val Loss: 2.0318 | Val Acc: 56.89% | Sparsity: 79.31%\n",
      "Epoch 20/50 | Train Loss: 0.7099 | Train Acc: 99.98% | Val Loss: 2.0329 | Val Acc: 56.71% | Sparsity: 79.31%\n",
      "Epoch 21/50 | Train Loss: 0.6892 | Train Acc: 99.98% | Val Loss: 2.0396 | Val Acc: 56.99% | Sparsity: 79.31%\n",
      "Early stopping triggered at epoch 21. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 36m 41s\n",
      "Retraining completed in 36.68 minutes (2200.60 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 57.95%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 41s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.8007)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 4.8227 | Train Acc: 83.67% | Val Loss: 2.2431 | Val Acc: 53.88% | Sparsity: 79.31%\n",
      "Epoch 2/50 | Train Loss: 2.0896 | Train Acc: 93.96% | Val Loss: 2.2816 | Val Acc: 54.18% | Sparsity: 79.31%\n",
      "Epoch 3/50 | Train Loss: 1.2789 | Train Acc: 97.50% | Val Loss: 2.2033 | Val Acc: 55.30% | Sparsity: 79.31%\n",
      "Epoch 4/50 | Train Loss: 0.8890 | Train Acc: 98.93% | Val Loss: 2.2408 | Val Acc: 55.04% | Sparsity: 79.31%\n",
      "Epoch 5/50 | Train Loss: 0.6656 | Train Acc: 99.60% | Val Loss: 2.2065 | Val Acc: 55.78% | Sparsity: 79.31%\n",
      "Epoch 6/50 | Train Loss: 0.5401 | Train Acc: 99.84% | Val Loss: 2.1417 | Val Acc: 56.23% | Sparsity: 79.31%\n",
      "Epoch 7/50 | Train Loss: 0.4719 | Train Acc: 99.92% | Val Loss: 2.1386 | Val Acc: 56.26% | Sparsity: 79.31%\n",
      "Epoch 8/50 | Train Loss: 0.4268 | Train Acc: 99.94% | Val Loss: 2.1414 | Val Acc: 56.28% | Sparsity: 79.31%\n",
      "Epoch 9/50 | Train Loss: 0.3950 | Train Acc: 99.96% | Val Loss: 2.1254 | Val Acc: 56.20% | Sparsity: 79.31%\n",
      "Epoch 10/50 | Train Loss: 0.3702 | Train Acc: 99.96% | Val Loss: 2.1243 | Val Acc: 56.22% | Sparsity: 79.31%\n",
      "Epoch 11/50 | Train Loss: 0.3486 | Train Acc: 99.97% | Val Loss: 2.1227 | Val Acc: 56.33% | Sparsity: 79.31%\n",
      "Epoch 12/50 | Train Loss: 0.3371 | Train Acc: 99.97% | Val Loss: 2.1289 | Val Acc: 56.24% | Sparsity: 79.31%\n",
      "Epoch 13/50 | Train Loss: 0.3244 | Train Acc: 99.98% | Val Loss: 2.1139 | Val Acc: 55.99% | Sparsity: 79.31%\n",
      "Epoch 14/50 | Train Loss: 0.3147 | Train Acc: 99.97% | Val Loss: 2.1058 | Val Acc: 56.34% | Sparsity: 79.31%\n",
      "Epoch 15/50 | Train Loss: 0.3030 | Train Acc: 99.98% | Val Loss: 2.1088 | Val Acc: 56.54% | Sparsity: 79.31%\n",
      "Epoch 16/50 | Train Loss: 0.2937 | Train Acc: 99.98% | Val Loss: 2.1061 | Val Acc: 56.41% | Sparsity: 79.31%\n",
      "Epoch 17/50 | Train Loss: 0.2845 | Train Acc: 99.98% | Val Loss: 2.1159 | Val Acc: 56.40% | Sparsity: 79.31%\n",
      "Epoch 18/50 | Train Loss: 0.2781 | Train Acc: 99.98% | Val Loss: 2.1073 | Val Acc: 56.34% | Sparsity: 79.31%\n",
      "Epoch 19/50 | Train Loss: 0.2712 | Train Acc: 99.98% | Val Loss: 2.1164 | Val Acc: 56.38% | Sparsity: 79.31%\n",
      "Epoch 20/50 | Train Loss: 0.2660 | Train Acc: 99.98% | Val Loss: 2.1184 | Val Acc: 56.53% | Sparsity: 79.31%\n",
      "Early stopping triggered at epoch 20. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 35m 11s\n",
      "Retraining completed in 35.18 minutes (2110.99 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Student Model Test Accuracy(Retrain with KD): 56.54%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75% of Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 45s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 2.63%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 52.35%\n",
      "Epoch 1/100 | Train Loss: 0.7020 | Train Acc: 83.90%\n",
      "Validation Loss: 2.4453 | Validation Acc: 52.35% | Sparsity: 74.35%\n",
      "\n",
      "New best model saved with Val Accuracy: 54.02%\n",
      "Epoch 2/100 | Train Loss: 0.2546 | Train Acc: 93.72%\n",
      "Validation Loss: 2.4056 | Validation Acc: 54.02% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 3/100 | Train Loss: 0.1488 | Train Acc: 96.48%\n",
      "Validation Loss: 2.4950 | Validation Acc: 53.80% | Sparsity: 74.35%\n",
      "\n",
      "New best model saved with Val Accuracy: 54.21%\n",
      "Epoch 4/100 | Train Loss: 0.0903 | Train Acc: 98.06%\n",
      "Validation Loss: 2.5649 | Validation Acc: 54.21% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 5/100 | Train Loss: 0.0597 | Train Acc: 98.79%\n",
      "Validation Loss: 2.6377 | Validation Acc: 54.11% | Sparsity: 74.35%\n",
      "\n",
      "New best model saved with Val Accuracy: 54.27%\n",
      "Epoch 6/100 | Train Loss: 0.0415 | Train Acc: 99.28%\n",
      "Validation Loss: 2.6783 | Validation Acc: 54.27% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 7/100 | Train Loss: 0.0299 | Train Acc: 99.52%\n",
      "Validation Loss: 2.7515 | Validation Acc: 54.20% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 8/100 | Train Loss: 0.0225 | Train Acc: 99.71%\n",
      "Validation Loss: 2.7779 | Validation Acc: 54.09% | Sparsity: 74.35%\n",
      "\n",
      "New best model saved with Val Accuracy: 54.33%\n",
      "Epoch 9/100 | Train Loss: 0.0181 | Train Acc: 99.78%\n",
      "Validation Loss: 2.8035 | Validation Acc: 54.33% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 10/100 | Train Loss: 0.0151 | Train Acc: 99.84%\n",
      "Validation Loss: 2.8198 | Validation Acc: 54.18% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 11/100 | Train Loss: 0.0132 | Train Acc: 99.84%\n",
      "Validation Loss: 2.8502 | Validation Acc: 54.02% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 12/100 | Train Loss: 0.0116 | Train Acc: 99.87%\n",
      "Validation Loss: 2.8906 | Validation Acc: 53.82% | Sparsity: 74.35%\n",
      "\n",
      "Epoch 13/100 | Train Loss: 0.0104 | Train Acc: 99.88%\n",
      "Validation Loss: 2.8822 | Validation Acc: 54.06% | Sparsity: 74.35%\n",
      "\n",
      "Early stopping triggered at epoch 14. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 54.33% | Best Model Saved at: retrained_student_model_75.pt\n",
      "Retraining completed in 16.49 minutes (989.23 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=100,  save_path='retrained_student_model_75.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 54.39%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(retrained_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure inference times\n",
    "# pruned_student_inference_time = measure_inference_time(retrained_student, test_loader,)\n",
    "# print(f\" Retrained pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain with KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 45s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "student = student.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 16.3893 | Train Acc: 75.71% | Val Loss: 2.7591 | Val Acc: 50.23% | Sparsity: 74.35%\n",
      "Epoch 2/50 | Train Loss: 11.1141 | Train Acc: 83.66% | Val Loss: 2.4510 | Val Acc: 51.89% | Sparsity: 74.35%\n",
      "Epoch 3/50 | Train Loss: 8.1134 | Train Acc: 89.09% | Val Loss: 2.5687 | Val Acc: 52.45% | Sparsity: 74.35%\n",
      "Epoch 4/50 | Train Loss: 6.0443 | Train Acc: 92.87% | Val Loss: 2.3957 | Val Acc: 53.21% | Sparsity: 74.35%\n",
      "Epoch 5/50 | Train Loss: 4.2513 | Train Acc: 96.06% | Val Loss: 2.3610 | Val Acc: 52.90% | Sparsity: 74.35%\n",
      "Epoch 6/50 | Train Loss: 3.0376 | Train Acc: 98.02% | Val Loss: 2.3233 | Val Acc: 53.96% | Sparsity: 74.35%\n",
      "Epoch 7/50 | Train Loss: 2.1287 | Train Acc: 99.22% | Val Loss: 2.1679 | Val Acc: 55.53% | Sparsity: 74.35%\n",
      "Epoch 8/50 | Train Loss: 1.5716 | Train Acc: 99.73% | Val Loss: 2.1225 | Val Acc: 56.49% | Sparsity: 74.35%\n",
      "Epoch 9/50 | Train Loss: 1.2264 | Train Acc: 99.91% | Val Loss: 2.0639 | Val Acc: 57.38% | Sparsity: 74.35%\n",
      "Epoch 10/50 | Train Loss: 1.0522 | Train Acc: 99.95% | Val Loss: 2.0236 | Val Acc: 57.87% | Sparsity: 74.35%\n",
      "Epoch 11/50 | Train Loss: 0.9429 | Train Acc: 99.97% | Val Loss: 2.0212 | Val Acc: 57.57% | Sparsity: 74.35%\n",
      "Epoch 12/50 | Train Loss: 0.8606 | Train Acc: 99.98% | Val Loss: 2.0155 | Val Acc: 57.90% | Sparsity: 74.35%\n",
      "Epoch 13/50 | Train Loss: 0.8048 | Train Acc: 99.98% | Val Loss: 1.9982 | Val Acc: 58.20% | Sparsity: 74.35%\n",
      "Epoch 14/50 | Train Loss: 0.7661 | Train Acc: 99.98% | Val Loss: 2.0052 | Val Acc: 57.85% | Sparsity: 74.35%\n",
      "Epoch 15/50 | Train Loss: 0.7256 | Train Acc: 99.98% | Val Loss: 2.0020 | Val Acc: 57.84% | Sparsity: 74.35%\n",
      "Epoch 16/50 | Train Loss: 0.6976 | Train Acc: 99.98% | Val Loss: 1.9987 | Val Acc: 58.35% | Sparsity: 74.35%\n",
      "Epoch 17/50 | Train Loss: 0.6743 | Train Acc: 99.99% | Val Loss: 1.9955 | Val Acc: 58.39% | Sparsity: 74.35%\n",
      "Epoch 18/50 | Train Loss: 0.6585 | Train Acc: 99.98% | Val Loss: 2.0069 | Val Acc: 57.74% | Sparsity: 74.35%\n",
      "Epoch 19/50 | Train Loss: 0.6337 | Train Acc: 99.98% | Val Loss: 1.9937 | Val Acc: 58.03% | Sparsity: 74.35%\n",
      "Epoch 20/50 | Train Loss: 0.6156 | Train Acc: 99.98% | Val Loss: 2.0094 | Val Acc: 57.59% | Sparsity: 74.35%\n",
      "Epoch 21/50 | Train Loss: 0.6034 | Train Acc: 99.98% | Val Loss: 2.0166 | Val Acc: 57.88% | Sparsity: 74.35%\n",
      "Epoch 22/50 | Train Loss: 0.5886 | Train Acc: 99.98% | Val Loss: 2.0101 | Val Acc: 58.23% | Sparsity: 74.35%\n",
      "Early stopping triggered at epoch 22. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 38m 52s\n",
      "Retraining completed in 38.86 minutes (2331.56 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 58.58%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Measure inference times\n",
    "# pruned_student_inference_time = measure_inference_time(pruned_student, test_loader, device)\n",
    "# print(f\" Retrained pruned Student Model Inference Time: {pruned_student_inference_time * 1000:.2f} ms per batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 45s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.75062)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 3.0841 | Train Acc: 91.23% | Val Loss: 2.2603 | Val Acc: 54.56% | Sparsity: 74.35%\n",
      "Epoch 2/50 | Train Loss: 1.1697 | Train Acc: 97.70% | Val Loss: 2.2637 | Val Acc: 54.63% | Sparsity: 74.35%\n",
      "Epoch 3/50 | Train Loss: 0.7056 | Train Acc: 99.39% | Val Loss: 2.1838 | Val Acc: 55.29% | Sparsity: 74.35%\n",
      "Epoch 4/50 | Train Loss: 0.5166 | Train Acc: 99.83% | Val Loss: 2.1493 | Val Acc: 56.03% | Sparsity: 74.35%\n",
      "Epoch 5/50 | Train Loss: 0.4266 | Train Acc: 99.93% | Val Loss: 2.1156 | Val Acc: 56.55% | Sparsity: 74.35%\n",
      "Epoch 6/50 | Train Loss: 0.3834 | Train Acc: 99.96% | Val Loss: 2.0867 | Val Acc: 56.75% | Sparsity: 74.35%\n",
      "Epoch 7/50 | Train Loss: 0.3470 | Train Acc: 99.97% | Val Loss: 2.0840 | Val Acc: 56.72% | Sparsity: 74.35%\n",
      "Epoch 8/50 | Train Loss: 0.3227 | Train Acc: 99.98% | Val Loss: 2.0773 | Val Acc: 57.03% | Sparsity: 74.35%\n",
      "Epoch 9/50 | Train Loss: 0.3055 | Train Acc: 99.98% | Val Loss: 2.0824 | Val Acc: 56.68% | Sparsity: 74.35%\n",
      "Epoch 10/50 | Train Loss: 0.2918 | Train Acc: 99.98% | Val Loss: 2.0843 | Val Acc: 56.92% | Sparsity: 74.35%\n",
      "Epoch 11/50 | Train Loss: 0.2790 | Train Acc: 99.98% | Val Loss: 2.0722 | Val Acc: 57.00% | Sparsity: 74.35%\n",
      "Epoch 12/50 | Train Loss: 0.2703 | Train Acc: 99.98% | Val Loss: 2.0640 | Val Acc: 56.79% | Sparsity: 74.35%\n",
      "Epoch 13/50 | Train Loss: 0.2633 | Train Acc: 99.98% | Val Loss: 2.0669 | Val Acc: 56.79% | Sparsity: 74.35%\n",
      "Early stopping triggered at epoch 13. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 22m 43s\n",
      "Retraining completed in 22.72 minutes (1362.91 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 57.42%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50% Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 43s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Test Accuracy After Pruning: 27.79%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\"Student Model Test Accuracy After Pruning: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with Val Accuracy: 57.59%\n",
      "Epoch 1/200 | Train Loss: 0.0226 | Train Acc: 99.65%\n",
      "Validation Loss: 2.2924 | Validation Acc: 57.59% | Sparsity: 50.02%\n",
      "\n",
      "New best model saved with Val Accuracy: 57.82%\n",
      "Epoch 2/200 | Train Loss: 0.0086 | Train Acc: 99.89%\n",
      "Validation Loss: 2.2752 | Validation Acc: 57.82% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 3/200 | Train Loss: 0.0059 | Train Acc: 99.94%\n",
      "Validation Loss: 2.2870 | Validation Acc: 57.57% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 4/200 | Train Loss: 0.0045 | Train Acc: 99.97%\n",
      "Validation Loss: 2.3075 | Validation Acc: 57.57% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 5/200 | Train Loss: 0.0041 | Train Acc: 99.96%\n",
      "Validation Loss: 2.3115 | Validation Acc: 57.67% | Sparsity: 50.02%\n",
      "\n",
      "New best model saved with Val Accuracy: 57.89%\n",
      "Epoch 6/200 | Train Loss: 0.0032 | Train Acc: 99.97%\n",
      "Validation Loss: 2.3337 | Validation Acc: 57.89% | Sparsity: 50.02%\n",
      "\n",
      "New best model saved with Val Accuracy: 57.98%\n",
      "Epoch 7/200 | Train Loss: 0.0031 | Train Acc: 99.97%\n",
      "Validation Loss: 2.3001 | Validation Acc: 57.98% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 8/200 | Train Loss: 0.0030 | Train Acc: 99.96%\n",
      "Validation Loss: 2.3073 | Validation Acc: 57.70% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 9/200 | Train Loss: 0.0026 | Train Acc: 99.97%\n",
      "Validation Loss: 2.2829 | Validation Acc: 57.83% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 10/200 | Train Loss: 0.0024 | Train Acc: 99.97%\n",
      "Validation Loss: 2.3234 | Validation Acc: 57.69% | Sparsity: 50.02%\n",
      "\n",
      "Epoch 11/200 | Train Loss: 0.0022 | Train Acc: 99.97%\n",
      "Validation Loss: 2.3390 | Validation Acc: 57.76% | Sparsity: 50.02%\n",
      "\n",
      "Early stopping triggered at epoch 12. No improvement for 5 epochs.\n",
      "Best Validation Accuracy: 57.98% | Best Model Saved at: retrained_student_model_50%.pt\n",
      "Retraining completed in 14.20 minutes (852.17 seconds)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "retrained_student = retrain_with_sparsity(\n",
    "    pruned_student, train_loader, val_loader,\n",
    "    epochs=200,  save_path='retrained_student_model_50%.pt',patience=5\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 58.53%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 44s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 7.6188 | Train Acc: 90.40% | Val Loss: 2.6825 | Val Acc: 50.49% | Sparsity: 50.02%\n",
      "Epoch 2/50 | Train Loss: 8.4020 | Train Acc: 88.52% | Val Loss: 2.6937 | Val Acc: 51.04% | Sparsity: 50.02%\n",
      "Epoch 3/50 | Train Loss: 5.2672 | Train Acc: 94.08% | Val Loss: 2.5011 | Val Acc: 53.16% | Sparsity: 50.02%\n",
      "Epoch 4/50 | Train Loss: 3.2214 | Train Acc: 97.60% | Val Loss: 2.3296 | Val Acc: 55.88% | Sparsity: 50.02%\n",
      "Epoch 5/50 | Train Loss: 1.9449 | Train Acc: 99.33% | Val Loss: 2.1442 | Val Acc: 57.25% | Sparsity: 50.02%\n",
      "Epoch 6/50 | Train Loss: 1.2713 | Train Acc: 99.86% | Val Loss: 2.0737 | Val Acc: 58.65% | Sparsity: 50.02%\n",
      "Epoch 7/50 | Train Loss: 0.9714 | Train Acc: 99.96% | Val Loss: 2.0289 | Val Acc: 59.13% | Sparsity: 50.02%\n",
      "Epoch 8/50 | Train Loss: 0.8093 | Train Acc: 99.97% | Val Loss: 1.9882 | Val Acc: 59.89% | Sparsity: 50.02%\n",
      "Epoch 9/50 | Train Loss: 0.7132 | Train Acc: 99.98% | Val Loss: 1.9695 | Val Acc: 60.02% | Sparsity: 50.02%\n",
      "Epoch 10/50 | Train Loss: 0.6560 | Train Acc: 99.98% | Val Loss: 1.9732 | Val Acc: 60.33% | Sparsity: 50.02%\n",
      "Epoch 11/50 | Train Loss: 0.6104 | Train Acc: 99.98% | Val Loss: 1.9534 | Val Acc: 60.57% | Sparsity: 50.02%\n",
      "Epoch 12/50 | Train Loss: 0.5789 | Train Acc: 99.98% | Val Loss: 1.9628 | Val Acc: 60.03% | Sparsity: 50.02%\n",
      "Epoch 13/50 | Train Loss: 0.5537 | Train Acc: 99.98% | Val Loss: 1.9608 | Val Acc: 60.27% | Sparsity: 50.02%\n",
      "Epoch 14/50 | Train Loss: 0.5339 | Train Acc: 99.99% | Val Loss: 1.9711 | Val Acc: 60.27% | Sparsity: 50.02%\n",
      "Epoch 15/50 | Train Loss: 0.5139 | Train Acc: 99.98% | Val Loss: 1.9466 | Val Acc: 60.40% | Sparsity: 50.02%\n",
      "Epoch 16/50 | Train Loss: 0.4968 | Train Acc: 99.98% | Val Loss: 1.9561 | Val Acc: 60.53% | Sparsity: 50.02%\n",
      "Early stopping triggered at epoch 16. No improvement for 5 epochs.\n",
      "Student model saved before pruning at: pruned_student_retrain_KD_90%.pth\n",
      "Total Training Time: 27m 46s\n",
      "Retraining completed in 27.77 minutes (1666.38 seconds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrained Pruned Student Model Test Accuracy: 60.93%\n"
     ]
    }
   ],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_path = 'student_before_pruning.pth'\n",
    "# Load the model weights\n",
    "student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Important Scores\n",
      "Accumulation Epoch 1/3\n",
      "Accumulation Epoch 2/3\n",
      "Accumulation Epoch 3/3\n",
      "Total Time take to calculate Important scores: 4m 33s\n",
      "Pruning the model\n",
      "Total Time take to prune the model scores: 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "print(\"Calculating Important Scores\")\n",
    "start_time = time.time()\n",
    "importance_scores = compute_gradient_importance(\n",
    "    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n",
    "print(\"Pruning the model\")\n",
    "start_time = time.time()\n",
    "\n",
    "pruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.505)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.4386 | Train Acc: 99.92% | Val Loss: 2.1028 | Val Acc: 58.50% | Sparsity: 50.02%\n",
      "Epoch 2/50 | Train Loss: 0.2524 | Train Acc: 99.98% | Val Loss: 2.0408 | Val Acc: 59.21% | Sparsity: 50.02%\n",
      "Epoch 3/50 | Train Loss: 0.2250 | Train Acc: 99.98% | Val Loss: 2.0560 | Val Acc: 58.99% | Sparsity: 50.02%\n",
      "Epoch 4/50 | Train Loss: 0.2084 | Train Acc: 99.98% | Val Loss: 2.0333 | Val Acc: 59.06% | Sparsity: 50.02%\n",
      "Epoch 5/50 | Train Loss: 0.1974 | Train Acc: 99.98% | Val Loss: 2.0252 | Val Acc: 59.21% | Sparsity: 50.02%\n",
      "Epoch 6/50 | Train Loss: 0.1884 | Train Acc: 99.98% | Val Loss: 2.0225 | Val Acc: 59.21% | Sparsity: 50.02%\n",
      "Epoch 7/50 | Train Loss: 0.1828 | Train Acc: 99.98% | Val Loss: 2.0204 | Val Acc: 59.39% | Sparsity: 50.02%\n",
      "Epoch 8/50 | Train Loss: 0.1775 | Train Acc: 99.98% | Val Loss: 2.0089 | Val Acc: 59.38% | Sparsity: 50.02%\n",
      "Epoch 9/50 | Train Loss: 0.1736 | Train Acc: 99.98% | Val Loss: 2.0135 | Val Acc: 59.47% | Sparsity: 50.02%\n",
      "Epoch 10/50 | Train Loss: 0.1694 | Train Acc: 99.98% | Val Loss: 2.0140 | Val Acc: 59.20% | Sparsity: 50.02%\n",
      "Epoch 11/50 | Train Loss: 0.1671 | Train Acc: 99.98% | Val Loss: 2.0108 | Val Acc: 59.36% | Sparsity: 50.02%\n",
      "Epoch 12/50 | Train Loss: 0.1633 | Train Acc: 99.98% | Val Loss: 2.0152 | Val Acc: 59.36% | Sparsity: 50.02%\n",
      "Epoch 13/50 | Train Loss: 0.1608 | Train Acc: 99.99% | Val Loss: 2.0093 | Val Acc: 59.52% | Sparsity: 50.02%\n",
      "Epoch 14/50 | Train Loss: 0.1589 | Train Acc: 99.98% | Val Loss: 2.0076 | Val Acc: 59.44% | Sparsity: 50.02%\n",
      "Epoch 15/50 | Train Loss: 0.1558 | Train Acc: 99.98% | Val Loss: 2.0108 | Val Acc: 59.38% | Sparsity: 50.02%\n",
      "Epoch 16/50 | Train Loss: 0.1534 | Train Acc: 99.98% | Val Loss: 2.0004 | Val Acc: 59.53% | Sparsity: 50.02%\n",
      "Epoch 17/50 | Train Loss: 0.1518 | Train Acc: 99.98% | Val Loss: 2.0090 | Val Acc: 59.40% | Sparsity: 50.02%\n",
      "Epoch 18/50 | Train Loss: 0.1500 | Train Acc: 99.98% | Val Loss: 2.0027 | Val Acc: 59.38% | Sparsity: 50.02%\n",
      "Epoch 19/50 | Train Loss: 0.1479 | Train Acc: 99.98% | Val Loss: 1.9977 | Val Acc: 59.57% | Sparsity: 50.02%\n",
      "Epoch 20/50 | Train Loss: 0.1467 | Train Acc: 99.98% | Val Loss: 1.9990 | Val Acc: 59.45% | Sparsity: 50.02%\n",
      "Epoch 21/50 | Train Loss: 0.1445 | Train Acc: 99.98% | Val Loss: 2.0015 | Val Acc: 59.29% | Sparsity: 50.02%\n",
      "Epoch 22/50 | Train Loss: 0.1430 | Train Acc: 99.98% | Val Loss: 2.0073 | Val Acc: 59.52% | Sparsity: 50.02%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pruned_student = retrain_with_KD(\n",
    "    teacher, pruned_student, train_loader, val_loader,\n",
    "    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_accuracy = evaluate(pruned_student, test_loader, device)\n",
    "print(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": false,
     "modelId": 268576,
     "modelInstanceId": 247034,
     "sourceId": 288333,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
