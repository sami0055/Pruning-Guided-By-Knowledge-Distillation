{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":360308,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":299802,"modelId":320374},{"sourceId":360371,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":299842,"modelId":320413}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:27:51.839403Z","iopub.execute_input":"2025-05-08T07:27:51.839866Z","iopub.status.idle":"2025-05-08T07:27:55.560431Z","shell.execute_reply.started":"2025-05-08T07:27:51.839840Z","shell.execute_reply":"2025-05-08T07:27:55.559618Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\n\nprint(\"PyTorch version:\", torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:27:55.561801Z","iopub.execute_input":"2025-05-08T07:27:55.562054Z","iopub.status.idle":"2025-05-08T07:27:57.198516Z","shell.execute_reply.started":"2025-05-08T07:27:55.562034Z","shell.execute_reply":"2025-05-08T07:27:57.197822Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.5.1+cu124\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport time","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:27:57.199376Z","iopub.execute_input":"2025-05-08T07:27:57.199773Z","iopub.status.idle":"2025-05-08T07:28:00.484664Z","shell.execute_reply.started":"2025-05-08T07:27:57.199748Z","shell.execute_reply":"2025-05-08T07:28:00.483956Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:00.486490Z","iopub.execute_input":"2025-05-08T07:28:00.487038Z","iopub.status.idle":"2025-05-08T07:28:00.544329Z","shell.execute_reply.started":"2025-05-08T07:28:00.487015Z","shell.execute_reply":"2025-05-08T07:28:00.543594Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:00.545154Z","iopub.execute_input":"2025-05-08T07:28:00.545424Z","iopub.status.idle":"2025-05-08T07:28:00.570477Z","shell.execute_reply.started":"2025-05-08T07:28:00.545405Z","shell.execute_reply":"2025-05-08T07:28:00.569776Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Data augmentation for training\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n    transforms.RandomCrop(32, padding=4),  # Randomly crop the image\n    transforms.Resize(224),  # Resize to 224x224 for ResNet\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# No augmentation for validation and test\nval_test_transform = transforms.Compose([\n    transforms.Resize(224),  # Resize to 224x224 for ResNet\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load CIFAR-10 dataset\ntrain_val_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=val_test_transform)\n\n# Split train_val_dataset into train and validation sets (80% train, 20% validation)\ntrain_size = int(0.8 * len(train_val_dataset))\nval_size = len(train_val_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n\n# Apply val_test_transform to the validation set\nval_dataset.dataset.transform = val_test_transform\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:00.571120Z","iopub.execute_input":"2025-05-08T07:28:00.571283Z","iopub.status.idle":"2025-05-08T07:28:12.160715Z","shell.execute_reply.started":"2025-05-08T07:28:00.571270Z","shell.execute_reply":"2025-05-08T07:28:12.159915Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:08<00:00, 21.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load pretrained ResNet-50 (Teacher Model)\nteacher = models.resnet50(pretrained=False)\n\n# Modify the final fully connected layer for 10 classes (CIFAR-10)\nteacher.fc = nn.Linear(teacher.fc.in_features, 10)\n# Move models to device\nteacher = teacher.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:12.161633Z","iopub.execute_input":"2025-05-08T07:28:12.161862Z","iopub.status.idle":"2025-05-08T07:28:12.719276Z","shell.execute_reply.started":"2025-05-08T07:28:12.161846Z","shell.execute_reply":"2025-05-08T07:28:12.718538Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/teacherc10/pytorch/default/1/Best_Teacher.pth'\n# Load the model weights\nteacher.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:12.720986Z","iopub.execute_input":"2025-05-08T07:28:12.721216Z","iopub.status.idle":"2025-05-08T07:28:13.698236Z","shell.execute_reply.started":"2025-05-08T07:28:12.721194Z","shell.execute_reply":"2025-05-08T07:28:13.697615Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1084507953.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  teacher.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Load pretrained ResNet-18 (Student Model)\nstudent = models.resnet18(pretrained=True)\n# Modify the final fully connected layer for 10 classes (CIFAR-10)\nstudent.fc = nn.Linear(student.fc.in_features, 10)\nstudent = student.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:13.698907Z","iopub.execute_input":"2025-05-08T07:28:13.699114Z","iopub.status.idle":"2025-05-08T07:28:14.532229Z","shell.execute_reply.started":"2025-05-08T07:28:13.699098Z","shell.execute_reply":"2025-05-08T07:28:14.531450Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 84.0MB/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:14.533043Z","iopub.execute_input":"2025-05-08T07:28:14.533299Z","iopub.status.idle":"2025-05-08T07:28:14.915416Z","shell.execute_reply.started":"2025-05-08T07:28:14.533278Z","shell.execute_reply":"2025-05-08T07:28:14.914686Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Logits normalization function\ndef normalize(logit):\n    mean = logit.mean(dim=-1, keepdim=True)\n    stdv = logit.std(dim=-1, keepdim=True)\n    return (logit - mean) / (1e-7 + stdv)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:17.684987Z","iopub.execute_input":"2025-05-08T07:28:17.685512Z","iopub.status.idle":"2025-05-08T07:28:17.689140Z","shell.execute_reply.started":"2025-05-08T07:28:17.685488Z","shell.execute_reply":"2025-05-08T07:28:17.688470Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# CA-KLD Loss for Classification\ndef cakld_loss(student_logits, teacher_logits, beta_prob):\n    # Forward KL (student || teacher)\n    student_log_prob = F.log_softmax(student_logits, dim=1)\n    teacher_prob = F.softmax(teacher_logits, dim=1)\n    forward_kl = F.kl_div(student_log_prob, teacher_prob, reduction='batchmean')\n\n    # Reverse KL (teacher || student)\n    teacher_log_prob = F.log_softmax(teacher_logits, dim=1)\n    student_prob = F.softmax(student_logits, dim=1)\n    reverse_kl = F.kl_div(teacher_log_prob, student_prob, reduction='batchmean')\n\n    # Combined KL loss\n    kl_loss = beta_prob * reverse_kl + (1 - beta_prob) * forward_kl\n    return kl_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:17.804028Z","iopub.execute_input":"2025-05-08T07:28:17.804705Z","iopub.status.idle":"2025-05-08T07:28:17.809216Z","shell.execute_reply.started":"2025-05-08T07:28:17.804683Z","shell.execute_reply":"2025-05-08T07:28:17.808465Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(model, test_loader, device):\n    model = model.to(device)  # Ensure model is on the correct device\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return 100 * correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:17.932958Z","iopub.execute_input":"2025-05-08T07:28:17.933235Z","iopub.status.idle":"2025-05-08T07:28:17.938211Z","shell.execute_reply.started":"2025-05-08T07:28:17.933216Z","shell.execute_reply":"2025-05-08T07:28:17.937548Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def calculate_sparsity(model):\n    total_zeros = 0\n    total_params = 0\n    for name, param in model.named_parameters():\n        if 'weight' in name:\n            total_zeros += torch.sum(param == 0).item()\n            total_params += param.numel()\n    return total_zeros / total_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:18.089795Z","iopub.execute_input":"2025-05-08T07:28:18.090032Z","iopub.status.idle":"2025-05-08T07:28:18.094308Z","shell.execute_reply.started":"2025-05-08T07:28:18.090016Z","shell.execute_reply":"2025-05-08T07:28:18.093613Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nimport time\ndef measure_inference_time(model, test_loader, num_runs=5):\n    device = torch.device('cpu')\n    model.eval()\n    model.to(device)\n\n    # Warm-up (one batch to avoid startup cost)\n    with torch.no_grad():\n        for inputs, _ in test_loader:\n            inputs = inputs.to(device)\n            _ = model(inputs)\n            break\n\n    total_time = 0\n    total_images = 0\n\n    with torch.no_grad():\n        for _ in range(num_runs):\n            for inputs, _ in test_loader:\n                inputs = inputs.to(device)\n                batch_size = inputs.size(0)\n                start_time = time.time()\n                _ = model(inputs)\n                end_time = time.time()\n\n                total_time += (end_time - start_time)\n                total_images += batch_size\n\n    avg_time_per_image = total_time / total_images\n    return avg_time_per_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:18.251024Z","iopub.execute_input":"2025-05-08T07:28:18.251734Z","iopub.status.idle":"2025-05-08T07:28:18.256847Z","shell.execute_reply.started":"2025-05-08T07:28:18.251709Z","shell.execute_reply":"2025-05-08T07:28:18.256129Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters())\n\ndef calculate_model_size(model, filename=\"temp.pth\"):\n    torch.save(model.state_dict(), filename)\n    size = os.path.getsize(filename) / (1024 * 1024)  # Size in MB\n    os.remove(filename)\n    return size\n\ndef compare_model_sizes(teacher, student, pruned_student):\n    # Count parameters\n    teacher_params = count_parameters(teacher)\n    student_params = count_parameters(student)\n    pruned_params = count_parameters(pruned_student)\n    \n    # Calculate disk size\n    teacher_size = calculate_model_size(teacher, \"teacher.pth\")\n    student_size = calculate_model_size(student, \"student.pth\")\n    pruned_size = calculate_model_size(pruned_student, \"pruned_student.pth\")\n    \n    # Print comparison\n    print(\"\\n--- Model Size Comparison ---\")\n    print(f\"Teacher Model: {teacher_params} parameters, {teacher_size:.2f} MB\")\n    print(f\"Student Model (Before Pruning): {student_params} parameters, {student_size:.2f} MB\")\n    print(f\"Student Model (After Pruning): {pruned_params} parameters, {pruned_size:.2f} MB\")\n    \n    # Calculate compression ratio\n    compression_ratio = student_size / pruned_size\n    print(f\"\\nCompression Ratio: {compression_ratio:.2f}x\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:21.215912Z","iopub.execute_input":"2025-05-08T07:28:21.216595Z","iopub.status.idle":"2025-05-08T07:28:21.222114Z","shell.execute_reply.started":"2025-05-08T07:28:21.216550Z","shell.execute_reply":"2025-05-08T07:28:21.221337Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, patience=3):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n    \n    best_val_accuracy = 0.0\n    best_model_state = None\n    patience_counter = 0  # Counter for early stopping\n    \n    for epoch in range(epochs):\n        print(epoch)\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        # Evaluate on the validation set\n        val_accuracy = evaluate(model, val_loader, device)\n        print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n        \n        # Early stopping logic\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_model_state = model.state_dict()\n            patience_counter = 0  # Reset patience counter\n            torch.save(model.state_dict(), 'best_teacher_model.pth')  # Save the best model\n            print(f\" New best model saved with validation accuracy: {best_val_accuracy:.2f}%\")\n        else:\n            patience_counter += 1\n            print(f\" No improvement in validation accuracy ({patience_counter}/{patience})\")\n            \n            # Stop training if no improvement for 'patience' epochs\n            if patience_counter >= patience:\n                print(f\"\\nEarly stopping triggered! No improvement for {patience} epochs.\")\n                break\n    \n    # Load the best model state\n    model.load_state_dict(torch.load('best_teacher_model.pth'))\n    print(\"\\nLoading the best model for final evaluation.\")\n    \n    # Evaluate on the test set\n    test_accuracy = evaluate(model, test_loader, device)\n    print(f\"Test Accuracy with Best Model: {test_accuracy:.2f}%\")\n    \n    return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:21.960521Z","iopub.execute_input":"2025-05-08T07:28:21.961217Z","iopub.status.idle":"2025-05-08T07:28:21.968133Z","shell.execute_reply.started":"2025-05-08T07:28:21.961192Z","shell.execute_reply":"2025-05-08T07:28:21.967513Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\ntch = train_model(\n    teacher, train_loader, val_loader,\n    epochs=50, lr=0.001, patience=5\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:21:20.500832Z","iopub.execute_input":"2025-04-28T11:21:20.501059Z","execution_failed":"2025-04-28T14:01:00.152Z"}},"outputs":[{"name":"stdout","text":"0\nEpoch 1/50 | Loss: 2.1086 | Val Accuracy: 27.72%\n New best model saved with validation accuracy: 27.72%\n1\nEpoch 2/50 | Loss: 1.8309 | Val Accuracy: 31.25%\n New best model saved with validation accuracy: 31.25%\n2\nEpoch 3/50 | Loss: 1.6877 | Val Accuracy: 37.42%\n New best model saved with validation accuracy: 37.42%\n3\nEpoch 4/50 | Loss: 1.5755 | Val Accuracy: 43.93%\n New best model saved with validation accuracy: 43.93%\n4\nEpoch 5/50 | Loss: 1.5001 | Val Accuracy: 45.49%\n New best model saved with validation accuracy: 45.49%\n5\nEpoch 6/50 | Loss: 1.4215 | Val Accuracy: 48.98%\n New best model saved with validation accuracy: 48.98%\n6\nEpoch 7/50 | Loss: 1.3491 | Val Accuracy: 50.04%\n New best model saved with validation accuracy: 50.04%\n7\nEpoch 8/50 | Loss: 1.2896 | Val Accuracy: 51.79%\n New best model saved with validation accuracy: 51.79%\n8\nEpoch 9/50 | Loss: 1.2194 | Val Accuracy: 53.57%\n New best model saved with validation accuracy: 53.57%\n9\nEpoch 10/50 | Loss: 1.1558 | Val Accuracy: 58.35%\n New best model saved with validation accuracy: 58.35%\n10\nEpoch 11/50 | Loss: 1.1020 | Val Accuracy: 55.04%\n No improvement in validation accuracy (1/5)\n11\nEpoch 12/50 | Loss: 1.0472 | Val Accuracy: 60.52%\n New best model saved with validation accuracy: 60.52%\n12\nEpoch 13/50 | Loss: 0.9741 | Val Accuracy: 60.43%\n No improvement in validation accuracy (1/5)\n13\nEpoch 14/50 | Loss: 0.9159 | Val Accuracy: 61.12%\n New best model saved with validation accuracy: 61.12%\n14\nEpoch 15/50 | Loss: 0.8516 | Val Accuracy: 59.48%\n No improvement in validation accuracy (1/5)\n15\nEpoch 16/50 | Loss: 0.7909 | Val Accuracy: 62.21%\n New best model saved with validation accuracy: 62.21%\n16\nEpoch 17/50 | Loss: 0.7210 | Val Accuracy: 61.71%\n No improvement in validation accuracy (1/5)\n17\nEpoch 18/50 | Loss: 0.6641 | Val Accuracy: 62.77%\n New best model saved with validation accuracy: 62.77%\n18\nEpoch 19/50 | Loss: 0.5967 | Val Accuracy: 64.17%\n New best model saved with validation accuracy: 64.17%\n19\nEpoch 20/50 | Loss: 0.5334 | Val Accuracy: 62.72%\n No improvement in validation accuracy (1/5)\n20\nEpoch 21/50 | Loss: 0.4769 | Val Accuracy: 63.16%\n No improvement in validation accuracy (2/5)\n21\nEpoch 22/50 | Loss: 0.4038 | Val Accuracy: 62.06%\n No improvement in validation accuracy (3/5)\n22\nEpoch 23/50 | Loss: 0.3479 | Val Accuracy: 63.22%\n No improvement in validation accuracy (4/5)\n23\nEpoch 24/50 | Loss: 0.3008 | Val Accuracy: 64.58%\n New best model saved with validation accuracy: 64.58%\n24\nEpoch 25/50 | Loss: 0.2438 | Val Accuracy: 64.97%\n New best model saved with validation accuracy: 64.97%\n25\nEpoch 26/50 | Loss: 0.2058 | Val Accuracy: 63.45%\n No improvement in validation accuracy (1/5)\n26\nEpoch 27/50 | Loss: 0.1831 | Val Accuracy: 64.84%\n No improvement in validation accuracy (2/5)\n27\nEpoch 28/50 | Loss: 0.1564 | Val Accuracy: 63.40%\n No improvement in validation accuracy (3/5)\n28\nEpoch 29/50 | Loss: 0.1339 | Val Accuracy: 65.53%\n New best model saved with validation accuracy: 65.53%\n29\nEpoch 30/50 | Loss: 0.1095 | Val Accuracy: 64.64%\n No improvement in validation accuracy (1/5)\n30\nEpoch 31/50 | Loss: 0.0835 | Val Accuracy: 64.69%\n No improvement in validation accuracy (2/5)\n31\nEpoch 32/50 | Loss: 0.0665 | Val Accuracy: 66.46%\n New best model saved with validation accuracy: 66.46%\n32\nEpoch 33/50 | Loss: 0.0592 | Val Accuracy: 66.50%\n New best model saved with validation accuracy: 66.50%\n33\nEpoch 34/50 | Loss: 0.0592 | Val Accuracy: 66.17%\n No improvement in validation accuracy (1/5)\n34\nEpoch 35/50 | Loss: 0.0616 | Val Accuracy: 62.74%\n No improvement in validation accuracy (2/5)\n35\nEpoch 36/50 | Loss: 0.0526 | Val Accuracy: 66.83%\n New best model saved with validation accuracy: 66.83%\n36\nEpoch 37/50 | Loss: 0.0465 | Val Accuracy: 65.60%\n No improvement in validation accuracy (1/5)\n37\nEpoch 38/50 | Loss: 0.0411 | Val Accuracy: 66.93%\n New best model saved with validation accuracy: 66.93%\n38\nEpoch 39/50 | Loss: 0.0339 | Val Accuracy: 65.15%\n No improvement in validation accuracy (1/5)\n39\nEpoch 40/50 | Loss: 0.0329 | Val Accuracy: 65.96%\n No improvement in validation accuracy (2/5)\n40\nEpoch 41/50 | Loss: 0.0357 | Val Accuracy: 66.48%\n No improvement in validation accuracy (3/5)\n41\nEpoch 42/50 | Loss: 0.0315 | Val Accuracy: 67.17%\n New best model saved with validation accuracy: 67.17%\n42\nEpoch 43/50 | Loss: 0.0266 | Val Accuracy: 67.37%\n New best model saved with validation accuracy: 67.37%\n43\nEpoch 44/50 | Loss: 0.0237 | Val Accuracy: 67.00%\n No improvement in validation accuracy (1/5)\n44\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef _get_gt_mask(logits, target):\n    target = target.reshape(-1)\n    mask = torch.zeros_like(logits).scatter_(1, target.unsqueeze(1), 1).bool()\n    return mask\n\ndef _get_other_mask(logits, target):\n    target = target.reshape(-1)\n    mask = torch.ones_like(logits).scatter_(1, target.unsqueeze(1), 0).bool()\n    return mask\n\ndef cat_mask(tensor, mask1, mask2):\n    t1 = (tensor * mask1).sum(dim=1, keepdim=True)\n    t2 = (tensor * mask2).sum(dim=1, keepdim=True)\n    return torch.cat([t1, t2], dim=1)\n\nclass DKDloss(nn.Module):\n    def __init__(self):\n        super(DKDloss, self).__init__()\n\n    def forward(self, logits_student, logits_teacher, target, alpha, beta, temperature):\n        # Get masks for ground-truth and other classes\n        gt_mask = _get_gt_mask(logits_student, target)\n        other_mask = _get_other_mask(logits_student, target)\n        \n        # Compute softened probabilities\n        pred_student = F.softmax(logits_student / temperature, dim=1)\n        pred_teacher = F.softmax(logits_teacher / temperature, dim=1)\n\n        \n\n        # Two-class transformation using GT and OTHER\n        pred_student = cat_mask(pred_student, gt_mask, other_mask)\n        pred_teacher = cat_mask(pred_teacher, gt_mask, other_mask)\n\n        # True class KD loss\n        log_pred_student = torch.log(pred_student)\n        tckd_loss = F.kl_div(\n            log_pred_student, pred_teacher, reduction='sum'\n        ) * (temperature ** 2) / target.shape[0]\n\n        # Non-ground-truth KD loss (mask GT with large value)\n        pred_teacher_part2 = F.softmax(\n            logits_teacher / temperature - 1000.0 * gt_mask, dim=1\n        )\n        log_pred_student_part2 = F.log_softmax(\n            logits_student / temperature - 1000.0 * gt_mask, dim=1\n        )\n        nckd_loss = F.kl_div(\n            log_pred_student_part2, pred_teacher_part2, reduction='sum'\n        ) * (temperature ** 2) / target.shape[0]\n\n        # Weighted sum\n        loss = alpha * tckd_loss + beta * nckd_loss\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:33.345817Z","iopub.execute_input":"2025-05-08T07:28:33.346416Z","iopub.status.idle":"2025-05-08T07:28:33.354499Z","shell.execute_reply.started":"2025-05-08T07:28:33.346385Z","shell.execute_reply":"2025-05-08T07:28:33.353832Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef compute_gradient_importance(\n    teacher, student, data_loader, device, temperature=4.0, alpha=0.5, beta_prob=0.5, accumulation_epochs=3\n):\n\n    # Initialize DKD loss\n    dkd_loss_fn = DKDloss()\n\n    importance_scores = {}\n    for name, param in student.named_parameters():\n        if 'weight' in name and len(param.shape) == 4:  # Conv weights only\n            importance_scores[name] = torch.zeros_like(param.data, device=device)\n\n    teacher.to(device).eval()\n    student.to(device).train()\n\n    momentum = 0.9\n    accumulated_batches = 0\n\n    for epoch in range(accumulation_epochs):\n        print(f\"Accumulation Epoch {epoch+1}/{accumulation_epochs}\")\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            student.zero_grad()\n\n            with torch.no_grad():\n                teacher_logits = teacher(inputs)\n\n            student_logits = student(inputs)\n\n            # Compute DKD loss + optional CE\n            distillation_loss = dkd_loss_fn(student_logits, teacher_logits, labels, alpha, beta_prob, temperature)\n            ce_loss = F.cross_entropy(student_logits, labels)\n            loss = alpha * distillation_loss + (1 - alpha) * ce_loss\n\n            loss.backward()\n\n            accumulated_batches += 1\n            for name, param in student.named_parameters():\n                if name in importance_scores and param.grad is not None:\n                    grad_product = (param.data * param.grad).abs_()\n                    if accumulated_batches == 1:\n                        importance_scores[name] = grad_product\n                    else:\n                        importance_scores[name] = momentum * importance_scores[name] + (1 - momentum) * grad_product\n\n    for name in importance_scores:\n        importance_scores[name] /= (1 - momentum ** accumulated_batches)\n\n    return importance_scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:34.000982Z","iopub.execute_input":"2025-05-08T07:28:34.001249Z","iopub.status.idle":"2025-05-08T07:28:34.008917Z","shell.execute_reply.started":"2025-05-08T07:28:34.001228Z","shell.execute_reply":"2025-05-08T07:28:34.008120Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def gradient_based_global_prune(model, importance_scores, prune_ratio=0.95):\n    all_scores = torch.cat([score.flatten() for score in importance_scores.values()])\n    threshold = torch.topk(all_scores, k=int(prune_ratio * all_scores.numel()), largest=False)[0][-1]\n\n    for name, param in model.named_parameters():\n        if name in importance_scores:\n            mask = (importance_scores[name] > threshold).float()\n            param.data.mul_(mask)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:36.902059Z","iopub.execute_input":"2025-05-08T07:28:36.902536Z","iopub.status.idle":"2025-05-08T07:28:36.907329Z","shell.execute_reply.started":"2025-05-08T07:28:36.902512Z","shell.execute_reply":"2025-05-08T07:28:36.906524Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ndef retrain_with_sparsity(student, train_loader, val_loader, epochs=5, save_path=\"retrained_student_model.pt\", patience=3):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n\n    # 1. Store masks AND zero momentum buffers for pruned weights\n    masks = {}\n    for name, param in student.named_parameters():\n        if 'weight' in name and param.dim() == 4:  # Consider only conv layers\n            mask = (param != 0).float().to(device)\n            masks[name] = mask\n            # Zero momentum buffers for pruned weights\n            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n                optimizer.state[param]['momentum_buffer'] *= mask\n\n    student = student.to(device)\n    best_val_acc = 0.0\n    best_model = None\n    patience_counter = 0  # Counter for early stopping\n\n    # 2. Add gradient clipping to prevent NaN\n    max_grad_norm = 1.0\n\n    for epoch in range(epochs):\n        student.train()\n        total_loss = 0.0\n        correct, total = 0, 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = student(inputs)\n            loss = F.cross_entropy(outputs, labels)\n            loss.backward()\n\n            # Apply masks to gradients\n            for name, param in student.named_parameters():\n                if name in masks:\n                    param.grad.data *= masks[name]\n\n            # Gradient clipping before optimizer step\n            torch.nn.utils.clip_grad_norm_(student.parameters(), max_grad_norm)\n\n            optimizer.step()\n\n            # Reapply masks and update momentum buffers\n            for name, param in student.named_parameters():\n                if name in masks:\n                    param.data *= masks[name]\n                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n\n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n        train_loss = total_loss / len(train_loader)\n        train_acc = 100.0 * correct / total\n\n        # Validation phase\n        student.eval()\n        val_loss, val_correct, val_total = 0.0, 0, 0\n\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = student(inputs)\n                loss = F.cross_entropy(outputs, labels)\n\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_correct += predicted.eq(labels).sum().item()\n                val_total += labels.size(0)\n\n        val_loss /= len(val_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Track best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model = student.state_dict()\n            torch.save(best_model, save_path)\n            patience_counter = 0  # Reset patience counter\n            print(f\"New best model saved with Val Accuracy: {best_val_acc:.2f}%\")\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n                break  # Stop training\n\n        # Print results\n        sparsity = calculate_sparsity(student)\n        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n        print(f\"Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.2f}% | Sparsity: {sparsity*100:.2f}%\\n\")\n\n    print(f\"Best Validation Accuracy: {best_val_acc:.2f}% | Best Model Saved at: {save_path}\")\n    return student","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:37.151429Z","iopub.execute_input":"2025-05-08T07:28:37.151728Z","iopub.status.idle":"2025-05-08T07:28:37.163706Z","shell.execute_reply.started":"2025-05-08T07:28:37.151705Z","shell.execute_reply":"2025-05-08T07:28:37.162943Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport time\n\n# KD training with DKD loss and mask-based momentum handling\ndef retrain_with_KD(teacher, student, train_loader, val_loader, epochs=50,\n                    temperature=5.0, alpha=0.5, beta_prob=0.5, patience=5,\n                    save_path=\"student_before_pruning.pth\"):\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n\n    # Initialize DKD loss function\n    dkd_loss_fn = DKDloss()\n\n    # Store masks and zero momentum buffers\n    masks = {}\n    for name, param in student.named_parameters():\n        if 'weight' in name and param.dim() == 4:\n            mask = (param != 0).float().to(device)\n            masks[name] = mask\n            if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n                optimizer.state[param]['momentum_buffer'] *= mask\n\n    teacher = teacher.to(device).eval()\n    student = student.to(device)\n\n    best_val_acc = 0.0\n    best_model_state = None\n    patience_counter = 0\n    start_time = time.time()\n\n    for epoch in range(epochs):\n        student.train()\n        total_loss, correct, total = 0.0, 0, 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            with torch.no_grad():\n                teacher_logits = teacher(inputs)\n\n            student_logits = student(inputs)\n\n            # DKD loss\n            kd_loss = dkd_loss_fn(student_logits, teacher_logits, labels, alpha, beta_prob, temperature)\n            ce_loss = F.cross_entropy(student_logits, labels)\n\n            # Total loss (optional to keep CE blended with KD)\n            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n\n            loss.backward()\n            optimizer.step()\n\n            # Reapply masks and update momentum\n            for name, param in student.named_parameters():\n                if name in masks:\n                    param.data *= masks[name]\n                    if optimizer.state.get(param, None) and 'momentum_buffer' in optimizer.state[param]:\n                        optimizer.state[param]['momentum_buffer'] *= masks[name]\n\n            total_loss += loss.item()\n            _, predicted = student_logits.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n        train_loss = total_loss / len(train_loader)\n        train_acc = 100.0 * correct / total\n\n        # Validation\n        student.eval()\n        val_loss, val_correct, val_total = 0.0, 0, 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = student(inputs)\n                loss = F.cross_entropy(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_correct += predicted.eq(labels).sum().item()\n                val_total += labels.size(0)\n\n        val_loss /= len(val_loader)\n        val_acc = 100.0 * val_correct / val_total\n        sparsity = calculate_sparsity(student) * 100.0  # Assuming this function is defined\n\n        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Sparsity: {sparsity:.2f}%\")\n\n        # Early stopping\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = student.state_dict()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n                break\n\n    # Save best model\n    student.load_state_dict(best_model_state)\n    torch.save(student.state_dict(), save_path)\n    print(f\"Student model saved before pruning at: {save_path}\")\n    total_time = time.time() - start_time\n    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\n    return student\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:43.542235Z","iopub.execute_input":"2025-05-08T07:28:43.542831Z","iopub.status.idle":"2025-05-08T07:28:43.554914Z","shell.execute_reply.started":"2025-05-08T07:28:43.542807Z","shell.execute_reply":"2025-05-08T07:28:43.554007Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\n# Training function with KD + CA-KLD and logits normalization\ndef train_kd_pruning(teacher, student, train_loader, val_loader, epochs=50, temperature=5.0, alpha=0.5,\n                     beta_prob=0.5, patience=5, save_path=\"student_before_pruning.pth\"):\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n\n    teacher = teacher.to(device)\n    student = student.to(device)\n    teacher.eval()  # Freeze teacher\n\n    best_val_acc = 0.0\n    best_model_state = None\n    patience_counter = 0\n    start_time = time.time()\n\n    for epoch in range(epochs):\n        student.train()\n        total_loss = 0.0\n        correct, total = 0, 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            with torch.no_grad():\n                teacher_logits = teacher(inputs)\n\n            student_logits = student(inputs)\n\n            # Temperature scaling\n            teacher_logits_temp = teacher_logits / temperature\n            student_logits_temp = student_logits / temperature\n\n            # Logits normalization\n            teacher_logits_temp = normalize(teacher_logits_temp)\n            student_logits_temp = normalize(student_logits_temp)\n\n            # CA-KLD loss (normalized logits)\n            distillation_loss = cakld_loss(student_logits_temp, teacher_logits_temp, beta_prob) * (temperature ** 2)\n\n            # Cross-entropy loss\n            ground_truth_loss = F.cross_entropy(student_logits, labels)\n\n            # Combined loss\n            loss = alpha * distillation_loss + (1 - alpha) * ground_truth_loss\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = student_logits.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n        train_loss = total_loss / len(train_loader)\n        train_acc = 100.0 * correct / total\n\n        # Validation accuracy\n        val_acc = evaluate(student, val_loader, device)\n\n        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | \"\n              f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n\n        # Early stopping\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = student.state_dict()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping triggered at epoch {epoch+1}. No improvement for {patience} epochs.\")\n                break\n\n    # Load best model state and save\n    student.load_state_dict(best_model_state)\n    torch.save(student.state_dict(), save_path)\n    print(f\"Student model saved before pruning at: {save_path}\")\n\n    total_time = time.time() - start_time\n    print(f\"Total Training Time: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\n    return student","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:45.815111Z","iopub.execute_input":"2025-05-08T07:28:45.815375Z","iopub.status.idle":"2025-05-08T07:28:45.825294Z","shell.execute_reply.started":"2025-05-08T07:28:45.815355Z","shell.execute_reply":"2025-05-08T07:28:45.824620Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\nstudent = train_kd_pruning(\n    teacher, student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.5,beta_prob=0.5, patience=5,save_path=\"student_before_pruning.pth\"\n)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50 | Train Loss: 2.6007 | Train Acc: 83.86% | Val Acc: 88.68%\n","Epoch 2/50 | Train Loss: 0.8082 | Train Acc: 94.44% | Val Acc: 92.16%\n","Epoch 3/50 | Train Loss: 0.4497 | Train Acc: 97.41% | Val Acc: 94.04%\n","Epoch 4/50 | Train Loss: 0.2881 | Train Acc: 98.71% | Val Acc: 94.84%\n","Epoch 5/50 | Train Loss: 0.2302 | Train Acc: 99.09% | Val Acc: 95.51%\n","Epoch 6/50 | Train Loss: 0.1968 | Train Acc: 99.22% | Val Acc: 95.55%\n","Epoch 7/50 | Train Loss: 0.1769 | Train Acc: 99.28% | Val Acc: 95.57%\n","Epoch 8/50 | Train Loss: 0.1595 | Train Acc: 99.32% | Val Acc: 95.84%\n","Epoch 9/50 | Train Loss: 0.1477 | Train Acc: 99.35% | Val Acc: 96.00%\n","Epoch 10/50 | Train Loss: 0.1395 | Train Acc: 99.33% | Val Acc: 95.79%\n","Epoch 11/50 | Train Loss: 0.1308 | Train Acc: 99.36% | Val Acc: 96.12%\n","Epoch 12/50 | Train Loss: 0.1276 | Train Acc: 99.30% | Val Acc: 95.96%\n","Epoch 13/50 | Train Loss: 0.1185 | Train Acc: 99.39% | Val Acc: 96.05%\n","Epoch 14/50 | Train Loss: 0.1156 | Train Acc: 99.32% | Val Acc: 96.18%\n","Epoch 15/50 | Train Loss: 0.1116 | Train Acc: 99.36% | Val Acc: 96.21%\n","Epoch 16/50 | Train Loss: 0.1061 | Train Acc: 99.36% | Val Acc: 96.16%\n","Epoch 17/50 | Train Loss: 0.1014 | Train Acc: 99.38% | Val Acc: 96.10%\n","Epoch 18/50 | Train Loss: 0.0980 | Train Acc: 99.33% | Val Acc: 96.03%\n","Epoch 19/50 | Train Loss: 0.0943 | Train Acc: 99.36% | Val Acc: 96.15%\n","Epoch 20/50 | Train Loss: 0.0923 | Train Acc: 99.36% | Val Acc: 96.10%\n","Early stopping triggered at epoch 20. No improvement for 5 epochs.\n","Student model saved before pruning at: student_before_pruning.pth\n","Total Training Time: 20m 31s\n"]}],"execution_count":21},{"cell_type":"code","source":"# Calculate sparsity\nsparsity = calculate_sparsity(student)\nprint(f\"Sparsity Before Pruning: {sparsity * 100:.2f}%\")\n\nteacher_accuracy = evaluate(teacher, test_loader, device)\nstudent_accuracy = evaluate(student, test_loader, device)\nprint(f\"Teacher Model Test Accuracy: {teacher_accuracy:.2f}%\")\nprint(f\"Student Model Test Accuracy Before Pruning: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:28:52.277881Z","iopub.execute_input":"2025-05-08T07:28:52.278153Z","iopub.status.idle":"2025-05-08T07:29:20.993878Z","shell.execute_reply.started":"2025-05-08T07:28:52.278133Z","shell.execute_reply":"2025-05-08T07:29:20.992884Z"}},"outputs":[{"name":"stdout","text":"Sparsity Before Pruning: 0.00%\nTeacher Model Test Accuracy: 95.41%\nStudent Model Test Accuracy Before Pruning: 95.92%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## 36% Sparsity","metadata":{}},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:29:20.995437Z","iopub.execute_input":"2025-05-08T07:29:20.995699Z","iopub.status.idle":"2025-05-08T07:29:21.062187Z","shell.execute_reply.started":"2025-05-08T07:29:20.995676Z","shell.execute_reply":"2025-05-08T07:29:21.061483Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=3.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.3608)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:29:42.956849Z","iopub.execute_input":"2025-05-08T07:29:42.957370Z","iopub.status.idle":"2025-05-08T07:35:55.533070Z","shell.execute_reply.started":"2025-05-08T07:29:42.957351Z","shell.execute_reply":"2025-05-08T07:35:55.532182Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 12s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:35:55.534800Z","iopub.execute_input":"2025-05-08T07:35:55.535084Z","iopub.status.idle":"2025-05-08T07:58:32.950630Z","shell.execute_reply.started":"2025-05-08T07:35:55.535058Z","shell.execute_reply":"2025-05-08T07:58:32.949755Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.3257 | Train Acc: 98.62% | Val Loss: 0.0408 | Val Acc: 98.66% | Sparsity: 36.05%\nEpoch 2/50 | Train Loss: 0.2050 | Train Acc: 99.22% | Val Loss: 0.0391 | Val Acc: 98.75% | Sparsity: 36.05%\nEpoch 3/50 | Train Loss: 0.1685 | Train Acc: 99.36% | Val Loss: 0.0393 | Val Acc: 98.70% | Sparsity: 36.05%\nEpoch 4/50 | Train Loss: 0.1478 | Train Acc: 99.38% | Val Loss: 0.0410 | Val Acc: 98.64% | Sparsity: 36.05%\nEpoch 5/50 | Train Loss: 0.1356 | Train Acc: 99.42% | Val Loss: 0.0378 | Val Acc: 98.78% | Sparsity: 36.05%\nEpoch 6/50 | Train Loss: 0.1186 | Train Acc: 99.47% | Val Loss: 0.0377 | Val Acc: 98.73% | Sparsity: 36.05%\nEpoch 7/50 | Train Loss: 0.1135 | Train Acc: 99.49% | Val Loss: 0.0408 | Val Acc: 98.62% | Sparsity: 36.05%\nEpoch 8/50 | Train Loss: 0.1037 | Train Acc: 99.49% | Val Loss: 0.0390 | Val Acc: 98.75% | Sparsity: 36.05%\nEpoch 9/50 | Train Loss: 0.0996 | Train Acc: 99.49% | Val Loss: 0.0388 | Val Acc: 98.71% | Sparsity: 36.05%\nEpoch 10/50 | Train Loss: 0.0931 | Train Acc: 99.50% | Val Loss: 0.0388 | Val Acc: 98.70% | Sparsity: 36.05%\nEarly stopping triggered at epoch 10. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 22m 37s\nRetraining completed in 22.62 minutes (1357.41 seconds)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T07:58:32.952333Z","iopub.execute_input":"2025-05-08T07:58:32.952565Z","iopub.status.idle":"2025-05-08T07:58:43.096800Z","shell.execute_reply.started":"2025-05-08T07:58:32.952544Z","shell.execute_reply":"2025-05-08T07:58:43.095910Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(After Retrain): 95.92%\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:01:17.520101Z","iopub.execute_input":"2025-04-27T14:01:17.520417Z","iopub.status.idle":"2025-04-27T14:01:27.270412Z","shell.execute_reply.started":"2025-04-27T14:01:17.520392Z","shell.execute_reply":"2025-04-27T14:01:27.269154Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(After Retrain): 95.88%\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:01:27.272671Z","iopub.execute_input":"2025-04-27T14:01:27.272960Z","iopub.status.idle":"2025-04-27T14:01:27.346891Z","shell.execute_reply.started":"2025-04-27T14:01:27.272939Z","shell.execute_reply":"2025-04-27T14:01:27.346258Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=5.0, alpha=0.7,beta_prob=0.5, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.3608)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:01:27.347662Z","iopub.execute_input":"2025-04-27T14:01:27.347930Z","iopub.status.idle":"2025-04-27T14:07:40.117044Z","shell.execute_reply.started":"2025-04-27T14:01:27.347909Z","shell.execute_reply":"2025-04-27T14:07:40.116276Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:07:40.118091Z","iopub.execute_input":"2025-04-27T14:07:40.118346Z","iopub.status.idle":"2025-04-27T14:32:31.831364Z","shell.execute_reply.started":"2025-04-27T14:07:40.118325Z","shell.execute_reply":"2025-04-27T14:32:31.830495Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.3343 | Train Acc: 98.32% | Val Loss: 0.0463 | Val Acc: 98.57% | Sparsity: 36.05%\nEpoch 2/50 | Train Loss: 0.2191 | Train Acc: 99.07% | Val Loss: 0.0410 | Val Acc: 98.69% | Sparsity: 36.05%\nEpoch 3/50 | Train Loss: 0.1704 | Train Acc: 99.10% | Val Loss: 0.0371 | Val Acc: 98.85% | Sparsity: 36.05%\nEpoch 4/50 | Train Loss: 0.1479 | Train Acc: 99.17% | Val Loss: 0.0353 | Val Acc: 98.91% | Sparsity: 36.05%\nEpoch 5/50 | Train Loss: 0.1356 | Train Acc: 99.12% | Val Loss: 0.0339 | Val Acc: 98.91% | Sparsity: 36.05%\nEpoch 6/50 | Train Loss: 0.1266 | Train Acc: 99.21% | Val Loss: 0.0336 | Val Acc: 98.92% | Sparsity: 36.05%\nEpoch 7/50 | Train Loss: 0.1181 | Train Acc: 99.21% | Val Loss: 0.0334 | Val Acc: 98.88% | Sparsity: 36.05%\nEpoch 8/50 | Train Loss: 0.1157 | Train Acc: 99.12% | Val Loss: 0.0346 | Val Acc: 98.88% | Sparsity: 36.05%\nEpoch 9/50 | Train Loss: 0.1079 | Train Acc: 99.19% | Val Loss: 0.0339 | Val Acc: 98.92% | Sparsity: 36.05%\nEpoch 10/50 | Train Loss: 0.1034 | Train Acc: 99.17% | Val Loss: 0.0356 | Val Acc: 98.84% | Sparsity: 36.05%\nEpoch 11/50 | Train Loss: 0.1011 | Train Acc: 99.18% | Val Loss: 0.0352 | Val Acc: 98.89% | Sparsity: 36.05%\nEarly stopping triggered at epoch 11. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 24m 52s\nRetraining completed in 24.86 minutes (1491.71 seconds)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(After Retrain): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:32:31.832457Z","iopub.execute_input":"2025-04-27T14:32:31.832726Z","iopub.status.idle":"2025-04-27T14:32:41.497268Z","shell.execute_reply.started":"2025-04-27T14:32:31.832702Z","shell.execute_reply":"2025-04-27T14:32:41.496381Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(After Retrain): 95.99%\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# 59% of Sparsity","metadata":{}},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:45:02.782520Z","iopub.execute_input":"2025-04-27T14:45:02.782802Z","iopub.status.idle":"2025-04-27T14:45:02.857789Z","shell.execute_reply.started":"2025-04-27T14:45:02.782780Z","shell.execute_reply":"2025-04-27T14:45:02.857156Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"student_accuracy = evaluate(student, test_loader, device)\nprint(f\"Student Model Test Accuracy: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:45:04.897342Z","iopub.execute_input":"2025-04-27T14:45:04.897580Z","iopub.status.idle":"2025-04-27T14:45:14.592549Z","shell.execute_reply.started":"2025-04-27T14:45:04.897563Z","shell.execute_reply":"2025-04-27T14:45:14.591767Z"}},"outputs":[{"name":"stdout","text":"Student Model Test Accuracy: 95.92%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.5909)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:45:36.348344Z","iopub.execute_input":"2025-04-27T14:45:36.348609Z","iopub.status.idle":"2025-04-27T14:51:49.118974Z","shell.execute_reply.started":"2025-04-27T14:45:36.348590Z","shell.execute_reply":"2025-04-27T14:51:49.118175Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=7,save_path=\"pruned_student_retrain_KD_59%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T14:51:49.120560Z","iopub.execute_input":"2025-04-27T14:51:49.120793Z","iopub.status.idle":"2025-04-27T15:39:15.870548Z","shell.execute_reply.started":"2025-04-27T14:51:49.120772Z","shell.execute_reply":"2025-04-27T15:39:15.869750Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.3888 | Train Acc: 98.21% | Val Loss: 0.0616 | Val Acc: 98.08% | Sparsity: 59.04%\nEpoch 2/50 | Train Loss: 0.2468 | Train Acc: 98.93% | Val Loss: 0.0458 | Val Acc: 98.59% | Sparsity: 59.04%\nEpoch 3/50 | Train Loss: 0.1878 | Train Acc: 99.10% | Val Loss: 0.0359 | Val Acc: 98.88% | Sparsity: 59.04%\nEpoch 4/50 | Train Loss: 0.1631 | Train Acc: 99.11% | Val Loss: 0.0359 | Val Acc: 98.84% | Sparsity: 59.04%\nEpoch 5/50 | Train Loss: 0.1499 | Train Acc: 99.16% | Val Loss: 0.0380 | Val Acc: 98.79% | Sparsity: 59.04%\nEpoch 6/50 | Train Loss: 0.1387 | Train Acc: 99.15% | Val Loss: 0.0358 | Val Acc: 98.86% | Sparsity: 59.04%\nEpoch 7/50 | Train Loss: 0.1306 | Train Acc: 99.19% | Val Loss: 0.0385 | Val Acc: 98.83% | Sparsity: 59.04%\nEpoch 8/50 | Train Loss: 0.1266 | Train Acc: 99.15% | Val Loss: 0.0346 | Val Acc: 98.92% | Sparsity: 59.04%\nEpoch 9/50 | Train Loss: 0.1209 | Train Acc: 99.12% | Val Loss: 0.0363 | Val Acc: 98.77% | Sparsity: 59.04%\nEpoch 10/50 | Train Loss: 0.1135 | Train Acc: 99.21% | Val Loss: 0.0368 | Val Acc: 98.89% | Sparsity: 59.04%\nEpoch 11/50 | Train Loss: 0.1097 | Train Acc: 99.12% | Val Loss: 0.0343 | Val Acc: 98.87% | Sparsity: 59.04%\nEpoch 12/50 | Train Loss: 0.1078 | Train Acc: 99.22% | Val Loss: 0.0367 | Val Acc: 98.86% | Sparsity: 59.04%\nEpoch 13/50 | Train Loss: 0.1046 | Train Acc: 99.21% | Val Loss: 0.0379 | Val Acc: 98.76% | Sparsity: 59.04%\nEpoch 14/50 | Train Loss: 0.1023 | Train Acc: 99.21% | Val Loss: 0.0357 | Val Acc: 98.95% | Sparsity: 59.04%\nEpoch 15/50 | Train Loss: 0.0989 | Train Acc: 99.15% | Val Loss: 0.0364 | Val Acc: 98.87% | Sparsity: 59.04%\nEpoch 16/50 | Train Loss: 0.0952 | Train Acc: 99.27% | Val Loss: 0.0342 | Val Acc: 98.89% | Sparsity: 59.04%\nEpoch 17/50 | Train Loss: 0.0909 | Train Acc: 99.17% | Val Loss: 0.0381 | Val Acc: 98.80% | Sparsity: 59.04%\nEpoch 18/50 | Train Loss: 0.0900 | Train Acc: 99.22% | Val Loss: 0.0364 | Val Acc: 98.83% | Sparsity: 59.04%\nEpoch 19/50 | Train Loss: 0.0875 | Train Acc: 99.20% | Val Loss: 0.0373 | Val Acc: 98.85% | Sparsity: 59.04%\nEpoch 20/50 | Train Loss: 0.0865 | Train Acc: 99.20% | Val Loss: 0.0359 | Val Acc: 98.87% | Sparsity: 59.04%\nEpoch 21/50 | Train Loss: 0.0838 | Train Acc: 99.20% | Val Loss: 0.0364 | Val Acc: 98.89% | Sparsity: 59.04%\nEarly stopping triggered at epoch 21. No improvement for 7 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_59%.pth\nTotal Training Time: 47m 27s\nRetraining completed in 47.45 minutes (2846.74 seconds)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:39:15.871629Z","iopub.execute_input":"2025-04-27T15:39:15.871852Z","iopub.status.idle":"2025-04-27T15:39:25.579960Z","shell.execute_reply.started":"2025-04-27T15:39:15.871831Z","shell.execute_reply":"2025-04-27T15:39:25.579009Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(Retrain with KD): 95.74%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:55:16.253893Z","iopub.execute_input":"2025-04-27T15:55:16.254238Z","iopub.status.idle":"2025-04-27T15:55:16.327013Z","shell.execute_reply.started":"2025-04-27T15:55:16.254201Z","shell.execute_reply":"2025-04-27T15:55:16.326399Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.5909)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:55:17.254034Z","iopub.execute_input":"2025-04-27T15:55:17.254319Z","iopub.status.idle":"2025-04-27T16:01:30.158516Z","shell.execute_reply.started":"2025-04-27T15:55:17.254296Z","shell.execute_reply":"2025-04-27T16:01:30.157617Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_59%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:01:30.160258Z","iopub.execute_input":"2025-04-27T16:01:30.160495Z","iopub.status.idle":"2025-04-27T16:19:36.535371Z","shell.execute_reply.started":"2025-04-27T16:01:30.160476Z","shell.execute_reply":"2025-04-27T16:19:36.534526Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.1116 | Train Acc: 98.67% | Val Loss: 0.0344 | Val Acc: 98.82% | Sparsity: 59.04%\nEpoch 2/50 | Train Loss: 0.0722 | Train Acc: 99.25% | Val Loss: 0.0335 | Val Acc: 98.86% | Sparsity: 59.04%\nEpoch 3/50 | Train Loss: 0.0621 | Train Acc: 99.37% | Val Loss: 0.0328 | Val Acc: 98.91% | Sparsity: 59.04%\nEpoch 4/50 | Train Loss: 0.0568 | Train Acc: 99.38% | Val Loss: 0.0329 | Val Acc: 98.84% | Sparsity: 59.04%\nEpoch 5/50 | Train Loss: 0.0531 | Train Acc: 99.42% | Val Loss: 0.0315 | Val Acc: 98.86% | Sparsity: 59.04%\nEpoch 6/50 | Train Loss: 0.0512 | Train Acc: 99.44% | Val Loss: 0.0332 | Val Acc: 98.86% | Sparsity: 59.04%\nEpoch 7/50 | Train Loss: 0.0493 | Train Acc: 99.40% | Val Loss: 0.0319 | Val Acc: 98.87% | Sparsity: 59.04%\nEpoch 8/50 | Train Loss: 0.0472 | Train Acc: 99.41% | Val Loss: 0.0328 | Val Acc: 98.84% | Sparsity: 59.04%\nEarly stopping triggered at epoch 8. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_59%.pth\nTotal Training Time: 18m 6s\nRetraining completed in 18.11 minutes (1086.37 seconds)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:19:36.536511Z","iopub.execute_input":"2025-04-27T16:19:36.536730Z","iopub.status.idle":"2025-04-27T16:19:46.448297Z","shell.execute_reply.started":"2025-04-27T16:19:36.536709Z","shell.execute_reply":"2025-04-27T16:19:46.447293Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(Retrain with KD): 95.86%\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# 79% Sparsity","metadata":{}},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:05:56.397204Z","iopub.execute_input":"2025-04-27T17:05:56.397505Z","iopub.status.idle":"2025-04-27T17:05:56.450252Z","shell.execute_reply.started":"2025-04-27T17:05:56.397483Z","shell.execute_reply":"2025-04-27T17:05:56.449630Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.7907)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:06:52.039631Z","iopub.execute_input":"2025-04-27T17:06:52.040372Z","iopub.status.idle":"2025-04-27T17:13:05.243472Z","shell.execute_reply.started":"2025-04-27T17:06:52.040346Z","shell.execute_reply":"2025-04-27T17:13:05.242539Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:13:05.244893Z","iopub.execute_input":"2025-04-27T17:13:05.245093Z","iopub.status.idle":"2025-04-27T17:40:18.534109Z","shell.execute_reply.started":"2025-04-27T17:13:05.245075Z","shell.execute_reply":"2025-04-27T17:40:18.533137Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.6026 | Train Acc: 97.14% | Val Loss: 0.1608 | Val Acc: 95.19% | Sparsity: 79.00%\nEpoch 2/50 | Train Loss: 0.4047 | Train Acc: 98.20% | Val Loss: 0.0835 | Val Acc: 97.56% | Sparsity: 79.00%\nEpoch 3/50 | Train Loss: 0.2879 | Train Acc: 98.81% | Val Loss: 0.0574 | Val Acc: 98.22% | Sparsity: 79.00%\nEpoch 4/50 | Train Loss: 0.2247 | Train Acc: 99.06% | Val Loss: 0.0547 | Val Acc: 98.17% | Sparsity: 79.00%\nEpoch 5/50 | Train Loss: 0.2027 | Train Acc: 99.11% | Val Loss: 0.0532 | Val Acc: 98.29% | Sparsity: 79.00%\nEpoch 6/50 | Train Loss: 0.1794 | Train Acc: 99.12% | Val Loss: 0.0483 | Val Acc: 98.47% | Sparsity: 79.00%\nEpoch 7/50 | Train Loss: 0.1676 | Train Acc: 99.16% | Val Loss: 0.0471 | Val Acc: 98.57% | Sparsity: 79.00%\nEpoch 8/50 | Train Loss: 0.1598 | Train Acc: 99.14% | Val Loss: 0.0526 | Val Acc: 98.41% | Sparsity: 79.00%\nEpoch 9/50 | Train Loss: 0.1503 | Train Acc: 99.13% | Val Loss: 0.0490 | Val Acc: 98.39% | Sparsity: 79.00%\nEpoch 10/50 | Train Loss: 0.1480 | Train Acc: 99.13% | Val Loss: 0.0525 | Val Acc: 98.26% | Sparsity: 79.00%\nEpoch 11/50 | Train Loss: 0.1419 | Train Acc: 99.16% | Val Loss: 0.0443 | Val Acc: 98.57% | Sparsity: 79.00%\nEpoch 12/50 | Train Loss: 0.1324 | Train Acc: 99.18% | Val Loss: 0.0464 | Val Acc: 98.55% | Sparsity: 79.00%\nEarly stopping triggered at epoch 12. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 27m 13s\nRetraining completed in 27.22 minutes (1633.28 seconds)\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:40:18.535453Z","iopub.execute_input":"2025-04-27T17:40:18.535779Z","iopub.status.idle":"2025-04-27T17:40:29.600385Z","shell.execute_reply.started":"2025-04-27T17:40:18.535747Z","shell.execute_reply":"2025-04-27T17:40:29.599276Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(Retrain with KD): 95.43%\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:40:29.602477Z","iopub.execute_input":"2025-04-27T17:40:29.602741Z","iopub.status.idle":"2025-04-27T17:40:29.688606Z","shell.execute_reply.started":"2025-04-27T17:40:29.602719Z","shell.execute_reply":"2025-04-27T17:40:29.687803Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.7907)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:40:29.689412Z","iopub.execute_input":"2025-04-27T17:40:29.689620Z","iopub.status.idle":"2025-04-27T17:46:43.217956Z","shell.execute_reply.started":"2025-04-27T17:40:29.689603Z","shell.execute_reply":"2025-04-27T17:46:43.217125Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 14s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:46:43.219075Z","iopub.execute_input":"2025-04-27T17:46:43.219356Z","iopub.status.idle":"2025-04-27T18:04:51.532940Z","shell.execute_reply.started":"2025-04-27T17:46:43.219335Z","shell.execute_reply":"2025-04-27T18:04:51.532094Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.1642 | Train Acc: 98.21% | Val Loss: 0.0512 | Val Acc: 98.47% | Sparsity: 79.00%\nEpoch 2/50 | Train Loss: 0.1008 | Train Acc: 99.06% | Val Loss: 0.0448 | Val Acc: 98.56% | Sparsity: 79.00%\nEpoch 3/50 | Train Loss: 0.0844 | Train Acc: 99.25% | Val Loss: 0.0434 | Val Acc: 98.66% | Sparsity: 79.00%\nEpoch 4/50 | Train Loss: 0.0736 | Train Acc: 99.34% | Val Loss: 0.0422 | Val Acc: 98.60% | Sparsity: 79.00%\nEpoch 5/50 | Train Loss: 0.0694 | Train Acc: 99.34% | Val Loss: 0.0406 | Val Acc: 98.59% | Sparsity: 79.00%\nEpoch 6/50 | Train Loss: 0.0656 | Train Acc: 99.33% | Val Loss: 0.0411 | Val Acc: 98.59% | Sparsity: 79.00%\nEpoch 7/50 | Train Loss: 0.0617 | Train Acc: 99.42% | Val Loss: 0.0411 | Val Acc: 98.63% | Sparsity: 79.00%\nEpoch 8/50 | Train Loss: 0.0597 | Train Acc: 99.42% | Val Loss: 0.0410 | Val Acc: 98.65% | Sparsity: 79.00%\nEarly stopping triggered at epoch 8. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 18m 8s\nRetraining completed in 18.14 minutes (1088.31 seconds)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\"Pruned Student Model Test Accuracy(Retrain with KD): {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:04:51.534384Z","iopub.execute_input":"2025-04-27T18:04:51.534644Z","iopub.status.idle":"2025-04-27T18:05:01.864690Z","shell.execute_reply.started":"2025-04-27T18:04:51.534620Z","shell.execute_reply":"2025-04-27T18:05:01.863891Z"}},"outputs":[{"name":"stdout","text":"Pruned Student Model Test Accuracy(Retrain with KD): 95.51%\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"# 90% of Sparsity","metadata":{}},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:33:16.997115Z","iopub.execute_input":"2025-04-27T18:33:16.997430Z","iopub.status.idle":"2025-04-27T18:33:17.053908Z","shell.execute_reply.started":"2025-04-27T18:33:16.997404Z","shell.execute_reply":"2025-04-27T18:33:17.053212Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\nstudent = student.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:33:18.947403Z","iopub.execute_input":"2025-04-27T18:33:18.947669Z","iopub.status.idle":"2025-04-27T18:39:32.547136Z","shell.execute_reply.started":"2025-04-27T18:33:18.947649Z","shell.execute_reply":"2025-04-27T18:39:32.546407Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 14s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:39:32.548665Z","iopub.execute_input":"2025-04-27T18:39:32.548869Z","iopub.status.idle":"2025-04-27T19:13:30.175613Z","shell.execute_reply.started":"2025-04-27T18:39:32.548852Z","shell.execute_reply":"2025-04-27T19:13:30.174797Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 1.3333 | Train Acc: 92.86% | Val Loss: 0.2295 | Val Acc: 93.52% | Sparsity: 90.00%\nEpoch 2/50 | Train Loss: 0.6924 | Train Acc: 96.58% | Val Loss: 0.1507 | Val Acc: 95.26% | Sparsity: 90.00%\nEpoch 3/50 | Train Loss: 0.4653 | Train Acc: 97.99% | Val Loss: 0.1247 | Val Acc: 96.37% | Sparsity: 90.00%\nEpoch 4/50 | Train Loss: 0.3618 | Train Acc: 98.66% | Val Loss: 0.1529 | Val Acc: 95.47% | Sparsity: 90.00%\nEpoch 5/50 | Train Loss: 0.2994 | Train Acc: 98.92% | Val Loss: 0.0997 | Val Acc: 96.76% | Sparsity: 90.00%\nEpoch 6/50 | Train Loss: 0.2598 | Train Acc: 98.99% | Val Loss: 0.0973 | Val Acc: 96.98% | Sparsity: 90.00%\nEpoch 7/50 | Train Loss: 0.2344 | Train Acc: 99.10% | Val Loss: 0.0897 | Val Acc: 97.05% | Sparsity: 90.00%\nEpoch 8/50 | Train Loss: 0.2190 | Train Acc: 99.10% | Val Loss: 0.0905 | Val Acc: 97.17% | Sparsity: 90.00%\nEpoch 9/50 | Train Loss: 0.2068 | Train Acc: 99.14% | Val Loss: 0.0867 | Val Acc: 97.26% | Sparsity: 90.00%\nEpoch 10/50 | Train Loss: 0.1945 | Train Acc: 99.13% | Val Loss: 0.0839 | Val Acc: 97.41% | Sparsity: 90.00%\nEpoch 11/50 | Train Loss: 0.1891 | Train Acc: 99.13% | Val Loss: 0.0877 | Val Acc: 97.19% | Sparsity: 90.00%\nEpoch 12/50 | Train Loss: 0.1844 | Train Acc: 99.14% | Val Loss: 0.0874 | Val Acc: 97.14% | Sparsity: 90.00%\nEpoch 13/50 | Train Loss: 0.1743 | Train Acc: 99.08% | Val Loss: 0.0852 | Val Acc: 97.21% | Sparsity: 90.00%\nEpoch 14/50 | Train Loss: 0.1715 | Train Acc: 99.11% | Val Loss: 0.0858 | Val Acc: 97.39% | Sparsity: 90.00%\nEpoch 15/50 | Train Loss: 0.1625 | Train Acc: 99.12% | Val Loss: 0.0875 | Val Acc: 97.17% | Sparsity: 90.00%\nEarly stopping triggered at epoch 15. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 33m 58s\nRetraining completed in 33.96 minutes (2037.62 seconds)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:13:30.176701Z","iopub.execute_input":"2025-04-27T19:13:30.176929Z","iopub.status.idle":"2025-04-27T19:13:39.916707Z","shell.execute_reply.started":"2025-04-27T19:13:30.176908Z","shell.execute_reply":"2025-04-27T19:13:39.915921Z"}},"outputs":[{"name":"stdout","text":" Retrained Pruned Student Model Test Accuracy: 94.83%\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:13:39.918719Z","iopub.execute_input":"2025-04-27T19:13:39.918954Z","iopub.status.idle":"2025-04-27T19:13:39.979757Z","shell.execute_reply.started":"2025-04-27T19:13:39.918934Z","shell.execute_reply":"2025-04-27T19:13:39.978964Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.9008)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:13:39.980604Z","iopub.execute_input":"2025-04-27T19:13:39.981119Z","iopub.status.idle":"2025-04-27T19:19:53.475993Z","shell.execute_reply.started":"2025-04-27T19:13:39.981092Z","shell.execute_reply":"2025-04-27T19:19:53.475056Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:19:53.477305Z","iopub.execute_input":"2025-04-27T19:19:53.477553Z","iopub.status.idle":"2025-04-27T19:47:05.655197Z","shell.execute_reply.started":"2025-04-27T19:19:53.477532Z","shell.execute_reply":"2025-04-27T19:47:05.654274Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.3225 | Train Acc: 95.89% | Val Loss: 0.1079 | Val Acc: 96.82% | Sparsity: 90.00%\nEpoch 2/50 | Train Loss: 0.1664 | Train Acc: 98.38% | Val Loss: 0.0850 | Val Acc: 97.34% | Sparsity: 90.00%\nEpoch 3/50 | Train Loss: 0.1255 | Train Acc: 98.95% | Val Loss: 0.0721 | Val Acc: 97.82% | Sparsity: 90.00%\nEpoch 4/50 | Train Loss: 0.1072 | Train Acc: 99.17% | Val Loss: 0.0723 | Val Acc: 97.80% | Sparsity: 90.00%\nEpoch 5/50 | Train Loss: 0.0966 | Train Acc: 99.25% | Val Loss: 0.0694 | Val Acc: 97.91% | Sparsity: 90.00%\nEpoch 6/50 | Train Loss: 0.0908 | Train Acc: 99.24% | Val Loss: 0.0664 | Val Acc: 97.99% | Sparsity: 90.00%\nEpoch 7/50 | Train Loss: 0.0858 | Train Acc: 99.33% | Val Loss: 0.0679 | Val Acc: 98.04% | Sparsity: 90.00%\nEpoch 8/50 | Train Loss: 0.0811 | Train Acc: 99.28% | Val Loss: 0.0665 | Val Acc: 97.95% | Sparsity: 90.00%\nEpoch 9/50 | Train Loss: 0.0772 | Train Acc: 99.33% | Val Loss: 0.0645 | Val Acc: 97.96% | Sparsity: 90.00%\nEpoch 10/50 | Train Loss: 0.0751 | Train Acc: 99.29% | Val Loss: 0.0696 | Val Acc: 97.82% | Sparsity: 90.00%\nEpoch 11/50 | Train Loss: 0.0724 | Train Acc: 99.37% | Val Loss: 0.0695 | Val Acc: 97.89% | Sparsity: 90.00%\nEpoch 12/50 | Train Loss: 0.0705 | Train Acc: 99.39% | Val Loss: 0.0673 | Val Acc: 97.85% | Sparsity: 90.00%\nEarly stopping triggered at epoch 12. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 27m 12s\nRetraining completed in 27.20 minutes (1632.17 seconds)\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:47:05.656491Z","iopub.execute_input":"2025-04-27T19:47:05.656813Z","iopub.status.idle":"2025-04-27T19:47:15.879560Z","shell.execute_reply.started":"2025-04-27T19:47:05.656788Z","shell.execute_reply":"2025-04-27T19:47:15.878704Z"}},"outputs":[{"name":"stdout","text":" Retrained Pruned Student Model Test Accuracy: 94.62%\n","output_type":"stream"}],"execution_count":75},{"cell_type":"markdown","source":"## 95% Sparsity","metadata":{}},{"cell_type":"code","source":"sparsity = calculate_sparsity(pruned_student)\nprint(f\"Sparsity After Pruning: {sparsity * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:54:16.984651Z","iopub.execute_input":"2025-04-28T04:54:16.984902Z","iopub.status.idle":"2025-04-28T04:54:17.044701Z","shell.execute_reply.started":"2025-04-28T04:54:16.984882Z","shell.execute_reply":"2025-04-28T04:54:17.043862Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=5.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.95096)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:54:17.045760Z","iopub.execute_input":"2025-04-28T04:54:17.046594Z","iopub.status.idle":"2025-04-28T05:00:30.746882Z","shell.execute_reply.started":"2025-04-28T04:54:17.046568Z","shell.execute_reply":"2025-04-28T05:00:30.746152Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 13s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"sparsity = calculate_sparsity(pruned_student)\nprint(f\"Sparsity After Pruning: {sparsity * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:00:30.747783Z","iopub.execute_input":"2025-04-28T05:00:30.748106Z","iopub.status.idle":"2025-04-28T05:00:30.758259Z","shell.execute_reply.started":"2025-04-28T05:00:30.748080Z","shell.execute_reply":"2025-04-28T05:00:30.757454Z"}},"outputs":[{"name":"stdout","text":"Sparsity After Pruning: 95.01%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=5.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:02:12.687668Z","iopub.execute_input":"2025-04-28T05:02:12.688177Z","iopub.status.idle":"2025-04-28T05:42:59.172247Z","shell.execute_reply.started":"2025-04-28T05:02:12.688156Z","shell.execute_reply":"2025-04-28T05:42:59.171237Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 2.2595 | Train Acc: 87.98% | Val Loss: 0.3583 | Val Acc: 90.33% | Sparsity: 95.01%\nEpoch 2/50 | Train Loss: 1.1815 | Train Acc: 93.55% | Val Loss: 0.2888 | Val Acc: 92.66% | Sparsity: 95.01%\nEpoch 3/50 | Train Loss: 0.8662 | Train Acc: 95.48% | Val Loss: 0.2892 | Val Acc: 92.74% | Sparsity: 95.01%\nEpoch 4/50 | Train Loss: 0.6655 | Train Acc: 96.81% | Val Loss: 0.2717 | Val Acc: 93.29% | Sparsity: 95.01%\nEpoch 5/50 | Train Loss: 0.5171 | Train Acc: 97.92% | Val Loss: 0.2075 | Val Acc: 94.24% | Sparsity: 95.01%\nEpoch 6/50 | Train Loss: 0.4235 | Train Acc: 98.37% | Val Loss: 0.1786 | Val Acc: 95.17% | Sparsity: 95.01%\nEpoch 7/50 | Train Loss: 0.3598 | Train Acc: 98.69% | Val Loss: 0.1761 | Val Acc: 95.11% | Sparsity: 95.01%\nEpoch 8/50 | Train Loss: 0.3150 | Train Acc: 98.91% | Val Loss: 0.1653 | Val Acc: 95.26% | Sparsity: 95.01%\nEpoch 9/50 | Train Loss: 0.2926 | Train Acc: 98.99% | Val Loss: 0.1698 | Val Acc: 95.35% | Sparsity: 95.01%\nEpoch 10/50 | Train Loss: 0.2698 | Train Acc: 98.99% | Val Loss: 0.1566 | Val Acc: 95.61% | Sparsity: 95.01%\nEpoch 11/50 | Train Loss: 0.2560 | Train Acc: 99.02% | Val Loss: 0.1614 | Val Acc: 95.61% | Sparsity: 95.01%\nEpoch 12/50 | Train Loss: 0.2455 | Train Acc: 99.02% | Val Loss: 0.1589 | Val Acc: 95.60% | Sparsity: 95.01%\nEpoch 13/50 | Train Loss: 0.2345 | Train Acc: 99.05% | Val Loss: 0.1489 | Val Acc: 95.91% | Sparsity: 95.01%\nEpoch 14/50 | Train Loss: 0.2261 | Train Acc: 99.02% | Val Loss: 0.1498 | Val Acc: 95.77% | Sparsity: 95.01%\nEpoch 15/50 | Train Loss: 0.2192 | Train Acc: 99.09% | Val Loss: 0.1428 | Val Acc: 95.77% | Sparsity: 95.01%\nEpoch 16/50 | Train Loss: 0.2117 | Train Acc: 99.14% | Val Loss: 0.1518 | Val Acc: 95.63% | Sparsity: 95.01%\nEpoch 17/50 | Train Loss: 0.2069 | Train Acc: 99.04% | Val Loss: 0.1434 | Val Acc: 95.71% | Sparsity: 95.01%\nEpoch 18/50 | Train Loss: 0.1984 | Train Acc: 99.11% | Val Loss: 0.1431 | Val Acc: 95.86% | Sparsity: 95.01%\nEarly stopping triggered at epoch 18. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 40m 46s\nRetraining completed in 40.77 minutes (2446.48 seconds)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:42:59.173912Z","iopub.execute_input":"2025-04-28T05:42:59.174189Z","iopub.status.idle":"2025-04-28T05:43:09.149528Z","shell.execute_reply.started":"2025-04-28T05:42:59.174164Z","shell.execute_reply":"2025-04-28T05:43:09.148704Z"}},"outputs":[{"name":"stdout","text":" Retrained Pruned Student Model Test Accuracy: 94.34%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\nmodel_path = '/kaggle/input/studentc10/pytorch/default/1/student_before_pruning.pth'\n# Load the model weights\nstudent.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:43:09.150466Z","iopub.execute_input":"2025-04-28T05:43:09.150672Z","iopub.status.idle":"2025-04-28T05:43:09.220760Z","shell.execute_reply.started":"2025-04-28T05:43:09.150652Z","shell.execute_reply":"2025-04-28T05:43:09.220015Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/794737303.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  student.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Pruning\nprint(\"Calculating Important Scores\")\nstart_time = time.time()\nimportance_scores = compute_gradient_importance(\n    teacher, student, train_loader, device, temperature=3.0, alpha=0.7, accumulation_epochs=3\n)\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to calculate Important scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\nprint(\"Pruning the model\")\nstart_time = time.time()\n\npruned_student = gradient_based_global_prune(student, importance_scores, prune_ratio=0.95096)\n\ntotal_time = time.time() - start_time\nprint(f\"Total Time take to prune the model scores: {total_time // 60:.0f}m {total_time % 60:.0f}s\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:43:09.222431Z","iopub.execute_input":"2025-04-28T05:43:09.222635Z","iopub.status.idle":"2025-04-28T05:49:21.621086Z","shell.execute_reply.started":"2025-04-28T05:43:09.222619Z","shell.execute_reply":"2025-04-28T05:49:21.620146Z"}},"outputs":[{"name":"stdout","text":"Calculating Important Scores\nAccumulation Epoch 1/3\nAccumulation Epoch 2/3\nAccumulation Epoch 3/3\nTotal Time take to calculate Important scores: 6m 12s\nPruning the model\nTotal Time take to prune the model scores: 0m 0s\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"\nstart_time = time.time()\npruned_student = retrain_with_KD(\n    teacher, pruned_student, train_loader, val_loader,\n    epochs=50, temperature=3.0, alpha=0.7, beta_prob=0.5,patience=5,save_path=\"pruned_student_retrain_KD_90%.pth\"\n)\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Retraining completed in {elapsed_time / 60:.2f} minutes ({elapsed_time:.2f} seconds)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:49:21.622086Z","iopub.execute_input":"2025-04-28T05:49:21.622347Z","iopub.status.idle":"2025-04-28T06:34:37.504317Z","shell.execute_reply.started":"2025-04-28T05:49:21.622324Z","shell.execute_reply":"2025-04-28T06:34:37.503423Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 | Train Loss: 0.6771 | Train Acc: 90.86% | Val Loss: 0.1898 | Val Acc: 94.28% | Sparsity: 95.01%\nEpoch 2/50 | Train Loss: 0.3212 | Train Acc: 95.88% | Val Loss: 0.1843 | Val Acc: 94.60% | Sparsity: 95.01%\nEpoch 3/50 | Train Loss: 0.2287 | Train Acc: 97.63% | Val Loss: 0.1554 | Val Acc: 95.30% | Sparsity: 95.01%\nEpoch 4/50 | Train Loss: 0.1770 | Train Acc: 98.34% | Val Loss: 0.1448 | Val Acc: 95.48% | Sparsity: 95.01%\nEpoch 5/50 | Train Loss: 0.1452 | Train Acc: 98.78% | Val Loss: 0.1452 | Val Acc: 95.65% | Sparsity: 95.01%\nEpoch 6/50 | Train Loss: 0.1301 | Train Acc: 99.06% | Val Loss: 0.1384 | Val Acc: 95.84% | Sparsity: 95.01%\nEpoch 7/50 | Train Loss: 0.1184 | Train Acc: 99.13% | Val Loss: 0.1346 | Val Acc: 95.88% | Sparsity: 95.01%\nEpoch 8/50 | Train Loss: 0.1118 | Train Acc: 99.17% | Val Loss: 0.1289 | Val Acc: 96.04% | Sparsity: 95.01%\nEpoch 9/50 | Train Loss: 0.1041 | Train Acc: 99.21% | Val Loss: 0.1264 | Val Acc: 95.95% | Sparsity: 95.01%\nEpoch 10/50 | Train Loss: 0.0991 | Train Acc: 99.23% | Val Loss: 0.1330 | Val Acc: 95.96% | Sparsity: 95.01%\nEpoch 11/50 | Train Loss: 0.0972 | Train Acc: 99.24% | Val Loss: 0.1267 | Val Acc: 96.03% | Sparsity: 95.01%\nEpoch 12/50 | Train Loss: 0.0938 | Train Acc: 99.19% | Val Loss: 0.1293 | Val Acc: 96.05% | Sparsity: 95.01%\nEpoch 13/50 | Train Loss: 0.0915 | Train Acc: 99.30% | Val Loss: 0.1258 | Val Acc: 96.10% | Sparsity: 95.01%\nEpoch 14/50 | Train Loss: 0.0886 | Train Acc: 99.30% | Val Loss: 0.1261 | Val Acc: 96.14% | Sparsity: 95.01%\nEpoch 15/50 | Train Loss: 0.0871 | Train Acc: 99.30% | Val Loss: 0.1256 | Val Acc: 96.16% | Sparsity: 95.01%\nEpoch 16/50 | Train Loss: 0.0839 | Train Acc: 99.26% | Val Loss: 0.1281 | Val Acc: 96.06% | Sparsity: 95.01%\nEpoch 17/50 | Train Loss: 0.0815 | Train Acc: 99.31% | Val Loss: 0.1282 | Val Acc: 96.10% | Sparsity: 95.01%\nEpoch 18/50 | Train Loss: 0.0795 | Train Acc: 99.31% | Val Loss: 0.1266 | Val Acc: 96.15% | Sparsity: 95.01%\nEpoch 19/50 | Train Loss: 0.0774 | Train Acc: 99.37% | Val Loss: 0.1279 | Val Acc: 96.01% | Sparsity: 95.01%\nEpoch 20/50 | Train Loss: 0.0767 | Train Acc: 99.31% | Val Loss: 0.1327 | Val Acc: 96.00% | Sparsity: 95.01%\nEarly stopping triggered at epoch 20. No improvement for 5 epochs.\nStudent model saved before pruning at: pruned_student_retrain_KD_90%.pth\nTotal Training Time: 45m 16s\nRetraining completed in 45.26 minutes (2715.88 seconds)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"student_accuracy = evaluate(pruned_student, test_loader, device)\nprint(f\" Retrained Pruned Student Model Test Accuracy: {student_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T06:34:37.505783Z","iopub.execute_input":"2025-04-28T06:34:37.506040Z","iopub.status.idle":"2025-04-28T06:34:48.605673Z","shell.execute_reply.started":"2025-04-28T06:34:37.506017Z","shell.execute_reply":"2025-04-28T06:34:48.604731Z"}},"outputs":[{"name":"stdout","text":" Retrained Pruned Student Model Test Accuracy: 93.86%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}